{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24173a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "836ddb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7911b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                num_filters: int = 32, \n",
    "                hidden_dim: int = 128,\n",
    "                kernel_size: int = 4,\n",
    "                max_pool: int = 2,\n",
    "                output_dim:int=10,\n",
    "                width: int = 28,\n",
    "                height: int = 28\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            # Convolution 1\n",
    "            nn.Conv2d(in_channels = 1, out_channels = num_filters, kernel_size = kernel_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Convolution 2\n",
    "            nn.Conv2d(in_channels = num_filters, out_channels = num_filters, kernel_size = kernel_size),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Max pooling\n",
    "            nn.MaxPool2d(kernel_size=max_pool),\n",
    "\n",
    "            # Dropoout 1\n",
    "            nn.Dropout(p=0.25),\n",
    "\n",
    "            # Flatten and fully connected (account for two convolutions and maxpooling in input dimension)\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = (num_filters \n",
    "                                    * ((width - 2 * kernel_size + 2) // max_pool)\n",
    "                                    * ((height - 2 * kernel_size + 2) // max_pool)), \n",
    "                      out_features = hidden_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Droput 2\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            # Fully connected 2 \n",
    "            nn.Linear(in_features = hidden_dim, out_features = output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24050d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b42ef0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_set(dataset, size):\n",
    "    targets = np.array(dataset.targets)\n",
    "    all_indices = np.arange(len(targets))\n",
    "\n",
    "    samples_per_class = size//10\n",
    "\n",
    "    indices = []\n",
    "\n",
    "    for c in range(10):\n",
    "        c_indices = all_indices[targets == c]\n",
    "\n",
    "        indices.extend(np.random.choice(c_indices, size=samples_per_class, replace = False))\n",
    "    \n",
    "    return np.array(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ca166d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the indices of the trianing data\n",
    "total_indices = np.arange(len(train_dataset))\n",
    "\n",
    "# Initial Training Set: 20 random but balanced samples\n",
    "train_indices = get_balanced_set(train_dataset, 20)\n",
    "\n",
    "remaining_indices = np.setdiff1d(total_indices, train_indices)\n",
    "\n",
    "# Get the 100 validation datapoints used to optimize the learning rate\n",
    "validation_indices = np.random.choice(remaining_indices, size = 100, replace = False)\n",
    "\n",
    "# Pool Set: Everything else\n",
    "pool_indices = np.setdiff1d(remaining_indices, validation_indices)\n",
    "\n",
    "# Initialise training dataset to the initial 20 datapoints\n",
    "train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=64, shuffle=True)\n",
    "\n",
    "pool_loader = DataLoader(Subset(train_dataset, pool_indices), batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ad96d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_indices, lr = 3e-4, weight_decay = 1e-6, n_epochs = 50):\n",
    "    train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=128, shuffle=True)\n",
    "    n_batches = len(train_loader)\n",
    "\n",
    "    # Initialize model, optimizer and loss function \n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        pbar = tqdm.tqdm(enumerate(train_loader), total=n_batches, \n",
    "                               desc=f'Epoch {epoch + 1}/{n_epochs}')\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Encode and decode data\n",
    "            output = model(data)\n",
    "            predicted = output.argmax(dim=1, keepdim = True)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            pbar.set_postfix(loss = loss.item())\n",
    "            #pbar.set_description(f'Epoch {epoch + 1}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12bb3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    all_outputs = []\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in (pbar:= tqdm.tqdm(enumerate(test_loader))):\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output, dim=1)\n",
    "        correct += (target == predicted).sum().item()\n",
    "        all_outputs.append(output)\n",
    "\n",
    "    accuracy = correct/len(all_outputs)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "461ff139",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lrs = [np.exp(-i) for i in np.linspace(1,5,5)]\n",
    "lambdas = [np.exp(-i) for i in np.linspace(3,6,5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1b6fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(n_epochs=50):\n",
    "    val_loader = DataLoader(Subset(train_dataset, validation_indices), batch_size = 100, shuffle = False)\n",
    "\n",
    "    val_losses = []\n",
    "    #lrs = [np.exp(-i) for i in np.linspace(1,5,10)]\n",
    "    lambdas = [np.exp(-i) for i in np.linspace(3,6,10)]\n",
    "\n",
    "    #hypers = list(itertools.product(lrs, lambdas))\n",
    "\n",
    "    for wd in lambdas:\n",
    "        model = CNN()\n",
    "        model = train_model(model = model ,train_indices = train_indices, weight_decay = wd, n_epochs = n_epochs)\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (data, target) in (pbar := tqdm.tqdm(enumerate(val_loader))):\n",
    "            output = model(data)\n",
    "            val_loss = nn.CrossEntropyLoss()(output, target)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    #opt_lr, opt_wd = hypers[np.argmin(val_losses)]#\n",
    "    opt_wd = lambdas[np.argmin(val_losses)]\n",
    "    return opt_wd #, opt_wd\n",
    "\n",
    "#base_model = train_model(train_indices = train_indices, lr = opt_lr, weight_decay = opt_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c2a55f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 49.90it/s, loss=2.32]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 38.48it/s, loss=2.28]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 47.48it/s, loss=2.24]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 45.62it/s, loss=2.17]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 44.94it/s, loss=2.09]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 43.41it/s, loss=2.05]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 39.03it/s, loss=1.99]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 46.71it/s, loss=1.93]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 42.05it/s, loss=1.85]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 45.59it/s, loss=1.78]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 30.94it/s, loss=1.6]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 39.11it/s, loss=1.58]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 40.95it/s, loss=1.54]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 45.74it/s, loss=1.36]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 40.99it/s, loss=1.23]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 49.00it/s, loss=1.28]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 45.25it/s, loss=1.17]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 44.99it/s, loss=0.957]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 45.11it/s, loss=0.949]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 47.55it/s, loss=0.809]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 48.36it/s, loss=0.812]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 42.75it/s, loss=0.763]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 45.19it/s, loss=0.544]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 44.57it/s, loss=0.617]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s, loss=0.595]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 46.47it/s, loss=0.551]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 37.89it/s, loss=0.358]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 38.88it/s, loss=0.297]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 43.18it/s, loss=0.389]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 42.15it/s, loss=0.307]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 39.85it/s, loss=0.288]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 50.28it/s, loss=0.286]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 40.52it/s, loss=0.238]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 44.81it/s, loss=0.123]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 41.40it/s, loss=0.204]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 43.97it/s, loss=0.108]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 31.22it/s, loss=0.201]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 44.10it/s, loss=0.12]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 41.99it/s, loss=0.139]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s, loss=0.115]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 47.23it/s, loss=0.0729]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 39.30it/s, loss=0.293]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 45.46it/s, loss=0.103]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 48.70it/s, loss=0.0809]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 45.54it/s, loss=0.0473]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 40.06it/s, loss=0.124]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 42.39it/s, loss=0.0829]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 44.09it/s, loss=0.0322]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 45.50it/s, loss=0.0362]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 48.42it/s, loss=0.111]\n",
      "1it [00:00, 56.47it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 60.87it/s, loss=2.35]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 45.30it/s, loss=2.27]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 50.66it/s, loss=2.21]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 54.53it/s, loss=2.19]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 47.08it/s, loss=2.14]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 56.93it/s, loss=2.02]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 51.54it/s, loss=1.99]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 56.12it/s, loss=1.85]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, loss=1.86]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 48.63it/s, loss=1.67]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 58.98it/s, loss=1.74]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 50.07it/s, loss=1.64]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 56.45it/s, loss=1.54]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 51.61it/s, loss=1.23]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 57.19it/s, loss=1.28]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 50.42it/s, loss=1.17]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 35.91it/s, loss=0.934]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 48.54it/s, loss=0.954]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 57.48it/s, loss=0.938]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, loss=0.732]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 52.06it/s, loss=0.678]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 46.85it/s, loss=0.558]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 51.77it/s, loss=0.482]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 50.81it/s, loss=0.529]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 60.79it/s, loss=0.471]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 55.81it/s, loss=0.415]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 55.14it/s, loss=0.356]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 52.71it/s, loss=0.297]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 48.27it/s, loss=0.264]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 47.23it/s, loss=0.224]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 60.18it/s, loss=0.248]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 55.99it/s, loss=0.282]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 52.89it/s, loss=0.175]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 47.47it/s, loss=0.253]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 51.28it/s, loss=0.127]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 50.21it/s, loss=0.285]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 52.36it/s, loss=0.129]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 50.08it/s, loss=0.0768]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 51.61it/s, loss=0.0939]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 39.93it/s, loss=0.143]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 48.78it/s, loss=0.143]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 57.89it/s, loss=0.105]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 48.58it/s, loss=0.0724]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 47.37it/s, loss=0.0651]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 57.11it/s, loss=0.0608]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 55.16it/s, loss=0.0286]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 47.98it/s, loss=0.153]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 50.35it/s, loss=0.044]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 57.29it/s, loss=0.0531]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 53.69it/s, loss=0.0328]\n",
      "1it [00:00, 52.74it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 60.85it/s, loss=2.35]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 53.84it/s, loss=2.28]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 50.04it/s, loss=2.2]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 58.16it/s, loss=2.21]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 60.13it/s, loss=2.08]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 59.17it/s, loss=2.09]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 59.22it/s, loss=2.03]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 41.05it/s, loss=2.03]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 51.76it/s, loss=1.9]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 53.07it/s, loss=1.71]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 54.80it/s, loss=1.72]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 52.40it/s, loss=1.59]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 54.16it/s, loss=1.43]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 58.48it/s, loss=1.43]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 58.14it/s, loss=1.19]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 60.74it/s, loss=1.13]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 52.51it/s, loss=1.11]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 56.90it/s, loss=1.07]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 57.19it/s, loss=0.926]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 49.00it/s, loss=0.774]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 50.66it/s, loss=0.839]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 68.24it/s, loss=0.662]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 53.60it/s, loss=0.694]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 54.25it/s, loss=0.46]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 52.56it/s, loss=0.46]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 63.30it/s, loss=0.398]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 37.09it/s, loss=0.47]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 59.03it/s, loss=0.33]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 59.88it/s, loss=0.358]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 58.64it/s, loss=0.243]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 45.27it/s, loss=0.244]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 56.39it/s, loss=0.286]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 51.65it/s, loss=0.193]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 60.04it/s, loss=0.174]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 61.26it/s, loss=0.25]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 57.69it/s, loss=0.229]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 55.57it/s, loss=0.177]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 57.57it/s, loss=0.133]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 53.92it/s, loss=0.0724]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 50.79it/s, loss=0.0976]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 61.65it/s, loss=0.0913]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 62.86it/s, loss=0.0481]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 53.59it/s, loss=0.109]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 56.34it/s, loss=0.0416]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 53.55it/s, loss=0.0764]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 62.80it/s, loss=0.034]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 55.61it/s, loss=0.0303]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 35.95it/s, loss=0.0485]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 53.12it/s, loss=0.0479]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 60.87it/s, loss=0.0485]\n",
      "1it [00:00, 50.43it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 43.01it/s, loss=2.29]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 50.94it/s, loss=2.28]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 51.07it/s, loss=2.26]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 47.95it/s, loss=2.16]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 46.88it/s, loss=2.16]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 52.26it/s, loss=2.13]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 45.08it/s, loss=2.09]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s, loss=2.06]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 59.46it/s, loss=1.84]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 46.24it/s, loss=1.85]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 43.17it/s, loss=1.81]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 42.17it/s, loss=1.72]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 43.21it/s, loss=1.53]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 44.24it/s, loss=1.59]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 47.58it/s, loss=1.38]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 51.49it/s, loss=1.45]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 37.44it/s, loss=1.27]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 52.12it/s, loss=1.25]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 48.61it/s, loss=1.16]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 49.79it/s, loss=0.874]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 53.77it/s, loss=0.9]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 42.25it/s, loss=0.813]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 48.39it/s, loss=0.812]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 48.37it/s, loss=0.638]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 46.83it/s, loss=0.666]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 51.38it/s, loss=0.622]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 38.10it/s, loss=0.713]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 45.84it/s, loss=0.511]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 45.36it/s, loss=0.472]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 51.50it/s, loss=0.309]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 41.67it/s, loss=0.423]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 52.12it/s, loss=0.332]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 34.59it/s, loss=0.298]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 46.95it/s, loss=0.257]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 57.50it/s, loss=0.16]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 40.23it/s, loss=0.362]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 51.99it/s, loss=0.235]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 44.16it/s, loss=0.159]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 45.59it/s, loss=0.105]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 45.71it/s, loss=0.184]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 50.20it/s, loss=0.162]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 47.45it/s, loss=0.213]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 47.08it/s, loss=0.168]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, loss=0.106]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 45.24it/s, loss=0.131]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 53.00it/s, loss=0.115]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 52.61it/s, loss=0.0853]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 40.15it/s, loss=0.0871]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 39.46it/s, loss=0.0479]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 43.74it/s, loss=0.0466]\n",
      "1it [00:00, 47.29it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 50.20it/s, loss=2.32]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 48.90it/s, loss=2.3]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 56.54it/s, loss=2.26]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 49.17it/s, loss=2.18]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 42.78it/s, loss=2.14]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 57.32it/s, loss=2.08]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 47.94it/s, loss=1.92]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 53.36it/s, loss=1.94]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 42.27it/s, loss=1.86]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 43.34it/s, loss=1.75]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 53.33it/s, loss=1.64]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 51.08it/s, loss=1.53]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 55.55it/s, loss=1.52]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 33.93it/s, loss=1.34]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 55.22it/s, loss=1.13]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 50.19it/s, loss=1.26]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 55.98it/s, loss=0.881]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 54.27it/s, loss=0.972]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 55.21it/s, loss=0.789]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 49.28it/s, loss=0.74]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 48.34it/s, loss=0.578]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, loss=0.609]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 50.66it/s, loss=0.432]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 59.02it/s, loss=0.467]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 49.26it/s, loss=0.488]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 54.09it/s, loss=0.393]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 44.04it/s, loss=0.346]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 53.33it/s, loss=0.271]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 34.10it/s, loss=0.295]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 50.53it/s, loss=0.239]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 50.80it/s, loss=0.288]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 47.90it/s, loss=0.198]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 54.48it/s, loss=0.141]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 47.93it/s, loss=0.206]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 46.99it/s, loss=0.133]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 56.52it/s, loss=0.0793]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 44.52it/s, loss=0.0794]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 55.25it/s, loss=0.081]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 45.07it/s, loss=0.103]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 50.21it/s, loss=0.0663]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 44.02it/s, loss=0.0559]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 54.37it/s, loss=0.0803]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 52.27it/s, loss=0.113]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 48.99it/s, loss=0.0708]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 32.33it/s, loss=0.0524]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 50.83it/s, loss=0.0294]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 49.10it/s, loss=0.0545]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 47.73it/s, loss=0.0327]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 49.18it/s, loss=0.0544]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 61.08it/s, loss=0.0159]\n",
      "1it [00:00, 46.67it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 46.98it/s, loss=2.32]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 50.33it/s, loss=2.27]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 54.16it/s, loss=2.23]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 47.09it/s, loss=2.19]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 45.55it/s, loss=2.12]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 48.53it/s, loss=2.07]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 48.14it/s, loss=2.03]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 35.19it/s, loss=1.94]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 53.07it/s, loss=1.82]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 54.23it/s, loss=1.73]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 45.79it/s, loss=1.68]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 49.16it/s, loss=1.57]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 58.20it/s, loss=1.41]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 51.74it/s, loss=1.48]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 53.40it/s, loss=1.28]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 45.90it/s, loss=1.21]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 49.00it/s, loss=1.04]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 60.64it/s, loss=0.932]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 50.58it/s, loss=1]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 43.65it/s, loss=0.792]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 56.94it/s, loss=0.832]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 54.85it/s, loss=0.641]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 54.02it/s, loss=0.541]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 57.35it/s, loss=0.528]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 59.06it/s, loss=0.397]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 34.90it/s, loss=0.505]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 48.02it/s, loss=0.297]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 62.83it/s, loss=0.32]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 50.90it/s, loss=0.351]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 54.37it/s, loss=0.294]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 52.53it/s, loss=0.227]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 51.67it/s, loss=0.246]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 59.31it/s, loss=0.195]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 45.58it/s, loss=0.23]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 54.26it/s, loss=0.159]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 51.43it/s, loss=0.121]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 48.08it/s, loss=0.204]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 57.84it/s, loss=0.165]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 59.02it/s, loss=0.0959]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 38.15it/s, loss=0.0514]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 42.71it/s, loss=0.0831]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 41.86it/s, loss=0.112]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 60.84it/s, loss=0.0679]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 56.62it/s, loss=0.0614]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 55.11it/s, loss=0.0739]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 55.85it/s, loss=0.113]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 57.61it/s, loss=0.0611]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 48.45it/s, loss=0.071]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 55.94it/s, loss=0.0215]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 51.46it/s, loss=0.0354]\n",
      "1it [00:00, 47.63it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 53.32it/s, loss=2.31]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 50.01it/s, loss=2.3]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 50.85it/s, loss=2.21]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 42.70it/s, loss=2.15]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 59.49it/s, loss=2.13]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 57.00it/s, loss=2.07]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s, loss=2.03]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s, loss=1.91]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 51.68it/s, loss=1.9]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 61.02it/s, loss=1.75]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 51.37it/s, loss=1.73]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 62.64it/s, loss=1.51]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 55.27it/s, loss=1.44]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 56.64it/s, loss=1.39]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 53.87it/s, loss=1.38]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 49.63it/s, loss=1.15]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 53.85it/s, loss=0.933]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 51.34it/s, loss=0.992]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 38.27it/s, loss=0.792]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 49.48it/s, loss=0.784]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 47.84it/s, loss=0.862]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 48.60it/s, loss=0.647]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 45.66it/s, loss=0.544]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 50.51it/s, loss=0.424]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 53.38it/s, loss=0.387]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 51.60it/s, loss=0.473]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 50.58it/s, loss=0.354]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 47.48it/s, loss=0.247]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 43.09it/s, loss=0.371]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 46.98it/s, loss=0.324]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 53.46it/s, loss=0.321]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 31.72it/s, loss=0.167]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 54.58it/s, loss=0.089]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 50.46it/s, loss=0.153]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 58.52it/s, loss=0.095]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 46.47it/s, loss=0.155]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 57.92it/s, loss=0.136]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 48.25it/s, loss=0.129]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 51.58it/s, loss=0.182]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 47.19it/s, loss=0.0717]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 45.84it/s, loss=0.107]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 54.64it/s, loss=0.0397]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 44.61it/s, loss=0.14]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 57.53it/s, loss=0.0622]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 46.98it/s, loss=0.0361]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 39.43it/s, loss=0.0764]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 48.19it/s, loss=0.047]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 46.01it/s, loss=0.0547]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 52.18it/s, loss=0.1]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 53.29it/s, loss=0.0884]\n",
      "1it [00:00, 48.19it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 63.26it/s, loss=2.29]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 47.51it/s, loss=2.24]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 49.74it/s, loss=2.13]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 44.65it/s, loss=2.17]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 49.59it/s, loss=2.05]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 62.94it/s, loss=1.95]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 52.72it/s, loss=1.94]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 52.33it/s, loss=1.83]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 50.65it/s, loss=1.8]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 48.02it/s, loss=1.77]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 38.45it/s, loss=1.66]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 43.37it/s, loss=1.38]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 51.22it/s, loss=1.35]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 48.62it/s, loss=1.27]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 41.55it/s, loss=1.09]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 58.27it/s, loss=1.11]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 50.05it/s, loss=0.934]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 61.10it/s, loss=0.962]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 47.96it/s, loss=0.835]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 47.18it/s, loss=0.802]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 46.45it/s, loss=0.699]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 53.32it/s, loss=0.447]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 43.28it/s, loss=0.512]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 36.27it/s, loss=0.459]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 41.49it/s, loss=0.311]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 52.16it/s, loss=0.396]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 54.20it/s, loss=0.396]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 53.60it/s, loss=0.282]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 56.79it/s, loss=0.26]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 48.37it/s, loss=0.14]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 50.50it/s, loss=0.163]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 41.92it/s, loss=0.183]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 56.33it/s, loss=0.125]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s, loss=0.19]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 54.29it/s, loss=0.153]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 50.83it/s, loss=0.108]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 44.92it/s, loss=0.0737]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 54.41it/s, loss=0.0793]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 45.69it/s, loss=0.0669]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s, loss=0.0776]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 46.51it/s, loss=0.048]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 50.15it/s, loss=0.2]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s, loss=0.117]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 53.58it/s, loss=0.0895]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 38.40it/s, loss=0.0474]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 46.88it/s, loss=0.023]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 58.92it/s, loss=0.0777]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 49.00it/s, loss=0.0293]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 48.83it/s, loss=0.0994]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 44.38it/s, loss=0.0741]\n",
      "1it [00:00, 45.65it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 57.68it/s, loss=2.29]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 55.06it/s, loss=2.27]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 55.38it/s, loss=2.23]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 46.85it/s, loss=2.18]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 59.53it/s, loss=2.1]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 46.55it/s, loss=2.06]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 56.49it/s, loss=2.08]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 46.98it/s, loss=1.95]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 52.97it/s, loss=1.98]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 54.43it/s, loss=1.75]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 47.10it/s, loss=1.7]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 41.77it/s, loss=1.57]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 54.62it/s, loss=1.63]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 36.30it/s, loss=1.4]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 48.46it/s, loss=1.49]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 49.85it/s, loss=1.14]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 44.65it/s, loss=1.09]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 60.68it/s, loss=1.14]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 53.57it/s, loss=1.11]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 47.25it/s, loss=0.965]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 43.90it/s, loss=0.824]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 52.64it/s, loss=0.777]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 59.07it/s, loss=0.701]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 54.05it/s, loss=0.541]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 47.47it/s, loss=0.458]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 44.22it/s, loss=0.496]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 44.36it/s, loss=0.376]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s, loss=0.444]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 49.07it/s, loss=0.296]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 61.44it/s, loss=0.297]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 53.10it/s, loss=0.19]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 57.48it/s, loss=0.157]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 56.34it/s, loss=0.275]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 55.52it/s, loss=0.26]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 55.03it/s, loss=0.131]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 54.00it/s, loss=0.103]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 58.18it/s, loss=0.186]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 44.24it/s, loss=0.181]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 39.31it/s, loss=0.0995]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 50.24it/s, loss=0.18]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 56.61it/s, loss=0.173]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 50.58it/s, loss=0.117]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 50.06it/s, loss=0.186]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 55.22it/s, loss=0.102]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 53.73it/s, loss=0.109]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 47.40it/s, loss=0.196]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 54.29it/s, loss=0.0768]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 50.52it/s, loss=0.119]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 52.50it/s, loss=0.0762]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 54.94it/s, loss=0.0557]\n",
      "1it [00:00, 39.99it/s]\n",
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 52.06it/s, loss=2.31]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 48.47it/s, loss=2.26]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 51.78it/s, loss=2.2]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 61.91it/s, loss=2.16]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 54.39it/s, loss=2.16]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 50.06it/s, loss=2.1]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 52.12it/s, loss=1.97]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 51.20it/s, loss=2]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 54.81it/s, loss=1.86]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 58.32it/s, loss=1.78]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 41.33it/s, loss=1.71]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 54.72it/s, loss=1.55]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 52.93it/s, loss=1.47]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 53.01it/s, loss=1.25]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 50.14it/s, loss=1.2]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 67.05it/s, loss=1.19]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 57.20it/s, loss=0.975]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 56.33it/s, loss=0.852]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 52.89it/s, loss=0.88]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 51.72it/s, loss=0.661]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 48.94it/s, loss=0.604]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 46.28it/s, loss=0.611]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 38.68it/s, loss=0.491]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 54.50it/s, loss=0.552]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 55.36it/s, loss=0.422]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 45.86it/s, loss=0.418]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 58.84it/s, loss=0.172]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 45.66it/s, loss=0.396]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 46.28it/s, loss=0.311]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 52.32it/s, loss=0.207]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 54.20it/s, loss=0.152]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 45.73it/s, loss=0.276]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 45.06it/s, loss=0.205]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 47.04it/s, loss=0.201]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 50.26it/s, loss=0.222]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 40.36it/s, loss=0.0997]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 56.50it/s, loss=0.117]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 53.21it/s, loss=0.186]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 59.83it/s, loss=0.2]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 48.82it/s, loss=0.0476]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 44.14it/s, loss=0.105]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 52.95it/s, loss=0.0561]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 45.77it/s, loss=0.0407]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 52.49it/s, loss=0.0742]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s, loss=0.0416]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 51.57it/s, loss=0.019]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 54.33it/s, loss=0.108]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 50.39it/s, loss=0.0399]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 47.13it/s, loss=0.0922]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 50.45it/s, loss=0.0358]\n",
      "1it [00:00, 44.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt wd: 0.004827949993831441\n"
     ]
    }
   ],
   "source": [
    "opt_wd = validation()\n",
    "print(f\"Opt wd: {opt_wd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71f08262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 50.55it/s, loss=2.32]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 42.92it/s, loss=2.22]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 46.44it/s, loss=2.17]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 48.41it/s, loss=2.13]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 49.81it/s, loss=1.83]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 45.74it/s, loss=1.58]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 49.60it/s, loss=1.36]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 46.20it/s, loss=1.05]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 45.32it/s, loss=1.07]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 49.89it/s, loss=0.705]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 53.48it/s, loss=0.595]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 36.94it/s, loss=0.701]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 48.03it/s, loss=0.447]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 43.13it/s, loss=0.486]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 41.06it/s, loss=0.274]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 60.19it/s, loss=0.268]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 48.38it/s, loss=0.522]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 40.75it/s, loss=0.227]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 52.65it/s, loss=0.225]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 41.36it/s, loss=0.332]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 53.73it/s, loss=0.134]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 36.73it/s, loss=0.163]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 37.58it/s, loss=0.188]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 40.23it/s, loss=0.184]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 42.44it/s, loss=0.0463]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 44.29it/s, loss=0.0753]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 46.42it/s, loss=0.116]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 45.91it/s, loss=0.114]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 46.10it/s, loss=0.104]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 43.44it/s, loss=0.0789]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 47.80it/s, loss=0.0664]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 45.37it/s, loss=0.0323]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 37.62it/s, loss=0.0261]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 37.75it/s, loss=0.111]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 43.63it/s, loss=0.0391]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 36.87it/s, loss=0.0965]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 54.24it/s, loss=0.0657]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 43.78it/s, loss=0.0082]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 46.65it/s, loss=0.0426]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 42.11it/s, loss=0.0731]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 43.38it/s, loss=0.211]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 46.04it/s, loss=0.0755]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 42.21it/s, loss=0.101]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 44.05it/s, loss=0.0139]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 42.80it/s, loss=0.0144]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 44.20it/s, loss=0.00852]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 36.78it/s, loss=0.0296]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 48.46it/s, loss=0.0141]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 46.92it/s, loss=0.0116]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 49.70it/s, loss=0.00603]\n",
      "79it [00:01, 52.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model test accuracy: 66.32911392405063\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "base_model = train_model(model = model, train_indices = train_indices, lr = 1e-3, weight_decay = opt_wd, n_epochs = 50)\n",
    "print(f\"Base model test accuracy: {test_model(base_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4393737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(preds):\n",
    "    # Input of shape T x N x dim_output\n",
    "\n",
    "    # negative sum over C [(1/T sum over T p_c^t) * log(1/T sum over T p_c^t)]\n",
    "    T,N,C = preds.shape\n",
    "\n",
    "    mean_probs = torch.mean(preds, dim = 0) + 1e-10\n",
    "\n",
    "    log_probs = torch.log(mean_probs)\n",
    "\n",
    "    entropy = -torch.sum(mean_probs*log_probs, dim =1)\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5d8d22b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MI(preds):\n",
    "    print(f\"Calculating MI\")\n",
    "    entropy = calc_entropy(preds)\n",
    "\n",
    "    T,N,C = preds.shape\n",
    "    plogp = preds * torch.log(preds+1e-10)\n",
    "    sum_T = torch.sum(plogp, dim  =0) #sum over T, leaving an N x C tensor\n",
    "    sum_C = torch.sum(sum_T, dim = 1) #sum over C leaving a N dim tensor\n",
    "    \n",
    "    MI = entropy + 1/T*sum_C\n",
    "    print(f\"MI calc done\")\n",
    "    return MI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "037ce72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_var_rat(preds):\n",
    "    \n",
    "    T,N,C = preds.shape\n",
    "\n",
    "    max_indices = torch.argmax(preds, dim=2, keepdim = True)\n",
    "    #print(f\"max indices shape: {max_indices.shape}\")\n",
    "\n",
    "    one_hot = torch.zeros_like(preds, dtype = torch.float)\n",
    "    #print(f\"zeros: {one_hot.shape}\")\n",
    "    one_hot.scatter_(2, max_indices, 1.0)\n",
    "    #print(f\"one_hot scatter: {one_hot.shape}\")\n",
    "\n",
    "    sum_T = torch.sum(one_hot, dim=0)       # N x C \n",
    "    #print(f\"sum over T: {sum_T.shape}\")\n",
    "    c_max = torch.argmax(sum_T, dim =1)         # Maximise over C\n",
    "    #print(f\"c_argmax: {c_max.shape}\")\n",
    "    f_x,_ = torch.max(sum_T, dim=1)         # N\n",
    "\n",
    "    return 1-(f_x/T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c63e5737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MSTD(preds):\n",
    "    T,N,C = preds.shape\n",
    "\n",
    "    mean_pred_squared = torch.mean(preds, dim=0)**2\n",
    "    mean_squared_pred = torch.mean(preds**2, dim =0)\n",
    "\n",
    "    sigmas = torch.sqrt((mean_squared_pred-mean_pred_squared))\n",
    "    sigmas_c = torch.sum(sigmas, dim=1)\n",
    "\n",
    "    return sigmas_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71d0f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uniform(preds):\n",
    "    T,N,C = preds.shape\n",
    "    uniform = torch.ones(N, dtype = torch.float)\n",
    "    \n",
    "    return uniform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a87982b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TNC_preds(x, model, T):\n",
    "    #print(f\"getTNC:{x.shape}\")\n",
    "    N = x.shape[0]\n",
    "\n",
    "    x_batch = x.repeat(T,1,1,1)\n",
    "\n",
    "    #print(f\"x_batch shape: {x_batch.shape}\")\n",
    "\n",
    "    #x_batch = x_tiled.reshape(T*N, -1)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    output = model(x_batch)\n",
    "    output_TNC = output.reshape(T,N,-1)\n",
    "\n",
    "    return output_TNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3c71a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_x(x, n, TNC_preds, acquisition_fn):\n",
    "    acquisition_values = acquisition_fn(TNC_preds)\n",
    "\n",
    "    _,acquired_indices = torch.topk(acquisition_values, k = n)\n",
    "\n",
    "    acquired_x = x[acquired_indices]\n",
    "    \n",
    "    return acquired_x, acquired_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc2f3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling of data during training using each acquisition function \n",
    "\n",
    "import pickle \n",
    "#from google.colab import drive\n",
    "#import os\n",
    "\n",
    "global database\n",
    "global filename\n",
    "\n",
    "# 1. Mount your Google Drive (A window will pop up asking for authentication)\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# 2. Define a path inside your Drive\n",
    "#DRIVE_PATH = '/content/drive/MyDrive/UDL_Results/'\n",
    "\n",
    "# Ensure the directory exists\n",
    "#os.makedirs(DRIVE_PATH, exist_ok=True)\n",
    "\n",
    "#filename = os.path.join(DRIVE_PATH, 'active_learning_results.png')                 \n",
    "#filename = 'active_learning_results.png'\n",
    "\n",
    "database = {}\n",
    "filename = \"acq_database\"\n",
    "\n",
    "acquisition_fns = {\"MI\":calc_MI}\n",
    "#acquisition_fns = {\"entropy\":calc_entropy, \"rvar_rat\": calc_var_rat, \"MI\": calc_MI,\"MSTD\": calc_MSTD, \"uniform\": calc_uniform}\n",
    "\n",
    "# Initiating an empy database which will store the accuracy after each acquisition step\n",
    "\n",
    "for name in acquisition_fns:\n",
    "    database[name] = []\n",
    "\n",
    "\n",
    "def save_database(data, filename):\n",
    "    try:\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving database to {filename}: {e}\")\n",
    "\n",
    "def load_database(filename):\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No previous database found at {filename}. Starting fresh.\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading database from {filename}: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac3372bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_w_acquisition(T, base_model, train_dataset, train_indices, pool_indices, acq_fn_name, acq_fn, n_acq = 100, n_epochs=1, acq_batch_size = 64):\n",
    "    global database\n",
    "    global filename\n",
    "    model = copy.deepcopy(base_model)               # Ensures base_model is not changed \n",
    "    train_indices_copy = train_indices.copy()\n",
    "    pool_indices_copy = pool_indices.copy()\n",
    "    #pool_indices_copy = pool_indices[0:1000]\n",
    "    for i in range(n_acq):\n",
    "        uncertainty_scores = []\n",
    "\n",
    "        pool_data = DataLoader(Subset(train_dataset, pool_indices_copy), batch_size = acq_batch_size, shuffle = False)    # gets data from pool from which we will acquire new xs\n",
    "        for batch_idx, (x_batch,_) in enumerate(pool_data):\n",
    "            acq_values = acq_fn(get_TNC_preds(x_batch, model, T))\n",
    "\n",
    "            # Helps with memory\n",
    "            if isinstance(acq_values, torch.Tensor):\n",
    "                scores = acq_values.detach().cpu().numpy()\n",
    "            else:\n",
    "                scores = acq_values\n",
    "                \n",
    "            uncertainty_scores.append(scores)\n",
    "            \n",
    "            # Delete unused values to help clear memory\n",
    "            del x_batch, acq_values \n",
    "            torch.cuda.empty_cache() # Clear GPU cache if using CUDA\n",
    "\n",
    "            print(f\"Progress: {batch_idx/len(pool_data)}\")\n",
    "            \n",
    "        uncertainty_scores = np.concatenate(uncertainty_scores)\n",
    "        sorted_indices_in_scores = np.argsort(uncertainty_scores)[::-1]\n",
    "        acquired_indices = sorted_indices_in_scores[:10]\n",
    "        pool_indices_copy = np.setdiff1d(pool_indices_copy, acquired_indices)\n",
    "        train_indices_copy = np.concatenate((train_indices_copy, acquired_indices))\n",
    "\n",
    "        model = train_model(model = model, train_indices=train_indices_copy, lr = 1e-3, weight_decay = opt_wd, n_epochs = n_epochs)\n",
    "        accuracy = test_model(model)\n",
    "        database[acq_fn_name].append([(i+1)*10, accuracy])\n",
    "        save_database(database, filename)\n",
    "        \n",
    "\n",
    "        print(f\"Accuracy for acq_fn {acq_fn_name} at acq-step {(i+1)*10} is {accuracy}\")\n",
    "\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02a0331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0010683760683760685\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.002136752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.003205128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.004273504273504274\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.005341880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.00641025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.007478632478632479\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.008547008547008548\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.009615384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.010683760683760684\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.011752136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.01282051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.013888888888888888\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.014957264957264958\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.016025641025641024\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.017094017094017096\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.018162393162393164\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.019230769230769232\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0202991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.021367521367521368\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.022435897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.023504273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.024572649572649572\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.02564102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.026709401709401708\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.027777777777777776\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.028846153846153848\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.029914529914529916\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.030982905982905984\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03205128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03311965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03418803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.035256410256410256\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03632478632478633\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03739316239316239\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.038461538461538464\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03952991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0405982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.041666666666666664\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.042735042735042736\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0438034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.04487179487179487\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.045940170940170943\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.04700854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.04807692307692308\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.049145299145299144\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.050213675213675216\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05128205128205128\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05235042735042735\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.053418803418803416\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05448717948717949\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05555555555555555\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.056623931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.057692307692307696\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05876068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05982905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.060897435897435896\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06196581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06303418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0641025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06517094017094018\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06623931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0673076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06837606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06944444444444445\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07051282051282051\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07158119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07264957264957266\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07371794871794872\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07478632478632478\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07585470085470085\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07692307692307693\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07799145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07905982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08012820512820513\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0811965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08226495726495726\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08333333333333333\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08440170940170941\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08547008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08653846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0876068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08867521367521368\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08974358974358974\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09081196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09188034188034189\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09294871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09401709401709402\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09508547008547008\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09615384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09722222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09829059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09935897435897435\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10042735042735043\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1014957264957265\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10256410256410256\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10363247863247864\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1047008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10576923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10683760683760683\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10790598290598291\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10897435897435898\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11004273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1111111111111111\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11217948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11324786324786325\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11431623931623931\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11538461538461539\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11645299145299146\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11752136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11858974358974358\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11965811965811966\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12072649572649573\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12179487179487179\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12286324786324786\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12393162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.125\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12606837606837606\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12713675213675213\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1282051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12927350427350429\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13034188034188035\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13141025641025642\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13247863247863248\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13354700854700854\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1346153846153846\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13568376068376067\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13675213675213677\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13782051282051283\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1388888888888889\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.13995726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.14102564102564102\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1420940170940171\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.14316239316239315\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.14423076923076922\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1452991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.14636752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.14743589743589744\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1485042735042735\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.14957264957264957\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.15064102564102563\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1517094017094017\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1527777777777778\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.15384615384615385\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.15491452991452992\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.15598290598290598\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.15705128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1581196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.15918803418803418\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16025641025641027\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16132478632478633\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1623931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16346153846153846\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16452991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1655982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16666666666666666\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16773504273504272\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16880341880341881\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.16987179487179488\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.17094017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.172008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.17307692307692307\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.17414529914529914\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1752136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1762820512820513\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.17735042735042736\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.17841880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1794871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.18055555555555555\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.18162393162393162\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.18269230769230768\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.18376068376068377\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.18482905982905984\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1858974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.18696581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.18803418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1891025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.19017094017094016\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.19123931623931623\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.19230769230769232\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.19337606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.19444444444444445\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1955128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.19658119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.19764957264957264\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1987179487179487\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1997863247863248\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.20085470085470086\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.20192307692307693\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.202991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.20405982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.20512820512820512\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.20619658119658119\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.20726495726495728\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.20833333333333334\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2094017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.21047008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.21153846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2126068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.21367521367521367\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.21474358974358973\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.21581196581196582\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2168803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.21794871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.21901709401709402\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.22008547008547008\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.22115384615384615\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2222222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2232905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.22435897435897437\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.22542735042735043\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2264957264957265\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.22756410256410256\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.22863247863247863\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2297008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.23076923076923078\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.23183760683760685\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2329059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.23397435897435898\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.23504273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2361111111111111\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.23717948717948717\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.23824786324786323\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.23931623931623933\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2403846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.24145299145299146\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.24252136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.24358974358974358\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.24465811965811965\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.24572649572649571\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2467948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.24786324786324787\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.24893162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.25\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.25106837606837606\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.25213675213675213\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2532051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.25427350427350426\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2553418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2564102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.25747863247863245\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.25854700854700857\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.25961538461538464\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2606837606837607\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.26175213675213677\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.26282051282051283\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2638888888888889\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.26495726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.266025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2670940170940171\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.26816239316239315\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2692307692307692\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2702991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.27136752136752135\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2724358974358974\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.27350427350427353\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2745726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.27564102564102566\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2767094017094017\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2777777777777778\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.27884615384615385\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2799145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.280982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.28205128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2831196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2841880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.28525641025641024\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2863247863247863\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.28739316239316237\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.28846153846153844\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.28952991452991456\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2905982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2916666666666667\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.29273504273504275\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2938034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2948717948717949\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.29594017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.297008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.2980769230769231\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.29914529914529914\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3002136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.30128205128205127\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.30235042735042733\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3034188034188034\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.30448717948717946\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3055555555555556\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.30662393162393164\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3076923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3087606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.30982905982905984\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3108974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.31196581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.31303418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3141025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.31517094017094016\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3162393162393162\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3173076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.31837606837606836\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3194444444444444\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.32051282051282054\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3215811965811966\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.32264957264957267\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.32371794871794873\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3247863247863248\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.32585470085470086\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3269230769230769\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.327991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.32905982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3301282051282051\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3311965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.33226495726495725\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3333333333333333\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3344017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.33547008547008544\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.33653846153846156\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.33760683760683763\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3386752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.33974358974358976\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3408119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3418803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.34294871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.344017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3450854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.34615384615384615\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3472222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3482905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.34935897435897434\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3504273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.35149572649572647\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3525641025641026\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.35363247863247865\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3547008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3557692307692308\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.35683760683760685\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3579059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.358974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.36004273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3611111111111111\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.36217948717948717\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.36324786324786323\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3643162393162393\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.36538461538461536\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.36645299145299143\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.36752136752136755\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3685897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3696581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.37072649572649574\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3717948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.37286324786324787\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.37393162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.375\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.37606837606837606\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.37713675213675213\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3782051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.37927350427350426\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3803418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3814102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.38247863247863245\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.38354700854700857\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.38461538461538464\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3856837606837607\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.38675213675213677\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.38782051282051283\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3888888888888889\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.38995726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.391025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3920940170940171\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.39316239316239315\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3942307692307692\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3952991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.39636752136752135\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3974358974358974\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.39850427350427353\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.3995726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.40064102564102566\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4017094017094017\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4027777777777778\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.40384615384615385\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4049145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.405982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.40705128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4081196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4091880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.41025641025641024\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4113247863247863\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.41239316239316237\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.41346153846153844\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.41452991452991456\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4155982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4166666666666667\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.41773504273504275\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4188034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4198717948717949\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.42094017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.422008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4230769230769231\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.42414529914529914\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4252136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.42628205128205127\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.42735042735042733\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4284188034188034\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.42948717948717946\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4305555555555556\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.43162393162393164\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4326923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4337606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.43482905982905984\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4358974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.43696581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.43803418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4391025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.44017094017094016\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4412393162393162\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4423076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.44337606837606836\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4444444444444444\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.44551282051282054\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4465811965811966\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.44764957264957267\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.44871794871794873\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4497863247863248\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.45085470085470086\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4519230769230769\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.452991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.45405982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4551282051282051\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4561965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.45726495726495725\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4583333333333333\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4594017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.46047008547008544\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.46153846153846156\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.46260683760683763\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4636752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.46474358974358976\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4658119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4668803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.46794871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.469017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4700854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.47115384615384615\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4722222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4732905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.47435897435897434\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4754273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.47649572649572647\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4775641025641026\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.47863247863247865\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4797008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4807692307692308\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.48183760683760685\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4829059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.483974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.48504273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4861111111111111\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.48717948717948717\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.48824786324786323\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4893162393162393\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.49038461538461536\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.49145299145299143\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.49252136752136755\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4935897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4946581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.49572649572649574\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.4967948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.49786324786324787\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.49893162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5010683760683761\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5021367521367521\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5032051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5042735042735043\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5053418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5064102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5074786324786325\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5085470085470085\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5096153846153846\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5106837606837606\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5117521367521367\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5128205128205128\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5138888888888888\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5149572649572649\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5160256410256411\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5170940170940171\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5181623931623932\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5192307692307693\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5202991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5213675213675214\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5224358974358975\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5235042735042735\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5245726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5256410256410257\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5267094017094017\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5277777777777778\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5288461538461539\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5299145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.530982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.532051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5331196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5341880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5352564102564102\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5363247863247863\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5373931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5384615384615384\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5395299145299145\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5405982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5416666666666666\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5427350427350427\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5438034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5448717948717948\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5459401709401709\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5470085470085471\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5480769230769231\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5491452991452992\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5502136752136753\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5512820512820513\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5523504273504274\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5534188034188035\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5544871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5555555555555556\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5566239316239316\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5576923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5587606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5598290598290598\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5608974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.561965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.563034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5641025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5651709401709402\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5662393162393162\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5673076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5683760683760684\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5694444444444444\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5705128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5715811965811965\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5726495726495726\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5737179487179487\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5747863247863247\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5758547008547008\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5769230769230769\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5779914529914529\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5790598290598291\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5801282051282052\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5811965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5822649572649573\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5833333333333334\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5844017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5854700854700855\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5865384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5876068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5886752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5897435897435898\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5908119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5918803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.592948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.594017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5950854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5961538461538461\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5972222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5982905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.5993589743589743\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6004273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6014957264957265\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6025641025641025\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6036324786324786\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6047008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6057692307692307\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6068376068376068\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6079059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6089743589743589\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6100427350427351\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6111111111111112\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6121794871794872\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6132478632478633\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6143162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6153846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6164529914529915\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6175213675213675\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6185897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6196581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6207264957264957\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6217948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6228632478632479\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6239316239316239\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.625\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6260683760683761\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6271367521367521\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6282051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6292735042735043\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6303418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6314102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6324786324786325\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6335470085470085\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6346153846153846\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6356837606837606\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6367521367521367\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6378205128205128\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6388888888888888\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6399572649572649\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6410256410256411\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6420940170940171\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6431623931623932\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6442307692307693\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6452991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6463675213675214\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6474358974358975\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6485042735042735\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6495726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6506410256410257\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6517094017094017\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6527777777777778\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6538461538461539\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6549145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.655982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.657051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6581196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6591880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6602564102564102\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6613247863247863\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6623931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6634615384615384\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6645299145299145\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6655982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6666666666666666\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6677350427350427\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6688034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6698717948717948\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6709401709401709\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6720085470085471\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6730769230769231\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6741452991452992\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6752136752136753\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6762820512820513\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6773504273504274\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6784188034188035\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6794871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6805555555555556\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6816239316239316\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6826923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6837606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6848290598290598\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6858974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.686965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.688034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6891025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6901709401709402\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6912393162393162\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6923076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6933760683760684\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6944444444444444\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6955128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6965811965811965\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6976495726495726\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6987179487179487\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.6997863247863247\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7008547008547008\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7019230769230769\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7029914529914529\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7040598290598291\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7051282051282052\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7061965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7072649572649573\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7083333333333334\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7094017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7104700854700855\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7115384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7126068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7136752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7147435897435898\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7158119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7168803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.717948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.719017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7200854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7211538461538461\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7222222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7232905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7243589743589743\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7254273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7264957264957265\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7275641025641025\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7286324786324786\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7297008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7307692307692307\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7318376068376068\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7329059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7339743589743589\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7350427350427351\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7361111111111112\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7371794871794872\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7382478632478633\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7393162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7403846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7414529914529915\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7425213675213675\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7435897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7446581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7457264957264957\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7467948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7478632478632479\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7489316239316239\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.75\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7510683760683761\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7521367521367521\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7532051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7542735042735043\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7553418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7564102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7574786324786325\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7585470085470085\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7596153846153846\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7606837606837606\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7617521367521367\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7628205128205128\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7638888888888888\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7649572649572649\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7660256410256411\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7670940170940171\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7681623931623932\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7692307692307693\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7702991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7713675213675214\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7724358974358975\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7735042735042735\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7745726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7756410256410257\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7767094017094017\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7777777777777778\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7788461538461539\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7799145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.780982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.782051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7831196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7841880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7852564102564102\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7863247863247863\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7873931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7884615384615384\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7895299145299145\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7905982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7916666666666666\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7927350427350427\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7938034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7948717948717948\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7959401709401709\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7970085470085471\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7980769230769231\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.7991452991452992\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8002136752136753\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8012820512820513\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8023504273504274\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8034188034188035\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8044871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8055555555555556\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8066239316239316\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8076923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8087606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8098290598290598\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8108974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.811965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.813034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8141025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8151709401709402\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8162393162393162\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8173076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8183760683760684\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8194444444444444\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8205128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8215811965811965\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8226495726495726\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8237179487179487\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8247863247863247\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8258547008547008\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8269230769230769\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8279914529914529\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8290598290598291\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8301282051282052\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8311965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8322649572649573\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8333333333333334\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8344017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8354700854700855\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8365384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8376068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8386752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8397435897435898\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8408119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8418803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.842948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.844017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8450854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8461538461538461\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8472222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8482905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8493589743589743\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8504273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8514957264957265\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8525641025641025\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8536324786324786\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8547008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8557692307692307\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8568376068376068\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8579059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8589743589743589\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8600427350427351\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8611111111111112\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8621794871794872\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8632478632478633\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8643162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8653846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8664529914529915\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8675213675213675\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8685897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8696581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8707264957264957\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8717948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8728632478632479\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8739316239316239\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.875\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8760683760683761\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8771367521367521\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8782051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8792735042735043\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8803418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8814102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8824786324786325\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8835470085470085\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8846153846153846\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8856837606837606\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8867521367521367\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8878205128205128\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8888888888888888\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8899572649572649\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8910256410256411\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8920940170940171\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8931623931623932\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8942307692307693\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8952991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8963675213675214\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8974358974358975\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8985042735042735\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.8995726495726496\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9006410256410257\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9017094017094017\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9027777777777778\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9038461538461539\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9049145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.905982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.907051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9081196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9091880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9102564102564102\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9113247863247863\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9123931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9134615384615384\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9145299145299145\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9155982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9166666666666666\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9177350427350427\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9188034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9198717948717948\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9209401709401709\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9220085470085471\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9230769230769231\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9241452991452992\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9252136752136753\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9262820512820513\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9273504273504274\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9284188034188035\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9294871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9305555555555556\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9316239316239316\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9326923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9337606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9348290598290598\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9358974358974359\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.936965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.938034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9391025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9401709401709402\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9412393162393162\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9423076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9433760683760684\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9444444444444444\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9455128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9465811965811965\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9476495726495726\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9487179487179487\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9497863247863247\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9508547008547008\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9519230769230769\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9529914529914529\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9540598290598291\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9551282051282052\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9561965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9572649572649573\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9583333333333334\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9594017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9604700854700855\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9615384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9626068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9636752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9647435897435898\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9658119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9668803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.967948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.969017094017094\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9700854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9711538461538461\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9722222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9732905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9743589743589743\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9754273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9764957264957265\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9775641025641025\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9786324786324786\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9797008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9807692307692307\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9818376068376068\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9829059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9839743589743589\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9850427350427351\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9861111111111112\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9871794871794872\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9882478632478633\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9893162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9903846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9914529914529915\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9925213675213675\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9935897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9946581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9957264957264957\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9967948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9978632478632479\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.9989316239316239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1/1 [00:00<00:00, 41.59it/s, loss=0.378]\n",
      "Epoch 2/50: 100%|██████████| 1/1 [00:00<00:00, 40.00it/s, loss=0.165]\n",
      "Epoch 3/50: 100%|██████████| 1/1 [00:00<00:00, 42.98it/s, loss=0.439]\n",
      "Epoch 4/50: 100%|██████████| 1/1 [00:00<00:00, 42.28it/s, loss=0.26]\n",
      "Epoch 5/50: 100%|██████████| 1/1 [00:00<00:00, 41.10it/s, loss=0.0126]\n",
      "Epoch 6/50: 100%|██████████| 1/1 [00:00<00:00, 40.57it/s, loss=0.0515]\n",
      "Epoch 7/50: 100%|██████████| 1/1 [00:00<00:00, 43.05it/s, loss=0.189]\n",
      "Epoch 8/50: 100%|██████████| 1/1 [00:00<00:00, 42.41it/s, loss=0.0438]\n",
      "Epoch 9/50: 100%|██████████| 1/1 [00:00<00:00, 42.56it/s, loss=0.0687]\n",
      "Epoch 10/50: 100%|██████████| 1/1 [00:00<00:00, 41.98it/s, loss=0.0879]\n",
      "Epoch 11/50: 100%|██████████| 1/1 [00:00<00:00, 32.80it/s, loss=0.0926]\n",
      "Epoch 12/50: 100%|██████████| 1/1 [00:00<00:00, 41.05it/s, loss=0.0162]\n",
      "Epoch 13/50: 100%|██████████| 1/1 [00:00<00:00, 43.21it/s, loss=0.047]\n",
      "Epoch 14/50: 100%|██████████| 1/1 [00:00<00:00, 41.04it/s, loss=0.104]\n",
      "Epoch 15/50: 100%|██████████| 1/1 [00:00<00:00, 42.09it/s, loss=0.0549]\n",
      "Epoch 16/50: 100%|██████████| 1/1 [00:00<00:00, 44.12it/s, loss=0.159]\n",
      "Epoch 17/50: 100%|██████████| 1/1 [00:00<00:00, 46.04it/s, loss=0.0396]\n",
      "Epoch 18/50: 100%|██████████| 1/1 [00:00<00:00, 39.19it/s, loss=0.0258]\n",
      "Epoch 19/50: 100%|██████████| 1/1 [00:00<00:00, 41.60it/s, loss=0.103]\n",
      "Epoch 20/50: 100%|██████████| 1/1 [00:00<00:00, 40.84it/s, loss=0.0388]\n",
      "Epoch 21/50: 100%|██████████| 1/1 [00:00<00:00, 42.84it/s, loss=0.0297]\n",
      "Epoch 22/50: 100%|██████████| 1/1 [00:00<00:00, 41.76it/s, loss=0.0223]\n",
      "Epoch 23/50: 100%|██████████| 1/1 [00:00<00:00, 41.74it/s, loss=0.0216]\n",
      "Epoch 24/50: 100%|██████████| 1/1 [00:00<00:00, 39.92it/s, loss=0.0347]\n",
      "Epoch 25/50: 100%|██████████| 1/1 [00:00<00:00, 41.10it/s, loss=0.0495]\n",
      "Epoch 26/50: 100%|██████████| 1/1 [00:00<00:00, 43.21it/s, loss=0.196]\n",
      "Epoch 27/50: 100%|██████████| 1/1 [00:00<00:00, 43.69it/s, loss=0.0315]\n",
      "Epoch 28/50: 100%|██████████| 1/1 [00:00<00:00, 40.55it/s, loss=0.188]\n",
      "Epoch 29/50: 100%|██████████| 1/1 [00:00<00:00, 38.95it/s, loss=0.0224]\n",
      "Epoch 30/50: 100%|██████████| 1/1 [00:00<00:00, 41.92it/s, loss=0.0283]\n",
      "Epoch 31/50: 100%|██████████| 1/1 [00:00<00:00, 32.71it/s, loss=0.0146]\n",
      "Epoch 32/50: 100%|██████████| 1/1 [00:00<00:00, 39.79it/s, loss=0.0113]\n",
      "Epoch 33/50: 100%|██████████| 1/1 [00:00<00:00, 39.61it/s, loss=0.00454]\n",
      "Epoch 34/50: 100%|██████████| 1/1 [00:00<00:00, 39.58it/s, loss=0.0732]\n",
      "Epoch 35/50: 100%|██████████| 1/1 [00:00<00:00, 41.65it/s, loss=0.0206]\n",
      "Epoch 36/50: 100%|██████████| 1/1 [00:00<00:00, 42.71it/s, loss=0.00553]\n",
      "Epoch 37/50: 100%|██████████| 1/1 [00:00<00:00, 41.45it/s, loss=0.0231]\n",
      "Epoch 38/50: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, loss=0.00367]\n",
      "Epoch 39/50: 100%|██████████| 1/1 [00:00<00:00, 42.29it/s, loss=0.0829]\n",
      "Epoch 40/50: 100%|██████████| 1/1 [00:00<00:00, 41.72it/s, loss=0.00352]\n",
      "Epoch 41/50: 100%|██████████| 1/1 [00:00<00:00, 45.50it/s, loss=0.0125]\n",
      "Epoch 42/50: 100%|██████████| 1/1 [00:00<00:00, 37.26it/s, loss=0.00653]\n",
      "Epoch 43/50: 100%|██████████| 1/1 [00:00<00:00, 41.06it/s, loss=0.00547]\n",
      "Epoch 44/50: 100%|██████████| 1/1 [00:00<00:00, 44.62it/s, loss=0.00631]\n",
      "Epoch 45/50: 100%|██████████| 1/1 [00:00<00:00, 44.11it/s, loss=0.0252]\n",
      "Epoch 46/50: 100%|██████████| 1/1 [00:00<00:00, 41.77it/s, loss=0.0023]\n",
      "Epoch 47/50: 100%|██████████| 1/1 [00:00<00:00, 44.79it/s, loss=0.0023]\n",
      "Epoch 48/50: 100%|██████████| 1/1 [00:00<00:00, 41.44it/s, loss=0.0134]\n",
      "Epoch 49/50: 100%|██████████| 1/1 [00:00<00:00, 43.65it/s, loss=0.0501]\n",
      "Epoch 50/50: 100%|██████████| 1/1 [00:00<00:00, 41.82it/s, loss=0.003]\n",
      "79it [00:01, 51.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for acq_fn MI at acq-step 10 is 72.77215189873418\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0010683760683760685\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.002136752136752137\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.003205128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.004273504273504274\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.005341880341880342\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.00641025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.007478632478632479\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.008547008547008548\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.009615384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.010683760683760684\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.011752136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.01282051282051282\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.013888888888888888\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.014957264957264958\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.016025641025641024\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.017094017094017096\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.018162393162393164\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.019230769230769232\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0202991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.021367521367521368\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.022435897435897436\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.023504273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.024572649572649572\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.02564102564102564\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.026709401709401708\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.027777777777777776\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.028846153846153848\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.029914529914529916\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.030982905982905984\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03205128205128205\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03311965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03418803418803419\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.035256410256410256\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03632478632478633\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03739316239316239\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.038461538461538464\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.03952991452991453\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0405982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.041666666666666664\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.042735042735042736\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0438034188034188\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.04487179487179487\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.045940170940170943\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.04700854700854701\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.04807692307692308\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.049145299145299144\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.050213675213675216\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05128205128205128\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05235042735042735\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.053418803418803416\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05448717948717949\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05555555555555555\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.056623931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.057692307692307696\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05876068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.05982905982905983\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.060897435897435896\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06196581196581197\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06303418803418803\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0641025641025641\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06517094017094018\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06623931623931624\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0673076923076923\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06837606837606838\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.06944444444444445\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07051282051282051\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07158119658119658\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07264957264957266\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07371794871794872\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07478632478632478\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07585470085470085\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07692307692307693\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07799145299145299\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.07905982905982906\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08012820512820513\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0811965811965812\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08226495726495726\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08333333333333333\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08440170940170941\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08547008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08653846153846154\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.0876068376068376\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08867521367521368\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.08974358974358974\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09081196581196581\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09188034188034189\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09294871794871795\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09401709401709402\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09508547008547008\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09615384615384616\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09722222222222222\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09829059829059829\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.09935897435897435\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10042735042735043\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1014957264957265\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10256410256410256\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10363247863247864\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1047008547008547\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10576923076923077\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10683760683760683\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10790598290598291\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.10897435897435898\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11004273504273504\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.1111111111111111\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11217948717948718\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11324786324786325\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11431623931623931\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11538461538461539\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11645299145299146\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11752136752136752\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11858974358974358\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.11965811965811966\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12072649572649573\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12179487179487179\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12286324786324786\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12393162393162394\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.125\n",
      "Calculating MI\n",
      "MI calc done\n",
      "Progress: 0.12606837606837606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m acquisition_fns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_w_acquisition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macq_fn_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macq_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_acq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m test_model(model)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy for acquisition function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 13\u001b[0m, in \u001b[0;36mtrain_w_acquisition\u001b[0;34m(T, base_model, train_dataset, train_indices, pool_indices, acq_fn_name, acq_fn, n_acq, n_epochs, acq_batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m pool_data \u001b[38;5;241m=\u001b[39m DataLoader(Subset(train_dataset, pool_indices_copy), batch_size \u001b[38;5;241m=\u001b[39m acq_batch_size, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)    \u001b[38;5;66;03m# gets data from pool from which we will acquire new xs\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x_batch,_) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pool_data):\n\u001b[0;32m---> 13\u001b[0m     acq_values \u001b[38;5;241m=\u001b[39m acq_fn(\u001b[43mget_TNC_preds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Helps with memory\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(acq_values, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m, in \u001b[0;36mget_TNC_preds\u001b[0;34m(x, model, T)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#print(f\"x_batch shape: {x_batch.shape}\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#x_batch = x_tiled.reshape(T*N, -1)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m output_TNC \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mreshape(T,N,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_TNC\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[47], line 43\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 43\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Oxford/UDL/Mini Project/Code/local_copy/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key, value in acquisition_fns.items():\n",
    "    model = train_w_acquisition(T=100, base_model=base_model, train_dataset = train_dataset, train_indices = train_indices, pool_indices=pool_indices, acq_fn_name = key, acq_fn = value, n_acq=100, n_epochs = 50)\n",
    "    accuracy = test_model(model)\n",
    "\n",
    "    print(f\"Test accuracy for acquisition function: {key} = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_acquisition_curves(acq_names, database, file_name='acquisition_curves.png'):\n",
    "    \"\"\"\n",
    "    Draws the acquisition step number vs. accuracy for specified acquisition functions \n",
    "    on a single graph using Matplotlib.\n",
    "\n",
    "    Args:\n",
    "        acq_names (list): List of acquisition function names (keys in the database).\n",
    "        database (dict): Dictionary storing the results: \n",
    "                         database[name] = [[step_0, acc_0], [step_1, acc_1], ...]\n",
    "        file_name (str): Name of the file to save the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if not database:\n",
    "        print(\"Error: The database is empty or None.\")\n",
    "        return\n",
    "\n",
    "    all_data_found = False\n",
    "\n",
    "    for name in acq_names:\n",
    "        if name in database and database[name]:\n",
    "            # Extract data for given acquisition function\n",
    "            data_array = np.array(database[name])\n",
    "            \n",
    "            steps = data_array[:, 0]\n",
    "            accuracies = data_array[:, 1]\n",
    "            \n",
    "            plt.plot(steps, accuracies, marker='o', linestyle='-', label=name)\n",
    "            all_data_found = True\n",
    "        else:\n",
    "            print(f\"Warning: Data not found for acquisition function '{name}'. Skipping.\")\n",
    "\n",
    "    if all_data_found:\n",
    "        plt.title('Accuracy vs. Acquisition Step for Active Learning Strategies')\n",
    "        plt.xlabel('Acquisition Step Number')\n",
    "        plt.ylabel('Test Accuracy')\n",
    "        plt.legend(title='Acquisition Function')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.plot()\n",
    "        plt.savefig(file_name)\n",
    "        plt.close()\n",
    "        print(f\"Plot saved successfully as {file_name}\")\n",
    "    else:\n",
    "        print(\"Error: No valid data found for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26332055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MI': [[10, 70.31645569620254], [20, 78.75949367088607], [30, 76.9493670886076], [40, 81.17721518987342], [50, 85.24050632911393], [60, 84.73417721518987], [70, 84.22784810126582], [80, 83.11392405063292], [90, 82.43037974683544], [100, 81.30379746835443], [110, 77.92405063291139], [120, 83.56962025316456], [130, 80.12658227848101], [140, 81.0379746835443], [150, 85.41772151898734], [160, 84.65822784810126], [170, 82.16455696202532], [180, 85.37974683544304], [190, 84.35443037974683], [200, 84.12658227848101]]}\n"
     ]
    }
   ],
   "source": [
    "print(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805fe5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Data not found for acquisition function 'entropy'. Skipping.\n",
      "Plot saved successfully as acquisition_curves.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAAJYCAYAAADxHswlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAADyJUlEQVR4nOydB1gUV9fHD70XERAUEMFewN5LojFq1KhpxhRNbyamty/VlDevedM1MW/yJppEE1PsmpiiMbF3wV4QVFSkKEU6LN/zvzCbZVlwgV127sz5Pc+6y+w4c+/8Z2bn3HPuOU4VFRUVxDAMwzAMwzAMwzCMQ3F27O4ZhmEYhmEYhmEYhgFsoDMMwzAMwzAMwzCMCmADnWEYhmEYhmEYhmFUABvoDMMwDMMwDMMwDKMC2EBnGIZhGIZhGIZhGBXABjrDMAzDMAzDMAzDqAA20BmGYRiGYRiGYRhGBbCBzjAMwzAMwzAMwzAqgA10hmEYhmEYhmEYhlEBbKAzDMMwDMMwDMMwjApgA51hGIZhGIZhGIZhVAAb6AzDMAzDMAzDMAyjAthAZxiGYRiGYRiGYRgVwAY6wzAMwzAMwzAMw6gANtAZhmEYKYiOjqY77rijXv/n1VdfJScnJ6vWnT9/vlg3JSWlgS3UB2VlZfTMM89QZGQkOTs708SJE0krQH+cM4ztry+m8fA9imH0ARvoDMPYhU8++UQ8SPTr18/RTWHqwaFDh4Runp6elJ2dTVrkX//6Fy1btozURElJCX344YfUo0cP8vf3p8DAQOrSpQvdd999dPjwYeN6mzdvFkaRI7X58ssv6T//+Q/dcMMN9NVXX9Hjjz/eZPvu27evOD/nzp3b4G38/PPPqjPC0aeHH37Y0c2QjpUrV9KwYcMoNDSUvL29KSYmhm666SZas2aNcZ2zZ88Kvffu3WuXNnz77bf0wQcf2GXbDMPoE6eKiooKRzeCYRjtMWjQIPFghJH+Y8eOUdu2bR3dJMYKXnjhBWGAXbx4kebMmUP33HMPqYXi4mLhsXVzc6uXtxcvDDgo+Pr6CuMS3ihTysvLqbS0lDw8PJrcKzh+/Hj65ZdfaMqUKTRgwADRDhjmq1atotdff90YOfDOO+/Q008/TcnJySKiwBHcfPPNtHHjRkpNTW3S/eI+0r59e9HvVq1aiTY0BBjCH3/8MVl6/CkqKiJXV1fxakpwvk2fPl1cczJh6fpqKpRrAQb6hAkThIF+/Phx+uOPPyg+Pt54fe/cuZP69OlD8+bNq3cEjjWMGzeO9u/f3yRebUfeoxiGaTqa9heIYRhdAOMBnr4lS5bQ/fffTwsXLqRXXnmF1Eh+fj75+Pg4uhmqAAYLvEG33HKL0BC6qclAx0NpfamPseXi4iJeTc2OHTuEIf7mm2/S//3f/1X7Dgab2iIZ0tPThYffVhgMBhFBcDkjb8GCBcJT+u6774oBFhhEth6kcIShqSYKCgqEoWstjhjMABgUwMDVyJEj6bfffrN4jjbVMWhKHHWPYhimaeEQd4ZhbA4Mu2bNmtHYsWPFgzT+tgQMD4TH4iEbxldERARNnTqVMjMzq3m0EJ4IzxkensPDw+m6666jpKQk8f369euFJwHvpuDhHctNvaTwnsB7iv97zTXXkJ+fH916663iuw0bNtCNN95IUVFRoi2YX4u2FRYW1mg3PJsIowwJCSEvLy/q0KGD8DyDP//8U+x36dKlNf4fjF98t2XLFovHA54efI+wYXN+/fVX8R0MOZCXl0ePPfaY8djBcMHD6u7du6mhbNq0SRw3eEjx+vvvvy16SWFQIRy7W7duQhMch9GjR4v2m3q7cfzwHY7ztddeK7ZlPscXmlgysizNbTWfgw5P0syZM6ldu3aiHc2bN6fBgwfT77//Xut28BmDMjjG+IyXss3a5ndiugbCzXGcW7ZsKTyd5kbzFVdcQV27dqWDBw/SlVdeKR7w4eV9++23L3vclXMZUSfm4GEc/VL6Ao8haNOmjbH9pu2FEdurVy9xXgYFBQkdT58+bbGtu3btooEDB4p1sb1PP/20znYq1xTO8QMHDhj3r1x7OK5PPvmkuHZwrHBdwMtp7qlWwrlxX1COq2lIcm3g+sH9BB7LgIAA8bcltm3bJq5v3IMw+BYXFyfOVwCt4T1X2qG8TNumnJ8//fST+Puvv/6qsY///ve/4jt4Tk3vC2gfjjvOx969e9OKFSvIVuC6Qyg1jhm236JFCzEAimgXU5YvXy7uvThXcWxjY2OFMQvva23nwdChQ8U5iwEiRWdo99lnn4n/j+3AC43BpMtdp4q+mEaC7eP/os2WNMa5g+OE/mA/OK7WzGvHb0Rubq7FawbgfqhsH+0Gd955p1Fv5XehtmNg7XHE/1+9ejWdPHnSuG3T+xnugxicRgSZ8ruC/A1Ybgp+Z2bMmEHBwcHG++WZM2dq3C9ru0ch+mbIkCHifMf/R7txjZqSlpYmjgF+Z9EW/JYi8oDnszOM+mAPOsMwNgcP3jCi3d3dRcgu5oviwU55UAKXLl0SDxSY83zXXXdRz549xUMXHmhhyOFBBQ9CeBhfu3atMDQeffRRYZjCAMODMR6YGuJ5GTVqlDDk8ACqeEp+/PFH4Tl58MEHhUG0fft2mj17tmgLvlNITEwU7UaYNeYH42EMBhbmQsIDigc2PIThGEyaNKnGcUGbEcJsCTyoYg7lDz/8QNOmTav23ffffy8MDrQdPPDAA8KAwINw586dKSsrS4T84njiWDYEpX3QCQ+tODbfffed0ShUuPvuu8WD4pgxY4SHHccUAxxbt24VfQBYDmMR3ngYgevWrRMPjbYED65vvfWW2BfmJuOBHYMEGKTAYIUlvvnmG+P60A/UdR5hHxgEuOqqq8S5ceTIEeP5jAEN03B7GEoYqMC5jwEc6PPss8+KgQwcq9po3bq18fjD4KjNI4ntHj16VGjy/vvvi2sEYBAE4Px76aWXxL7Rx4yMDHEOw/DYs2dPNa832gojFuviGsU5h/7hmsX1aAnsB8cP+8H1i2MPOnXqJIxwGBUw3nF+dO/eXQwq4dyBoYH2moLzAfvE+Yt+XM4TDqMb4csIU0YbcSxwvMwjDnBvwD0DxgfuF2FhYeKawMAW/oZBi6k3WA99qQucrxjQQzsRRm1+PcLoxHUCYAxBOwzKPPfcc8JQwv9DAr3FixfXuBc0BLQd1x2MLBhziHJBhAW0NT0XsQ7a/cQTT4h3HOuXX35ZXB/IHWAK7hs4N3F/ve2224TRr4ABENxvsV8YhRhswnE/ceLEZaeZ4F6ECKqHHnpIGIwfffQRXX/99XTq1CnjgBPajesFWuEaw/3+tddeM57PdQEDHANLuO8+8sgjYlDEEjg3sU30H9c77t0A96TLHQNrjiMGZnNycsTvhHKOY11lQAXXBI4F9o227Nu3T6yH69g0DwYGjnC+3H777dS/f38xKGTt/RLnMX4v8Nswa9Ys8TuGexR+43CMlWsLxx/nKY4XliHKANcBNHHUdBmGYWoBc9AZhmFsxc6dO+Euq/j999/F3waDoSIiIqLi0Ucfrbbeyy+/LNZbsmRJjW3g/4Avv/xSrPPee+/Vus6ff/4p1sG7KcnJyWL5vHnzjMumTZsmlj333HM1tldQUFBj2VtvvVXh5ORUcfLkSeOyoUOHVvj5+VVbZtoe8Pzzz1d4eHhUZGdnG5elp6dXuLq6VrzyyisVdYH/6+bmVnHhwgXjsuLi4orAwMCKu+66y7gsICCgYvr06RW2oqSkpKJ58+YVL7zwgnHZLbfcUhEfH19tvXXr1oljOGPGjBrbUI7B3r17xToPPfRQte+xPSw3PQbQpHXr1jW2hXXMf6KwHtZXQNvGjh1bZ78sbcfHx6fadhRwrmBdnDuKZu7u7hVXX311RXl5uXG9OXPmiPVwfioMGzZMLPv666+r6RYWFlZx/fXX19lGHDfl/7do0aJiypQpFR9//HGNcwz85z//qdZGhZSUlAoXF5eKN998s9ryffv2ifPOdLmyr3fffbdaW7t3714RGhoqzoW6wP/v0qVLtWXLli0T23zjjTeqLb/hhhvENXT8+HHjMqzn7OxcceDAgQprefjhhysiIyON59hvv/0mtrNnzx7jOmVlZRVt2rQR58nFixdrvT5x3dT2+GN+fkILHBNsW+HcuXOi/a+99ppx2YgRIyq6detWUVRUVG2fAwcOrGjXrt1l+4f91nU9b9iwQayzcOHCasvXrFlTY7mle9n9999f4e3tXa19ynnw6aefWrx34n5geh9avny5WL5y5co6ry/8jevGVPOEhASxfPbs2cZl48ePF206c+aMcdmxY8fE+WrN46nyG4LrecyYMeIc37VrV431duzYUeO34HLHoD7HEfcgS/ewb775Rpwn0M4U7Av73LRpk/gbbcbfjz32WLX17rjjjhrno/k9Ki8vT/w23HvvvdX+b1pamviNUJbjesD/w/2DYRj1wyHuDMPYFHi14IFAmC+A52Xy5Mm0aNGiaqGB8CohkY8lz5IS3oh14F3DiH9t6zQEeArNgTdGAaG68ObDy4LnTXghADySCPuGhxGh8LW1B2H6CGGEB9XU4wZPMzw0dYFjhdBteJ8UMMcSIdX4TgHeUHgV4Q20BQiRhCcJ3lQFfE5ISKgWKglN0FdLOQWUY4As2QBePlMQkm9LcAzQNiQPswdINoW50Wg3ktMp3HvvvSLTOkJbTYHnzFRfeHrhqYfHsS5w3OBtfuONN0SUBDzkCKOHZx2aWzMHHecLPHbwiOPcVV7wIGMKADzbpsBLD8+oaVvxN7xqCPetL9Ac4fjmmiPkHdcQzi9T4JFG5Ic14LrB9YNjoZxjw4cPF15U0+kzuE7hVYZe5nPkG3q/wD5xTEyn0OC6xrFWrscLFy4I7yqOPTzOyrHH9QSvJs5PRBE0BkTxIKwfkSGm+mI6A847U31N72VKe+A5hmfVtCIAQKgzPPK19R3no4Lifb7c+QwQcWIamYJpBrhmlP+L3wJcX4gwQAi5AkLB64o2MQVed3j5UfkA1w+82TgeiCBC1IS11HYM6nMca9MMXvOOHTtW0wznLlA0U0L/EW1giqXfPXPgAcf9Afdq033gWkQFFWUf6AuucZzH5lMiGIZRH2ygMwxjM/DQBUMcxjkelBGSihceFM6fPy9C1RUQFq6Eh9YG1sE8VlsmIcK2MAfPHIT5IcwQoZJ44EWYpRLWihBGoDxcXq7deCBDmLip8YDPCF28XDZ7DFrg/8MgUcBnDFQoD3YA4aYI80c4PYxAhGJb8+BcGwhHxzxkPKwquuEBG2Hupv2AJnigri2kFGA+Jgxa89BxaGlLELqKh1PkJ0AYOcKpMQXBVqAfltqNB11MRVC+V8B5ZW4IwsCx5oEYxx0GBgwLDLrASMf5ooSBXw4YgTCEYYzj3DV9YZvmSbOgoXlyRBxH0JA5qTgW2CbCmU2BgaJ8bwrONWvBABUGx3CeK+cm7i+4z+A4wVg2nct/ueuzPiAEG4ax+fWIEH7leKE9OPaYXmB+7JWBrMYkLVP0xX0IgxLm+8B0A9PtY9AKA59oN4xirKMMHCn3MgWE5ON8toT5IKRirFtzPpv/X+X/K/8X7cW8a0v3w/pU/IBhiuk12C7OE0ypwUANqiIgf4k11HYM6nMca9MM2zDXSzlvFM2U+6X5NWHNcVAGJ/HbYL4fHA9lH7i/IPwdA2UYQMe0F/yGYF46wzDqg+egMwxjM+BFOnfunDDS8TIHht7VV19t033W5hkzT4ikgAcVU2+osi48U/CEYc4wDGQYL/B6wWhXDID6AC865rxibiK86ZifbW0JJXiuMM8XnhAYPJiXjwdR04EKeOvgzUEyOjyIYU4kHsDgSbXWA6WAOZWYy4kHWhh45sBLhfbYo6xPffUzBQ+ZMMqQzAnH4H//+5+Y34lkZ47IPl9bduX6VjPFnFzMh8WcUcxzhpGO+bB1DVThHMWxxAO4pXYo82LVgql38nIoA0Q45y2B+bpKxI6twf0CXl5cZ0gWiIFGzPf+17/+ZVxHuT889dRTxhwR5jS2zCT2YR4xYIoybxsDVhhYhEGJASwMkiEBG/Iy4N5mfi+rS4fGnM+2uhasBf3FPRwvzI9HEkhEGJnnDrCEpWNQ3+NoCayDgcP33nvP4vcYXG0sSjswDx3RMuaY3jMQWYKBC8x9R8QBBpSQRwK/24hCYBhGPbCBzjCMzcDDIx4ilSzJpsBwxEMujCc8EOGBxzQDsiWwDh6yEPJdW1IixatjHgZs7rGrCyTuQdIePNTBsFYwzQYO4DUFl2s3gIGF5ELw8MFThPabhqjXBdZD+CbCyeHtgAGN7Vky5BAWiRc8JQjthCFdXwMd2sA4R2IhJfGYApKivfjii8IoQdIhaIKHOwxm1OZFR2g2HhyVCAjTbVnSz1IIt7X6oQ0IT8ULnkQY7YgmqMtAt3agQUnehnYr2gOEvcODizBee4JzBqHB8JIp4eq1tR26wPiBF07x0NUFvPTmJQZxDYCGJIzCsULIMkKBTb3oSiiwcizrC9qIARhcE8iQbg5C6nHfgYGuRGzg+qxLm/oONGHfuDcgAgjRCDjOpteycm5AL3udE+gbji8S0dVlVCOEGaH1uKZxLSjgfFUT+J2AwYvoA3MsLasPSFQJvTBYDBoysFif41jXNYkpQiNGjKizDcr9Ets2HSC15jgo5zyOpzXnHtbHtBO8cF9BJAjKFiKCimEY9cAh7gzD2AQYoXiYQQZlPEibvxCmi4d3pewQvIN4eLFUjkzxsmAdGCaWPM/KOni4gbcGc8NNgbfLWhRvj6l3B5+V0kymXio8rH355ZciJN5SexRg6MJQxoMPDAiEypobv7WBsGB4XhBKixcMcdOHRHiXzUMs8YCGEGPT8j04djCQMGeyLtBGGBnIDG+uG7yC8L4qnjtogr5iAMEc5RgoAwTI3GwKSkRZemBEX0xD0/Fgbem8MAcP0KagnfBUmpcwMgdGqTXzuvHAi9BX9MNU3y+++EK02VZZ6fGgbH4+AbQRJfkwiKF4SBWD2rz9yK6N8xi6mJ+L+Nv8WGFeN0pamQ464G/sB/N46wsywuO8NL9WEdEA46S+g0YKOA9gpGNOvqX7Cu43GMiC5higwgAFzjPz42N6TGo7hnWdBxgIUq5HhNqbhiPj2kP1Bhw/xSg0BeH5jQXRAzi+KPNlDrRU+mLpXgZt63M/bArQThxXeHNN82jAKDXPV2AJ3NNqK1ep/H9lcLC+eivts/Y4YvuWQt6hGaKwPv/8c4u/lzivgRJ1Yb5tVGC4HPi/8PIjogMD2bWdezhe5iH/uPdiMO1y90uGYZoe9qAzDGMTYHjDAEdZGUtgPi0e/mHowfuE+cJItoTa40i6BqMAXllsB152zMWGN/vrr78WnmiUPUNINx5q4EmC1xg1XDE/ENvAwwwMATx0oKRSfeZ8IqQd/w/GKB6o8MCDh35Lcy1hrMGTDGMApXPwoI45u0gYtnfv3mrrov2K18/Sg3Vd4BihpA+8TChbZRqWj+OM+c7YNo4TDFMcE5T+gjdEAcYSDDYkCoIBYQk8HON78+RepiG+eAhEwiP0HZ5KlALCZxiWGHiA9wfzQPEdBmLglUFIPh448eCKZHvwPlryCCEyACGjmOuJNiglguAFvlxNdyQZQ79w7sCAQok1pfRcXWB9HC+EnmJQAxoiT4I5OF+ff/55cQzRT5zb8KajX8gxcLmEf9aCgSrMnYURi3McfcF5CC8g9IHBqRgMivGM+eo4dvDaImwV5y+SzKG9OB8Rlo2Hb3jlYOTiXMX5rYB+Y0oE1sWxhuGJ8xd1ry9XQssSaAP0R7uwTZyXmHYA7zdCaxtSEhHgfoGyXKZlsUyBJjCAcP1hkALnDtqCcxBRFRjcwiAV5gIj8sP0GOJ8w7mNY2spQkUBxwPbxrQd3H9QntEcRA3hvoCBNSQRxIAXwuFhRGKaCzS+HDh/oaE5OMcRbo0kfghJhk6YKoR24RrEtYnBRNwPcJwwoIOyW+gf7okIf7ZXaHljQKQLzhFEBSBxpzLAgxwC5vdSc3CfQF/xu4JrE+HiMMBh8ONehPNfCdvGuYekgfhdwTUBgxrXe115EOpzHHE+4frB7xTuC7gf4xzEfRLTUzDwiXss+ok+4nzEcpyP8Pbj/2PgE9c5BtKUMmtKREtd3nf8VuGcx77wm4TzGPctDPjhmsA+cUyxLXjyMWiA+yZC33FfwDla17nPMIyDcHQaeYZhtAFK5nh6elbk5+fXug7KxqCEWGZmpvg7KytLlE9q1aqVKMuDcmwof6V8r5S6QekvlE/C/0XZKpRuSkpKMq6TkZEhSlmh/E2zZs1EKZz9+/dbLLOGkjyWOHjwYMVVV11V4evrWxEcHCzK0yilgczL82DbkyZNEuVt0OcOHTpUvPTSSzW2idJVaA/K3RQWFtbreKLcEPaN18aNG2ts9+mnnxZlxlDyDX3C508++aTaekoJJPMSdKag1BbWWbt2ba3rzJ8/X6yDMksAJadQrqdjx45Ct5CQEFHmyLTEEfqLUmwo1YT24fw4ffp0jbJBSsmsrl27im3hWC5YsMCqMmso6dW3b1+hg5eXl2gPSi2ZlgmztJ3Dhw+Lcnn4P/hO2aZ5CSPTsmrYNs4/lEF78MEHa5TxslR6rK4ycqacP3++4t///rfYRnh4uCgzhfNm+PDhFT/99FON9V9//XVxzaCEk3l7Fy9eXDF48GBxzPFCu1G+68iRIzXaipKIAwYMEOcw2oh+WkNtfUXJp8cff7yiZcuW4lihvBjOE9MSZ9aUFDM9LjgWt99+e63r4P6A6x7XowKul5EjRxqvjbi4uGrlvXD+PvLII+K8RQk40/PD0vkJUDYS32F9nMeWwD1p6tSp4h6F/kOjcePGWdTQHOVat/SC3gqfffZZRa9evcS5i/6htNszzzxTcfbsWeM6KN/Vv39/sQ60wPe//vprjXtBbToqZdYsleQyPz61lVmzpK/59Qtw3+nRo4e49mNjYyv+97//VTz55JPinKyL0tLSis8//7xi4sSJYrsoa4nzANtCu3GPNAX3rs6dOxtLuCn39NqOQX2O46VLl0QJSdyH8J3p9Y570axZs8Q+0EZc19Bv5syZFTk5Ocb18LuJYxYUFCR+g9AvXLPYHu4NCrXdo9CeUaNGid8aHDscS/ze4hoH+E3F9nE/wDWB9fr161fxww8/1HmcGYZxDE74x1GDAwzDMFoGoafwVMKbgrBoptIbhMzW8J4xjgEeWUx/sCaXAsM0NfB+27N8oiwgigBRAJiCdOuttzq6OQzDNCE8B51hGMZOINwScwBNE88xDMMw/8zFNgVG+c8//1zrlBy9HAeAkHdMbTLNP8IwjD7gOegMwzA2BpnnkfQM887hAbGm1A/DMIzewFx9lLLEOyo3YD41EjM+88wzpCdQk3zXrl0ijwPmhyPRHV7IHWGLcmwMw8gFG+gMwzA2Bg+ZCEtEoirUr2YYhmFqggRvKEWZlpYmElIOGDBAZCQ3LTemB5CUDmU9MaiLcpFRUVFiGhCSLjIMoz94DjrDMAzDMAzDMAzDqACeg84wDMMwDMMwDMMwKoANdIZhGIZhGIZhGIZRAbqcg24wGOjs2bPk5+cnSv4wDMMwDMMwDMMwTGPBDPK8vDxRahfVGOqLLg10GOecFZNhGIZhGIZhGIaxB6dPn6aIiAj5DfTy8nKRuRIZkJHVEyMPKMHx4osvVvN2Hzp0iJ599ln666+/qKysjDp37kyLFy8WmS8vBzznykHz9/e3a3+YxgN99+zZI8pVofwIIw+snZywbnLCuskLaycnrJu8sHZyUiaJbrm5ucIZrNic9UV1PZs1a5YoUfTVV19Rly5daOfOnXTnnXdSQEAAzZgxQ6yTlJREgwcPprvvvptmzpwpjOwDBw6Qp6enVftQDH38PzbQ5bgYfXx8hFZqvhiZmrB2csK6yQnrJi+snZywbvLC2slJmWS6NXQqtep6tnnzZpowYQKNHTtW/B0dHS1qZG7fvt24DupCXnPNNfT2228bl8XGxjqkvQzDMAzDMAzDMAyjySzuAwcOpLVr19LRo0fF3wkJCbRx40YaM2aMMcHb6tWrqX379jRq1CgKDQ2lfv360bJlyxzccsaeuLi4OLoJTANh7eSEdZMT1k1eWDs5Yd3khbWTExcd6OZUgTRzKgIG+P/93/8J7zgEwJz0N998k55//nnxPealh4eHk7e3N73xxht05ZVX0po1a8T/+fPPP2nYsGE1tllcXCxe5vMCsrKyjCHuyLCHF/aPl4KyHO0wPVS1LUebEc6AEAxLJxPWt2Y5wjawXdPl2C7WN29jbcu5T9wn7hP3ifvEfeI+cZ+4T9wn7hP3iftkaLI+wdZs3rw55eTkNGg6tepC3H/44QdauHAhffvtt2IO+t69e+mxxx4TyeKmTZtmPFAIg3/88cfF5+7du4vQ+E8//dSigf7WW2+JuermIMkA5jGAkJAQESafnJxMGRkZxnXCwsLEC/PekS5fAQY+Dvzhw4epqKjIuDwmJkYIsW/fvmonR4cOHcjNzY32799frQ1du3al0tJSOnLkiHEZTpZu3boJcU+cOGFcjjn2HTt2FAMLSHCngAQEaDsGL/BSCAoKEknzTp06RRcuXJC6T7hgcdHJ3CfkUejUqZOoIpCammpcXtu5h6yPeCGaBBe4adsROYI2FhYWGpdjn4GBgeK8Nu1TXFwcubu7i3wOpvTu3ZtKSkooMTGxWp/69Okj9odjpuDl5UXx8fGUmZlZra/W9Anf4ZhqqU9a1Mm0T61atRLX4Llz5zTTJy3qZKlPuE8hwqxFixaa6ZMWdbLUJ2iHe6WW+qRFnUz7hH1gCqZpGSXZ+6RFnSz1Cc9veC48duyYZvqkRZ3iLPQJ98r+/fuLd7X2KT8/nzTlQYdB9dxzz9H06dONy+ApR1Z3HGycYDCqX3nlFZHZXQEZ3REKv2nTpkZ70HFipKenGw8+RlgsHSZLy5VkAPZcbm1bbLVcDX2C7rhAZe0Tzq3WrVuLm4SeRh+h265du6hnz55iPS30SYs6mS/H5927d4ssqaahZDL3SYs6mbcd79CtV69e4n6phT5dbrlW+oT2QzvcK6GdFvqkRZ3M+4RlO3bsMP7GaaFPWtTJUp+wDow+U+1k75MWdXIxa7vyO4dBB7RfrX3SnAe9oKCg2kgkUA4ewA8XRkdMPZkAoxkwgCzh4eEhXuZARPMMgNj3+fPnxYGFBwKh9A3NwMfYBpzsOC9k1QLnLkbnMOgD779yIZtT23LTHw5rlteW1bI+y3GcLS2vb9uxTLkBmm5P9j5pUSfT5coPpLluMvfpcm3XSp+wL2UdrfTJmuWy9wm/c8q9Uvmdk71PjW27LH2y9BtXW9tl6ZMWdTJvC37natPO0voy9Kkhy2Xsk5OTk/Gl1j41NsO86gz08ePHiznnMGQQ4o5Qh/fee4/uuusu4zpPP/00TZ48mYYOHWqcg75y5Upav359o/eP0Y/s7GwRqoCRD8bxKCNhCB2X0UBXwmVgpOMHQQn3ZhiGYRiGYRiGUbWBPnv2bHrppZfooYceEh5HzD2///776eWXXzauM2nSJDHfHHPLURsd84YXL14saqM3FsxnAPDWMurB0giWTCjh+Rho0JOBjgEVhPXLOrCiV1g3OWHd5IW1kxPWTV5YOzlx0oluqpuD3hQgfB2JASzNC0DCCCQFaNOmjfDYMowt4POKYRiGYRiGYfRta1qD3G5JRhdgDAmRDTocS5IezL9HJIxpkg1G/bBucsK6yQtrJyesm7ywdnJi0IlubKBLCubbI7wD8+VttW50dDR98MEHpEZMs/Dbg1dffVWU62NsC26gKGmh9Rup1mDd5IR1kxfWTk5YN3lh7eTEoBPd2EBvIFu2bBHZ+saOHeuQ/Q8cOFDUKEb4RH3XnT9/vqg1aA5Khdx3331kT5TBAvOXack8e4P9LVu2rNqyp556itauXdtkbWAYhmEYhmEYhlF9kjhZ+OKLL+iRRx4R78jOjWR2TZ10LCwszKbrItN4U4EyeaZzMnx9fcmRYP+ObgPDMAzDMAzDMPqGPegN4NKlS/T999/Tgw8+KDzo8Eibg7JvqNeOhGDBwcEi87wC5k6gnByyECJp2MKFC6uFl6ekpAgv7969e43/B+HpWKaUkjMPWz958qTYZrNmzcjHx0eUqPv5559rrIvPd955p0haoHivEd5tKcT91KlTNGHCBGG4wpi+6aabRI1487Dwb775RvxfeOhvvvlmysvLu+wxRBk7DBooL+zDUig+jgEyuKemplbz/v/666/UqVMn8f9Gjx4tIgRM+fLLL8Ux8PDwoPDwcHr44YeNfQTQA/tS/jYPcUfozGuvvUYRERFiG/gO5fwUFI2WLFkiSv0h6398fLyIrGD+AccI54XWs21qDdZNTlg3eWHt5IR1kxfWTk6cdKIbG+gN4IcffqCOHTuK8m633XabMAZNE5itXr1aGIDXXHONqOOO0Om+ffsav7/jjjvo9OnT9Oeff9JPP/1En3zyiTDaG8P06dPFPO2///6b9u3bR7NmzbLoEUa4O4xwGNwwavFCeLc5MFBhnF+4cIH++usv+v3338WcD9SfNyUpKUmEi69atUq8sO6///1vsjWmNdALCgronXfeEQMD6C8GEkz7MHfuXHE8EK6PY7FixQpq27atMYwfzJs3T/Rd+ducDz/8kN59912xn8TERBo1ahRde+21dOzYsWrrvfDCC2LfGEho3749TZkyRdQ6ZyrBNBAMpOCdkQfWTU5YN3lh7eSEdZMX1k5OXHSiG4e4NwCEtcMwB/DewhsNw/SKK64Qy958803hSZ45c6bx/8C7Co4ePUq//PILbd++XXjYle3hZGsMMFKvv/566tatm/g7Jiam1nB3ZeSprrB3DCrAuEVpsMjISLHs66+/Fl5pGLVK22HIw6vt5+cn/r799tvF/8UxqAt4pk1BBEBdlJSUGAdBkNH9008/pdjYWPE3vOPwdiu88cYb9OSTT9Kjjz5qXKa0Vwnjhxe+rv7DMH/22WeFjgADHhhQweDGxx9/bFwPxrmShwB64/gcP35cDOAwleeHMgVE9lr2eoJ1kxPWTV5YO/koN1TQthOZdORUGnWICqN+McHk4qxtr56W4GtOTgw60Y0N9AbMnYZxvXTpUvG3q6ur8CrDyFYMdHhT7733Xov//9ChQ+L/9OrVy7gMxpylpG31YcaMGSLk/rfffqOrrrpKGOtxcXEN3h7aCcNcMc5B586dRTvxnWLwIkRcMc4BwsmtiQbYsGFDtf+H0Py6gFGugHByxTg33yfeceGOGDGCGlO7ENsYNGhQteX4OyEhodoy02OMdihtYAP9nxsppidgMETLN1KtwbrJCesmL6ydXKzZf45mrjxI53KKqpacovAAT3plfGca3bXyWYDR3zWHQZvtyRcoPa+IQv08qW+bIB60sTEGndwr2UCvJzDEEcJsmhQOnl3MU54zZ47wTmNueWNQTjjTsHlTA9US99xzjwjDRng9jPS33npLhGgjkZ09cXNzq/Y3PPPWlD7A3HvzQQlr+21pn8r/aeyxry+mbVFC8LVe+oFhGIZh9GycP7hgN/3zpFJJWk6RWD73tp5spOuQmoM2xIM2TIPR7tCDHYBhjjBvGL7wkisveFVhsH/33XdGr2ptJbvgWcV2du3aVc0rb5oYTQnDNk18Zpowrjbg7X7ggQdE4jKEeH/++ee1hrmXl5fXuS2E3GOePF4KBw8eFO2EJ90eNLTfpsArD69+XSXTYFTX1X/Mz4eemzZtqrYcf9ur7wzDMAzDqBt4SGGEmRvnQFmG77Eeo79BG1Pj3HTQBt8zTH1gD3o9QBK0ixcv0t13312j/jhCyuFdh4H8yiuviBBrhGFjDjMMcmRUx5xmJJbDvPX7779fJDNDuPtjjz1WzfOLz/379xfJ1uBpRsj05eqEYxtjxowRicrQRsyXrm1eOwxYZKKHEYu58QgZx8sUhMljPvutt94q5l2jDw899BANGzaMevfuTfYAidwwyICM6pjDjvn6GAwBOE7Wgv8PHZApHscEWeVhXCvRBIoBj5B1RD5YCq9/+umnhY7QEBnckVQOgwXIuM9YD6IiMPCi5TAkLcK6yQnrJi+snRwgfNncCDMFZjm+x3oDYps3adsYx1xzlxu0QWwlvh/ZOYzD3W2As07uldrunY2BAQ7D1dw4Vwz0nTt3iozfmIv+448/iuzhMO6GDx8u5q0rwNiDhxbG7nXXXSeyjcOYNAWZ4WEUY646jG8kPqsLeISRuRxGOQYAYKgjO7wlkMkdBizmzuMkf/vtt2usg3Dt5cuXC+N16NChot9IPIfycvYCnm1EIRw+fFhEISAxm9JvGNLWllSYNm2aGFRA/5G0bdy4cdWyr8PoR1Z6DAb06NGj1jn9TzzxhIhEwEAFSqxBz3bt2tmot/oAN1AMcmj9Rqo1WDc5Yd3khbWTA8wttuV6jPzXXH0GbZjG46yTe6VThemEX52AJGAwspF9HeHMphQVFYnM5fBco7RXUwGvLgxxvJjq4BRFCbn6GOlqw1HnlRoy3B5ISqUusRGc4VYikEdBOV+1/iOoJVg3eWHt5GBLUhZN+XzrZdebdX03mtwnqknaxDj2mlu+9ww9uujy0zE/vLk7TejeqsH7YeS6V9Zla1qDenvGMCZwbXG5wHyrwbPW0S3/205v/nlWvONvnoclzw9gRkYGJzyUDNZNXlg7OUBWbiT+utxQ87OL99GM7/ZQcmZ+E7WMcdQ1h2zttlyPqRu93CvZQGcYxqZwshSGYRhGiyAKDFm5LaEY7T1bV1aoWZFwlq567y96bnEinc0ubMJWMo4YtKkLXw9X6hnVuHLKjL5gA10lpKSkcHg7Iz2c4ZZhGIbRMiiZ9ciItjWWhwV40qe39aQlDw6iVY8MpuEdQ8Vv3aIdp+mK/6yn11YepMxLxQ5pM2PfQZuXx9Vd4edScRnd/PlWOpnFERWMdbCBzkgBSsMx6oeTpWgDzOuKiIhQ9fwupiasm7ywdnKRkVdpaA/vEEKvXB1F397TlzY+O9xY77prqwD68o4+tPjBAdSvTRCVlBvoy03JNPTtP+mdX49QTmGpg3vA2PKa8/GorDRkPvUBnvW7BkWTn4cr7TmVTdd8uIF+2Hla5FZiGoazTu6VXGaNUT1IDMcGuhxYm7l28a5UahvqSyF+HnZvE9PwH0BGLlg3eWHt5KGs3EC/HjgvPt81OIYGtwuudd1erYNo0X39aePxTPrPr0coMTWH5vx5nL7ekkIPXBFLdwyMJm93fhSX/Zr7fMMJ8T51YGsa3SVcPAthzjnC3+Fhv2twG3rihwThnHjmp0Radyid3rquGzXz4Wfb+uKsk3ultocfGE2AkcbCwkIecZQAa5Og/LQ7lfr96w+6/Ytt9OPO05RbxN4ENYGyjYcOHRLvjDywbvLC2snD1hMX6EJ+CQX5uFOf1gGX1Q1OhiHtQmj59EH06W29qH0LX8otKqO31xyhoW+vp/mbkqm4jHWX9Zo7dC6XNhzLJBSpuWdwDA2IbS6yteNdqVwT0cybvru3Pz0zugO5OjvRmgNpNOqDv2nDsQwb9UY/lOvkXskGOiMFWr8Q9ZQsxd/TleJa+ROmoeNH7emfEqn3G3/Q/d/spNWJ56iolLV2NBgMQ2kQHhSTC9ZNXlg7eVi9rzLR6aguLYQBZq1uMNRHdw2jXx4dSu9PjqeoIG8xJ/3VlQdp+Dt/0Q87TgvvPCPXNad4z8d0C6fIIO9a18O58tAVbWnZ9EEUE+JD6XnFdPsX20VuAn7usZ4Kndwr2UBnGKZJkqU4Vb3eviGOVjwyhNY/dQU9MbK9CHUvKasMGZz+7W7q9frv9Pj3e+nPw+lUyg8rDMMwjKrC29PE52u6Vc43b8jv5KQeEbT2yWH05qSu1MLfg85kF9IzixPp6vf/plWJZ8nAiVSl4FxOIa3Ye1Z8vm9IjFX/B/kJVj8yhG7v31r8jdwEE+ZsEp54hlFgA51hGJsS6u9pMVkKMtzOva2nMYlOdLAPzRjRjn5/fCj9PGMIPTAslloFelF+STkt3XOG7py/g/q++Qe9sHQfbTuRxQ8sDMMwjEPZllwZ3t7M240GxDRv1LbcXJzp1n6t6a+nr6QXrukktnkiM58e/nYPjZ29kdYdPq95L6HszN+cQmWGChE9GB9pfRk1L3cXen1iV/ryjt4U7OtOR87nCSP9fxtO8LMOI+DMFIwUeHhwMjFZWLbnjHif2L0l3dg7gpLOZlJsy2DqFxNsnI9lHvbXuaW/eD07ugPtPnVRjEgjjDDzUgkt3HZKvBA6Py4unK6Nb0VdW/mL/8fYLwlLTEyM5rOkag3WTV5YO9nC28PI1cWZDAZqtG6ebi5079AYurlvJH25MUWETMObetf8ndSrdTN6elQH6t/IwQDG9tccSqd9u+1Uvbzn5gzv2ILWPDaUnlucSH8cSqc3Vh+iP4+k0zs3xlN4gFeDtql1nHVyr9R27xirQJ3OLUlZtHzvGfFu7xrVd9xxhzCuHnjggRrfTZ8+XXyHdZR1J02aRG5ubmyQSQBC0hGeByb2jKCBbUPo9qGdxLsl49wcaIystzMndKWtz4+gr+/qSzf0ihAlSlCe7fMNyTR+zkYa8e5f9P7vRykp41IT9Ep/4IcvNDRU8z+AWoN1kxfWTpLw9v3Vw9ttqZufpxs9elU72vDMlXT/0BjycHWmXScv0s2fbRUJVRNOZzd6H8w/NFa773ecpryiMjGfHDXvG0qwrwd9PrW3mO7g6eZMm45n0egPNoicPIx+75Xa7h1zWdbsP0eDZ62jKZ9vpUcX7RXv+BvL7UlkZCQtWrRIZGdXKCoqom+//ZaioqJqrF9QUMChXhLw99EMulhQKn5wBsU2F8n9EhISGpTkD96Joe1DxEjyjhevEtlvx3YLFw8tCAP8cO0xYaiP/WgD/fevJDqb/c+5xDSOxujGOA7WTV5YO/WDEllZ+SUUiPD22OZ20w2lt56/phP9/cyVYp6ym4uTSKg64eNNIpnq0fN5NtuXnmmMdhis+XJjsviMzO3OVjggLuecwHSH1TOGUFxEAOUUloqcPE/+kEB5XOVGl/dKNtB1DIzwBxfsFp5JU9JyisRyexrpPXv2FEb6kiVLjMvwGcZ5jx49aqxvQBwZo3owdxxcG99SGNi2KpGHEEBkv/341p6066WRIgPulR1CRLmSA2dz6a1fDtPAf6+jGz/dTN9sSaGsS8U26pE+4dKGcsK6yQtrJ1F4e+cwMX/c3rq18PcU85TXPXkFXd8zQpTxQjJVlOdCItWTWfk236eeaIx2P+9PE4n9mvu403U9W9msTbEhvrT4wYH08JVthd6Ld6fSNR9toJ0pF2y2D9mp0Mm9kg10DYGTtaCkzKoXRuReWXGALJ3eyrJXVxwU61mzvYZcKHfddRfNmzfP+PeXX35Jd955ZyOOAONIcK78fvC8+DyxR0u77cfXw1VkwJ13Z1/a/sJV9MbEriJBC9iRcpFeWn6A+v5rLU37cjst3pXKo88MwzBMo8DUP2P29riGZW9vKCjd9e5N8fTrY0NpTNcwwuMWBsMRQfZ/S/cJpwrTdOB59/O/K0urTR0QLRwItgSDP0+N6kCL7hsgEueevlBIN/13C7372xGubKMjOEmchigsLafOL/9qk23B3E7LLaJur/5m1foHXxtF3u71O51uu+02ev755+nkyZPi702bNomw9/Xr1zeozYxjwch+cZlBzMfq1iqgSfYZ5ONOt/VvLV4od7Iq4RytSDhL+87k0F9HM8TLY6mzmB8Gr/6VHUNr/THFAxhCGNPziijUz1MY/dbMm2cYhmG0zbbkLJG0FOHtA6vC25uadi38aO5tvWhfag6989sR8fuGJGUYiJ46oDU9eEVb8ZvI2D+TP54xMN3u9gGVpdLsAZ5BfnlsCL26/AAt2XOGZq87Tn8fy6QPJnenNsE+dtsvow7YQGccRkhICI0dO5bmz58vRiTxOTg42OK6np6VpbsY9Wdvn9S9lTGhn4uLC3Xs2FG82xtkPEUmXLxOZFyilQnnaHnCGTqRkU+/7E8TL3jfr+7SQhjrg9sGizB8gOkcM1cerDbdA1njXxnf2VgWTk80pW6M7WDd5IW1Uzc/V4W3X925hTG83VG6dYsIoK/u6isGlP/z62EROYYEqjDW7x4SQ/cMaUP+nm5N1h5Zaah2ivccCWztPSACHd+b3F04F1ByFokCr/lwA708vjPd3CdSl8mTXXRyr2QDXUN4ubkIT7Y14MZ+x7wdl11v/p19jOHDl9t3Q0CY+8MPPyw+f/zxx7Wu5+rKp6qaOZ9bRJuTMsXnCd3/mY+FH4/AQOtrg9qKmBBfkQ13xoi2Yo76yoSz4nU2p4iW7D4jXpg7hky8Lfw96N3fjtaY7qHkYjCt3a4XHKUb0zhYN3lh7dQLoqvW7D9fLXu7GnTDs9kP9w8QnnR41PefyaWP1h6jr7ek0APDYmnagGhRb1uBo8So0dodT8+jtYfTCXbx3YPbUFMxPr4l9Y5uJpLGbU7KoueX7KN1h9Pp39d1o+a++ipD7KSTeyXPQdfYSYswc2teQ9qFCA9hbbdmLMf3WM+a7TV0FG/06NFUUlJCpaWlNGpU7YML+fn5mk8IITMwflGdDzVbo5p7G5eXlZXRjh07xLsjwHnZtVWAyIi78dnh9OMDA0RWXBjnyMb7zdaT9I4F4xwoy+BZt3fpQbXhaN2YhsG6yQtrp15g1GZeKqYALzca1DZYVbrhN+6KDqG08uHBNPfWnhQb4kPZBaX0718O09D//CmSppaUGRxWsUfNNES7/22ozNw+slML4QhoShAluODufvTCNZ3I3cVZ5PwZ9cEGUTddT5Tp5F7JBrpOwagpwneBuWmt/I3v7T26ihCVQ4cO0cGDB+sMV2HjXN0s21sZ3j6xe83kcGophYEyKH2ig0RW3G3/N0KECA5tZ3lKhQLOOoS94wFNb6hFN6Z+sG7ywtrJFd6uJt1gqI/pFk6/PT5MlCaNaOZFGXnFImnqgLfW0gMOqtijduqjHY4nou/AfUNjyFHPMZjGt2z6IGoX6isGju6ct4NeWb6fikodfx42FeUquObsDRvoOgZhuwjfDQuoPr8bfzdlWK+/v794MXJy7HyeCK1DybOxcfbL3m5LMPd8WPsQur5XhFXrHz2fa/c2MQzDMOoC0VPIX+KI7O0NAU4VzI1GabbXJ3ShYN/KaDFL6DlKrCGIaIRyA/WIChTRgo6kc0t/WvnIYLpjYLT4+6stJ2nc7I20/0yOQ9vF2A6e2KtzYISP7BzWpPOSkBSuLpYtW1ZtXXjPEeLOqNt7fkWHEOkyyOJ8t4ZXVhyk1fvSRHI5zEGUrZ8MwzBM/dmRUhne7u/pSoNi6464UhPuIsN4NEUFedO0OvINmUaJDXBQdnoZKCwpp6+3VlYcundIjCqSs6EizavXdhEJ5J76MYGOp1+iSZ9soiev7iDaqOf8AlqAPeiMuIhxY0ZyL7yr8aL28vJydBMYCxgMFbR879kayeEUMG0hLi5Otdk2MRhVVy4G4O5S+S0eYF5ctp/6vvkH3TlvOy3dk0qXirU5B0rtujGWYd3khbVTeXh7lzBh9MqmW3ZhqVXrwUGjN+qj3U+7Tou5/ZFBXjSqSxipCUQD/vrYUDEFo7S8QuQfuPV/W+lMdiFpEReVX3O2gg10RgqcnflUVSO7Tl2k1IuFonzZVZ1aWFzH3d1d2lwMeH00pQdtem44PT+mI3Vp6U9lhgr680gGPf59AvV6/XeavhBz+NI0N/9LzboxtcO6yQtrp97w9rFm2dtl0c3aKDFr19Ma1miH8+B/GyuTw90zWJ2eaUT1/ff2XjTr+m7k7e5CW09coNEf/E0rEiodKFrDXcXXnK1gq4eRAg5xVydLq2qfj+4aVq2ci2kij507d6o6oYc1uRhaBXrR/cNiafWMIbT2yWH06Ih2FBPsQ8VlBlq97xw9sGAX9XnjDxFm9vfRDCorN5DMyKAbUxPWTV5YO/WxM+WCSAwmwtvNsrfLotvlosSUij3WlNPVGtZq9/vBNDqZVSCy+N/Y27q8NY4AYfeT+0TRzzOGUPfIQMorKqMZ3+2hxxbtodwi6yIpZKBc5decreA56AzDNAiUblmdWBn+N9FCeLtWczHEhvjS4yPb02NXtRM11jFCjTJzmMf3065U8UJiHnhcru3eknpGNVPFfDWGYRim/uHt+G2wFN4uA0qUGLK141fIPBVcRRNV7JGZz6tKq6FEK8oKq53oYB9RUnbOuuM0e90xWrb3LO1IuUjv3RRP/WI4z4AsqP9MYxhGlaw/kk45haUU6uehieQySi6G+tZYx+u50R1FMiEY63ioy7xUIrKq4gXv+/j4liLBXKdwPzbWGYZhJMivYgxvj1PXnOOGRokhW7t5qTUPV2cxiMxYZtfJC7Tr5EVRd3zqwNYkCygHCEfC0PYh9Pj3e+nUhQK6+fOt9MCwWHr8qvbSDjjpCTbQa8FgkDtElVEXWqzjrmRvn9C9pe5H31GbFCPTeCGr6sbjmbRy71n69UCaSNTy6V9J4tU21FcY6nhhlJthGIZRHztPXqT0vGLy83SlwW1DSHbMo8RCfD3o32sOU2JqDs1ac4TevSne0U1UJZ//Xek9n9ijpZTz9FEO7udHh9DMFQfox12pNHd9Em04lkEfTO4hnkcwv74pqzgx1uNUoUXL4TLk5uZSQEAA5eTk1Ki/DcP82LFjIjtgSEiISETAHi/HYnqKyqgF2p+RkUEFBQXUrl07TWSexHym3m/8IcLcVz0yWHiRa+s75gmhzzJq11iQOG7d4XRasfcsrTuSLo6XQlxEgDDU4V1v4a+uH3696yYrrJu8sHbq4tUVB2j+5hS6rmcreu+m7prUbe/pbJr48SbxeelDA6mHzjzpl9MuJTOfrnx3PeER9LfHh1L7Fn4kM7/sO0fPL90nstF7ujnTxB6taP2RDEoziapAPgJMecCAjlqpkOSaq8vWtAb2oFvIFt6mTRs6d+4cnT2rzeyHMoKBE5kzueMmEhERoQnjHKzZlyaMzXahviKzeV2UlJTotkwe6pSibjpeGNT4dX+aCIPfnJQlPBd4vfnzIerXJoiujW9FY7qGUTOV1FjXs24yw7rJC2unnvB2Zf55XdnbZdcNicRu6BUh8qZgQGLpQ4NENJieqEu7LzYmC+P8yg4h0hvnYEy3cDEI8/RPCbThWCYt2n66xjow1pGvQEmQq1ZKJL3m6gMb6BaA1zwqKorKyso0nyVQBqDD/v37qWvXruTqKucp6+bmphnj3DS8HSOwdY1g4vpJTEyk3r17S6udrfD3RAbYSPHKvFQsHgDhWUcoJUqi4PXy8v1izhg86yM7tyAfj9qPmT1D01g3OWHd5IW1U2F4u4crDW5nOXu7VnR7ZnQHUSY0ITWHFu9OFb9PeqEu7S7ml9CPuyoN2HuHxpBWQHWaL6f1oV5v/E65RWU1vke8Kp4ikK8AUyLUGO5eLvk1Zy3a7VkjgdEBowovxvEGOvD09NT0xSgL53IKacuJLPEZhiRTf4J9PWjqgGjxSr1YQKsSK431g+dyRUg8XghBQ215HONhHULIw/WfAZ41+8/VSPgjQ2gawzCMPNnbW1S772oRDO7OGNGW/vXzYTEXHSVT/Tz5uXfB1pNUVGoQEYIDNJb5HANQloxzUyMdzxZ3zNtO/WOai8o1bUN9KCrIh5PLNSFs7TAMUy9gSCLsq290EEUGeTu6OdIT0cxbZFbF63h6Hq1IgLF+hlKyKg13vFCHFw9OCIPPLSyl6d/urlEuR5bQNIZhGHVnb6800DE1SQ/cMbCNCHc+kZlPs9cdp/+7phPpGeSO+WpLivh839AYVc9zbgiIurMGhMHjpQBveusgb4oJ8aXYUB9qK959KTbYlwK8eVDH1rCBzkiBlsLDZQc1NcGEHtZ5z1k762kb6kdPjPSjx69qR/vO5IjBEBjoablF9MPOVPFCxJmlzJ62Dk1j3eSEdZMX1s7x7Dp1kc7nVoa3D2lfd3i7VnSDV/SlcZ3pzvk7aN6mZJrcJ1J4TfWAJe2W7TkjSqW2DPDU5CCNtdnocR6UlhnoeMYlSkq/RPkl5WIQB68/DtWMCowN8ak02GG443OIrygza8u8BuWGCjEdcMfZUio7cYEGtA1RZRi+LeAs7g3IrMcweuVwWi6N/mADubk40Y4XrqJAb3UkNNO6R2d7VY315XvPUH7x5fNifHdvf03UpmcYhnFE9vZJPVrR+5Nrz96uRe6av0NMr7qiQwjNv7Mv6fX3duT7f1FSRj69OLYT3TNEO/PPTY3cwbPWiag7SwagU9Vc9Y3PDjcavzAVMXCVBGO9ymDHMTqefkk4EGoDU/Vigqs87VVGO14xIT4iiW59WCPZ1D7O4s5oHtwYcILjRNdaqJFsLNtT6T2/skOoVcY5a9d4MPqMeWB49W7djJ74IcFmIWy1wbrJCesmL6ydnOHtWtINXnTUyEbprXWHz9Pwji1Iy1jSbv3RdGF4IoICHmQtAqMbRi2mxKHXpka6cgbje1PPNI4PjHa8BrWtHllyqbiMThgN93yjEZ+cmS/m8SO3Dl6m4HDDu145v93E6x7qS819apa3hnGO9uppah8b6IzqQcbGw4cPaz5jowwPL5gbrWRvtwbWzraEB3jZNIStNlg3OWHd5IW1czy7q8LbfRHefpns7VrUrU2wD901qA399+8T9PqqQ8IQ03KSPEvaffb3CfE+pV+UppPlwZiFUWvukQ5rgEca10tcRKB4mVJWbqDUi4XCy270vFd53XMKS8V3eP11NKPa/wvwcvvH2x7qS22a+9BLy/Y3ydQ+NSH33YRhmCYDYdZnc4rEyPLwjqGObo4uQSk1hHTVFpoGkFCuT3SzJm4ZwzCM3Kyuyt5+VafQeoffaoWHh7elJXvOCO/nvE0pInmpXkhMzRbzm12dneiOgdGkdWCEw6i1V7lWVxdnig72Ea+rqEW1yIUL+SXCWFfC5cU894xLwmCH8b77VLZ4WYOSdR790NLUPmc1jmi99NJL1KZNG1GEPjY2ll5//XUhqCUeeOABEQrxwQcfNHlbGUZPYP4zGNMtTLcPL2oJTQO1/YSifMoj3+2hvKLSJm0bwzCM1OHt+9LEZy0mBrMWeI2fHd1RfJ699hil1zG/WGt8viFZvI+Pb0ktA62LVtPCMwWM2gndW4n3pvBAw2Zr7ushBgOm9I2iF8d1FjkPNjwznA69Npp+eXQIzbmlBz1+VXtRZjbCSi0aO7VPbajOQJ81axbNnTuX5syZQ4cOHRJ/v/322zR79uwa6y5dupS2bt1KLVtyLWYtg4sZgzWyz++SvewIsonXJ7wdsHb2C01DKJop8Kzf3CdSJPD7ZX8aXTtnEx0ym/dlLaybnLBu8sLaOZY9py+KZFcI1x3aPkTXul3XoxXFRwaKrN2oja5VTLVLvVhAP1dFUNwzpI2jm6Zb4PzpFO5P4+Ja0qNXtaOPpvSg/9wY3yRT+9SG6kLcN2/eTBMmTKCxY8eKv6Ojo+m7776j7du3V1vvzJkz9Mgjj9Cvv/5qXJfRbhmM+HjrLlDGPqw/kk55RWXCCOzfxvoQItau6UPTbu4bRdMX7hYhihM/3kRvTOxKN/auX7Ib1k1OWDd5Ye0cy+rESu/5iHqGt2tRNyQmfXV8Z5r0yWZavDuVbusfRT2itDdtylQ7hPOL7OZtg6lLywBHN42px9Q+Jes81tMSqjPQBw4cSJ999hkdPXqU2rdvTwkJCbRx40Z67733jOsYDAa6/fbb6emnn6YuXbpcdpvFxcXiZZr6HpSVlYkXcHZ2Fi9sGy8FZTlC703D7Gtbjgseo3HKdk2XA6xvzXIkrMB2TZdju1jfvI21LddKn7DfrKwsat68udiGFvokm05L91SGt4+PCyeDoZyUZl6uT2hLRkaG0E5ZppY+aUGn/jFBxuUVhnIqr3Ci7pGBtOLhgSLb+19HM+npnxJpR/IFem1iV3J3cbKqT+DChQvUrFmzap4h1kndfcJ3uFeGhISI/WqhT5dbrpU+4aX8zrm5uWmiT7LohPB2xXuK8Pb69EmUnzp/3vgbpxWdurX0o+t7tKTFe87SK8v309KHBgnDXUvnHpZlZmaSi6cvLdp+Siy7c2CU8f/K2CctnHuW+vTyuM700MLas86/eE1H8QxUZlBPn8z7Ib2B/txzzwkDumPHjuKgobNvvvkm3XrrrcZ1EPYOAWbMmGHVNt966y2aOXNmjeV79uwhHx8f8RkPNJjvnpycLAwKhYiICPHCgAHKMSjExMRQaGgo7d+/nwoLC43L0e7AwECxbdOTIy4ujtzd3Wnnzp3V2oDskSUlJZSYmGhchn736dNH7A8ZJhUQioPRPtxQTpyozDQJUCKiU6dOdPbsWUpNTTUu10qfTp8+TdnZ2aINaJ8W+iSTTpdKDLT20EXxeVi0d7XtWNOn48ePi3bhRqiWPmlRJ9M+lRfk0v2dDNTCxYt+PFRIP+xKpX1nc+mVES2JLmVctk/h4eF07tw58vPzo7y8PFX0SYs62bpPeDDAvbJ79+5CQy30SYs6WepTQUGB8XcO29ZCn2TR6eiFUhHe7uXmTMPah9SrT76+vsKRZFqqSys6jWxRSj+7OlHimVxatC2ZJvdtralzDw4+tGPFsUIRzh/p70LeOSlUXh4ibZ+0cu6Vm/VpZKcQeryvL81PLKALRf8YzC38PeiWjm7UvPA07dx5WlV9ys/Pp8bgVFFb9jUHsWjRIuEZ/89//iMunr1799Jjjz0mPOjTpk2jXbt2iZD23bt3G+eeIwwe6+BlrQc9MjJSjFYrxeN5VEu9fSotLRV69+zZU3gWtNAnmXRatOM0vbj8IHUM86OfZwyuV5/wg4BrFtphPbX0SYs61db2Tcez6PEfE0XWVMyvfPv6rnR15xZ19gmfcc316NHDuH819UmLOtmiT3iHbr169RIPaVro0+WWa6VPaL/yOwfttNAnWXR68+fDNG/zSREhNvuWnvXqE5bt2LHD+BunNZ2QOG3Wr0cp2Ned1j05jLzdnKXvkwLW2bp9Bz25voDS84pp1nVd6fqeraTuk5bOPUttxzSEbScyafu+I9Q/vhP1jw1B+CCpsU+wNRFZA0NesTWl9qDDOIcX/eabbxZ/d+vWjU6ePCm84DDQN2zYQOnp6RQVFWX8PzggTz75pMjknpKSUmObHh4e4mUORDSvW6kcZHNMH1KtWV5bPcz6LMeJY2l5bW2s73JZ+qRctIqBp4U+yaTTyqq5ecjy2ZA+KdqZ7sfRfdKiTrW1cVjHFvTzjCH08Le7aefJi/TQt3vpvqEx9PSoDrVeT8oPpLluaumTFnVqzHLTtmNfyjpa6ZM1y2XvEx7qlHul4omVvU+NbXtT9AlBsr8eOC/+HhvXskF9svQbpxWd7h4SSz/uOkMnMvNpzp9J9H/XdJK+T6a/c1vOlArjPNTPgyb2jCBXk7rvMvapIctl6pMrpkK3DSH37JPUO6a5KOVmKd+5GvpUWz+kzeKOMC/zg6GMbgDMPUeIBjzryguedBj2SBjHaA9caKbhY0zTcSa7kLYlXxCfJ3Svf7UE1k4dIIHKd/f1p3urstN+9vcJuuXzrSLpiiVYNzlh3eSFtXMMe1Oz6WxOEfm4u9AVHazP3q4X3dxdnemlcZWlPedtSqYTGZdIS/ySXCLe7xgUTR4mxjmjXpw0fs2p1kAfP368mHO+evVq4Q1HKTWEt0+aNEl8j3CBrl27Vnsh7DksLIw6dOjg6OYzdgADNJgjUtuIFWM/Vuw9K977tQlqUF1Q1k49uLk40wtjO9Ont/UkPw9X2pFykcbN3kCbjmfWWJd1kxPWTV5YO8fwc1X50OGdWtQre7uedLuyYyhd2SGESssr6PVVB0krbEm+SMkXS8jb3YVu7dva0c1hrMRFB9ecKg101Du/4YYb6KGHHhICPPXUU3T//ffT66+/7uimMQ4C0RNI3mA6D4SxPwi5XLqnMmnGpHrUPjeFtVNnibaVjwwWtUYzL5XQ7V9soznrjolMxgqsm5ywbvLC2jnmN+6X/ZVTuMZ2C2vQNvSiG7zobi5O9OeRDFp3uHJKgOwgkgzc1CuCArzdHN0cxkoMOrnmVGegI2sw5pJj3jky4SUlJdEbb7whkqbUBjzttSWIY+RHLxej2jh0Lo+Onr9E7i7ONKZbeIO2wdqpk+hgH1r60ECa3DuSYJe/89tRuuurHXQxvzLcj3WTE9ZNXli7pmfv6WwxjQse1Cs6hDZoG3rRLSbEl+4aVDlF6vVVh6gE9awk5tC5XNpwLFOU6Zo24J+cVoz6MejkmlOdgc4wjDpYvrey9vnwjqEU4MWjy1oD4Zyzboijt2+IIw9XZ1p/JIPGzd4oHloZhmG0jlL7HL9xDQlv1xsPD29Lwb4elJyZL+ajy8znGyq95/1auVNkkLejm8MwNWADnWGYGqCUxfKq+ecTGxjezsjBTb0jaelDgyi6ubfwJt346Wb6ZuupaiVEGIapvC9uScoSg5d4x9+MnOD+9vM+Jby9YRFiesPP042eG9NRfP5o7TFKz7WcZFTtIDnqyoTK55vxbeufW4dhmgI20BnVg6z+ISEhFksdMPZh24ksSsstIn9PV7qyY/0z2yqwdnLQuaU/rXhkMI3uEiYSAc1cdYg+219KhaXaDiHTGny92Y81+8/R4FnraMrnW+nRRXvFO/7GclvA2jUtCak5jQ5v16Nu1/VoRfGRgZRfUk6z1hwhGZm/OUX8zvWJbkb924frRjut4KyTa07bvWM0AS7C2NhYzV+MamJZVXj72LjwRpUeYe3kwd/Tjebe1pNeHNuJXJ2d6M+kPJr4yWY6ej7P0U1jrISvN/sAI/zBBbvpnFlZQnjisNwWRjpr57jwdi93/o2zFmdnJ3p1fGXZtcW7U2nPqYskE5eKy2jhtpPi831DY3WlnVZw1sk1p+3eMZoAiSCQLFDrCSHUQlFpOf1SFfo3sXvjwttZO7lAXdF7hsTQd/f2o2AfV0rKyKcJczbRsj2VAzaMuuHrzfYgjH3myoNkKZhdWYbvGxvuzto1bXj76qryao0Nb9ejbj2imtENvSLE51dXHqxWAUTtfL/jNOUVlVFMsA9d2T5Yd9ppAYNOrjk20BnVg4swIyND8xejWlh7KJ3yisuoZYAn9YkOatS2WDs56REZQG8O9aNBsc2psLScHvt+L72wdJ8YvGHUC19vtmd78oUannNTYJrge6zXGFi7piOxKrzdy61x4e161u2Z0R3I18OVEk5nC0+6DJSVG+jLjZXJ7TAQjatXj9rJjkEn1xwb6AzDWAxvn9CjlQhnY/RJgIczfTmtF80Y0Y6cnIgWbjtFN366hU5fKHB00ximyUjPK7LpeoyKwts7NS68Xc+E+nnSI8Pbis+Yi55XVEpqBzXvMTDT3MedruvJyW8ZdcMGOsMwRrILSmj9kXTxeRJnb9c9Ls5O9MTI9jTvjj7UzNuN9p3JEaXY1h467+imMUyTGSK2XI9RQXh7lYHO2dsbx52D2ohQ8cxLxTRn3XFSu+6f/V1ZWu32Aa25rB6jethAZ1QPEkFERERoPiGEGsCDC7Kbdgr3p/Yt/Bq9PdZOTsx1QxjoqhlDqHtkIOUUltLdX+2kWWsOi5BBRj3w9WZ7+rYJovAAT6otlgjL8T3WawysXdOAQcbUi5Xh7Vc2Mrxd77q5uzrTS+MqE8Z9uSmZTmRcIrWyLfmC0N7D1Zlu79+a9K6dzDjrRDdt947RBHq5GNWAkgxsUo+WNtkeaycnlnRrFehFP9w/gO4YGC3+nrs+iW77YhuH9qoIvt7sE0XyyvjOFpPEKeB7rNcYWLumYbWNsrcr6F23KzuG0pUdQsTA/uurDpJa+bzKe47kds19PcRnvWsnK8460U3bvWM0QXl5OR06dEi8M/YDc4t3pFwU842vjbdNeDtrJye16QaPyavXdqE5t/QgH3cX2nriAo39aCNtPZHlsLYy/8DXm30Y3TWcbu8fVWM5vLAoTYjvGwtr1zRhzsr882tsFN7OupHworu5ONGfRzJo3WH1TX86np5Haw+ni2ebuwe3MS5n7eSkXCe6sYHOSPGjmpOTI94Z+7Ei4ax4HxDTnMICbDOfkrWTk8vpNi6uJS1/eDC1b+FLGXnFdMvnW4VHXaZyO1qErzf7kVtUZowuQl4GgCkeja10ocDa2Z/9Z3Lp9IVC8nRzpis7hthkm6wbUUyIL901qNLwfX3VISopU9fUpy+qMreP7NRCtFWBtZOTCp3oxgY6wzDiRrekqlTKRE4Ox1hB21BfWjZ9EF3XoxXBLsec9Pu+2UU5BerP5ssw9b0/bkmqjBK5sXekqGwQHxFApYYKWrTjtKObxzQgvN3b3dXRzdEUDw9vS8G+HpScmU/zNlUaxGoAA8iLd1dO3bt3KEqrMYwcsIHOMAwdOJtLSRn5IoR5dNcwRzeHkQQ85L57Uzz9a1I3cndxpj8OnadxczbQ/jM5jm4aw9gM3BvT84rF/bFnVDOxbOqAylwMC7ee5GSJOg1vZ/7Bz9ONnh3dQXz+aO0xSs9VR26Sb7akCI8+Epz2bl157TKMDLCBzqgeJIKIiYnRfEIINSSHQwiYv6ebzbbL2slJfXRzcnKiW/pF0eIHB1JkkJcIIb1u7mb6dtspzYegqQ2+3uzDlqRM8Y4HfKU809i4cArycaezOUX0x6HK0pSNgbWz/yD0qQsFIrwdHnRbwbr9w/U9Iyg+MpDyS8pFbXRHU1hSTl9vPSk+3zc0RvxWmcLayYmzTnTTdu8YTYCLMDQ0VPMXo6MoN1QY55/bOrydtZOThujWLSKAVj08hK7qFCo8Fv+3dB89+UMCFZSUGc8zhAkv33tGvONvxrbw9WYfNleFtw+MbW5cBkP95j6R4vPXW1IavQ/WrmnC21FazZbh7azbPzg7O9Gr4yvLri3enUp7Tl10aHt+2nWasgtKxcDxqC41IwNZOzlx1olu2u4dowmQqTEhIUHzGRsdBYwlhG8GervRsPa2SZyjwNrJSUN1C/B2o89u703Pjekoyk4t2XOGJn68ieZvTqbBs9bRlM+30qOL9op3/L1mf+VDM2Mb+HqzPUh8uKWqSsGA2OBq393avzWhuhoM+GPn8xq1H9ZOzvB21q06PaKaCU86eHXlQYclDsUAsJIc7p7BMRbLILJ2clKuE93YQGek+HEtLCzkcFk7sbQqvH1st3Axx9KWsHZy0hjd4EV5YFgsLbynH4X4edDR85fo1RUH6VxO9TmJaTlF9OCC3Wyk2xC+3mzPobRc4YVDWcG4iIBq37UK9KKRnVuIz1810ovO2tk3vP1kVgF5uNo2vB2wbjXBXHRfD1dKOJ0tPOmO4PeD5yklq4ACvNzoxt6VAwbmsHZyUqET3dhAZxgdgzlaioE0ibO3Mzakf0xzWvHwIHJ3qem5AMpP68yVBzncnVEtSvb2vm2CyM2l5iPTtIGVyeKW7D5DuUVcwUCN/GwS3u7jwdnb7U2ovyc9Mryt+Iy56HkOuC4+33BCvN/WP4oz9jNSwgY6w+gYZN1GQpeIZl7UizOcMjYmJbOASsprN77xDTzr25MvNGm7GKb+88+rh7crDIhpTu1CfamgpJwW73KMt5CxMrw9jrO3NxV3DmpDbYJ9KPNSMc1Zd7xJ973r5AXadfKiqCwyraraAsPIBhvojOpxcXGhjh07infGPtnbJ3ZvVSPDqS1g7eTEVrql5xXZdD2mbvh6sy2l5QbaZpx//k+COFNw35xa5UX/ZsvJBs+5Ze3sw8FzuSLUGeHtI2wc3g5YN8tgutzL4yoTxn25KZlOZFxqsn1//nfl3POJPVoKb35tsHZy4qIT3dhAZ1QPHoACAwPtYkDqmQv5JfTX0QzjD5k9YO3kxFa6hfrV/nBkCuYqFpVqO+FLU8DXm23ZdyZHRBhhHmvncP9a17uuRyvy83ClE5n5tPF4ZUm2+sLa2QfFe35FhxC7hLezbrVzZcdQurJDCJWWV9Drqw42yT5PZuXTrwfTxOd7hsTUuS5rJydOOtGNDXRG9ZSVldGOHTvEO2M7VieepTJDBXVt5U9tQ/3ssg/WTk5spRvm7YYHeNLlfka/3JRCg2f9SZ+sP87zeBsBX2/2mX+OMHYkP6wNGH7X94poVMk11s5e4e1pdsnersC61c1L4zqTm4sT/Xkkg/48nG73/SFzO3KHYUCmfYu6n2tYOzkp04lubKAzUqD1cgqOzN6O8HZ7wtrJiS10Q2mbV6rq4pqbN05Vr5t6R4hs2Jir+PaaIzTorXU0a81hDntvIHy92Y7NSZXe8IFtLYe3m3L7gNbife3hdDp9oaBB+2PtbMuhc3mUnJkvwq1HdKrMtm8PWLfaiQnxpbsGtRGfX1t1kErKDHbb18X8Evph52nx+b7LeM8VWDs5KdeBbmygM4wOQRjY7lPZoobvtfH2CW9nGDC6azjNva0nhQVUD3fH31j+9g3xtP7pK+jdG+NFsq284jKauz5JeNRfWLqPTmU1zNhhmMaAKRc7Uy6KzwNrmX9uSmyILw1pFyy8d99sPdkELWSsDm9vHyLKfjGO4eHhbSnY10MMlszbVDk/3B4s2HqSikoN1KWlf605IxhGFviOxTA6ZPnes+J9UNvgOpOoMIytjPSRncNEtnZ4xjE3HeHv8LADlK9CiDBK/aGywCfrk2jv6WxauO0Ufbf9FI2Laylqq3duWfs8YIaxJXtOZVNxmYFC/DyE8W0NdwyMpg3HMun7Hafp8avak5e7tpMYyZK9fSxnb3cofp5uojb60z8l0ux1x2lSz1ZW5yepz4DaV1XTS+4bGqP5+cmM9mEPOqN6kKkxLi5O8xkbm/LBxTR7uz1h7eTEHrrBGIdXY0L3VuJdMc5NwTzfq7uE0dKHBtKi+/rTsPYhhKTYKxLO0jUfbaA7520XRj7OYaYmfL3Zji1KeHtsc6sf9q/oEEqRQV6UU1hKKxIq77HWwtrZlsNpeSJpn73D21k367i+ZwTFRwbSpeIyMZXJ1izfe4YyL5VQywBPq/MNsHZy4qIT3dhAZ6TA3d3d0U3QVGZiPLh4ujnTqK5hdt8faycnjtQNBlH/mOb01V19adUjg2lcXLiYjoFEQzf9dwvd8OkWWnvofINLWmkZvt5sXf/c+lBZDDrd3r9yLvpXm0/WeyCJtbMdivd8WBOEt7NulweDr69W5SP5aVcq7TlVOX3EFuB34PMNycb664jIshbWTk7cdaAbG+iMFMkgdu7cqYukEE2ZHA4hx/Z+cGHt5ERNunVtFUBzbulJ6568gqb0jSJ3F2fadfIi3f3VThrz4QZauidV1Ktm1KWbzOQXl4kpFmBgbHC9/u9NvSNFzW3U38Z5ai2sne3AwMhqJbzdTtnbFVg36+kR1Ux40sGrKw/abIB1/dF0Op5+SZQ6vLlvpNX/j7WTk3Kd6MYGOsPoiLJyA61MqJx/PrE7J4dj5CE62Ifeuq4bbXz2Srp/WIwYXDpyPo8e/z6BrnxnvShvVVii7R9spmnYkXJBlKCMaOZFkUHe9fq/gd7uxqlDX23hZHGOAPeFExlKeHuoo5vDmIC56D7uLpRwOpuWVDkLGstnf58Q71P6RYn57gyjBdhAZxgdsSkpS8zTaubtRkPbhzi6OQxTb5DU8PkxnWjTc8Pp6VEdqLmPO6VeLKSXlx+gwbPW0Zx1x8QcYIZpKFtO1D+83VLJtV/2naP0XC4X2NT8nFjpPR/aLoQNNhXev2eMaCc+//uXw5RX1Lh79b7UHNp64gK5OjuJJI0MoxXYQGcYHaEkhxsf37Je87QYRm0EeLnR9CvbCkP9tQldRC31rPwSeue3ozTo3+vorZ8PsXHENIgtVfPPG1qqCdMyerduJrzwqETAOCi8Pc7+OVaY+oN54m2CfSjzUjHNWXe8Udv6fMMJ4zNNy0AvG7WQYRwPP6EzqgeZGnv37q35jI32pqCkjH49kCY+I5N2U8DayYlMunm6udDUAdGilvoHk7tThxZ+IlPwf/8+IWqpP79kH6Vk5pMekEk3tZJTUEr7z+SIzwNi6jf/3JRpVd68b7efopKyy+dIYO1sw9HzlygJ4e0u9s3ersC61R9MPXhpXCfx+ctNyXQi41KDtpN6scA4GHPPkDb1/v+snZy46EQ3NtAZKSgpKXF0E6Tn94PnqaCknKKCvKlnVGCT7Ze1kxPZdENEyMQereiXR4fQF9N6U6/Wzaik3CDqqA9/dz1N/3a30fDSMrLppja2JWeJ0n4xIT4UFtDwWs2juoRRqJ8HZeQV05qqgdHLwdo1HsVgG9o+mPybKLyddas/wzu2oCs7hFBpeQW9vupgg7Yxb1MKlRsqaFDb5tSlZUCDtsHayUmJDnRjA51RPcjUmJiYqPmMjU2VvR1GjLV1fRsLaycnMuuGcj7wnC1+cCD9cP8A8RAIg2t14jkaN3sjTf1yuwhh1mItdZl1k7m8Wm1ewlv6RYnPX29Ouez6rJ1ty6tZWwu7sbBuDeelcZ3JzcVJlM/883B6vf4v8ows2l45feTeITEN2j9rJyflOtGNDXSG0QGY67XhWKb4zNnbGb3Qt00QzbuzL/08YwhN6N5S1FL/+2gGTfl8K103dzP9diCNa6kzFuef17e8miVu6RslklftPHlRF9Ebjubo+TxRbgvh7Vd1tn94O9M4YkJ8xXx0AC+6NVNBFBAZlV9SLqY0odY9w2gNNtAZRgesSjgrQsHiIwLEjyLD6InOLf3pw5t70PqnrqTb+kcJ7+aeU9l03ze76OoP/qafdtWspY7rBcba8r1nxDv+ZrQNwtFRogv0j2mcB13JWD2mypP7DZdcszuIkgFD2jVdeDvTOB4Z3paCfT3oRGY+zd+cbNX/gSE/f1OKce55U0UEMkxTwgY6IwVaTwZhb5burap93qNpksOZwtrJiRZ1i2ruTW9MrKyl/uAVseTn4So8bk/9mEDD3v6T5m1KFrXU1+w/J0q2wdP+6KK94h1/Y7na0aJuTcXWqvJqncL9KcjH3SbbnFZVcm3Z3jOUXVD3vEnWTq7wdgXWreGgDB5qo4OP1h6n9LzLV95YlXiW0nKLKMTPg65tZEQgaycnLjrQzalCixPxLkNubi4FBARQTk4O+fv7O7o5DGNXkjPz6cp31pOLsxNtfX6E+FFjGIYot6iUFm49RV9sTBbTQICvh6vIAm+O4qOZe1tPGt21aQ0ApmlAxn+Ezt49uI2YH2sL8Ig19qONdPBcLj0/piPdPyzWJttlqnPsfB6NfP9vMad554sjRRlGRg4wzWjS3M2UcDqbbugVQe/cGF/n9TTmww10OC2Pnh7VQZTaZBgt2prsQWdUD27I2dnZmkzq1JS1zwe3DW5y45y1kxO96IYwWHjS4VF/Y2JXimzmZdE4B8qRmLnyoGrD3fWim73YkpRpkwRxpiD8dtrASi/6N1tP1nrusHa2yd4+pF1IkxrnrJttEnu+Or5yQAzTjfaezq513Y3HM4Vx7u3uQrdWJWFsKKydnFToRDc20BnVg0yNhw8f1nzGRnuAGxhCK8HEHk2fHI61kxO96YZa6rf1b01vXdetzvXwOHAup4i2J18gNaI33WzJmexCSskqEJFGSC5oSyZ0b0WB3m6UerGw1mzVrJ2c4e2sm23oEdWMru8ZIT6/suJArck7P/v7hHi/qXckBXo3bhoKaycn5TrRjQ10htEwGIk+mVVAXm4udHXnMEc3h2FUTVa+dbVVrZknyciZvb1bqwAxL9bWA0CTe0eKz19tuXzJNaZ+HE/Po6PnL4nw9pGcvV1aMBfdx91FhLovqYr8M+XQuVxRjQbVODANhWG0DBvoDKOD8PZRXVqQj4ero5vDMKom1M/Tpusx8rDZDuHtpiBCA8mmYWAkZVyyyz70yurENOM0Lp57Li+oejBjRDvxedaaw5RXVFrt+/9tqMzyPqZrOEUGeTukjQzTVLCBzqgezOHz8vLiUhr1BGWjVlaVnZnggOztgLWTE73qhtDm8ABPY0I4S+C7nMtk43YUetXNFlOBbFn/3BIwKEZ0DK215BprJ194O2DdbAvqorcJ9hElD+esO25cnpZTRCsSzhhLq9kC1k5OnHSiGxvojBTlFOLj43VRVsGWbDyWSRfyS6i5jzsNaWufh87LwdrJiV51w/zjV6qSFdX204+ZkQ8s3C08PGVmtdMdjV51ayyYe47cAu4uztSrdTO77WfqgGjxvnhXao1khKxdw0CZRNSuR3i7I6ZxsW62xd3VmV4a10l8/nJTssjOj8GzF5bto9LyCurTupmYr24LWDs5cdGJbmygM6rHYDBQenq6eGesZ2lVePv4+Jbk6uKYS521kxM964YSaiilFhZQPYwdnvU5t/SguwZVem/mrk+iqV9uN5ZnUwN61s0W4e09ogLJy91+D30IwY4J9qG84jJauju12nesXeO854MQ3u7d9OHtrJvtGd6xBV3ZIUQY5ONmb6Qpn2+ltYcqkysez7hEa/ZXat5YWDs5MehENzbQGdWDi/DEiROavxhtCbwzvx2snJc30UHh7YC1kxO96wYjfeOzw+m7e/vThzd3F+/4e1xcS3p5fGeaPaWHKPOzOSmLxn60gXadVEdWd73r1lCgoz3D203LSd0+oLLk2ldbTlYrE8TayRfeDlg3+zCsQ4h4Ly6rflyzC0rpwQW7bWKks3ZyYtCJbmygM4wG+e1AGhWVGsRcrviIAEc3h2GkDHcfENtclMjCO/5WQFTKiocHUWyID53PLabJ/91K8zYla74uqxZBOaetioHe1j4J4ky5oVeEyFSN0Gxl3jvTMJBsDzWxXZ0R3s7Z27VCuaGC/vtXZTk1c5Q77MyVB8V6DKNV2EBnGA2Ht0/o3lLziTQYxhG0DfWj5Q8PprFx4VRmqBAPjDMW7aV8s7nFjLo5mp4nyuuhFGV8RKDd94cSbtdV1XvmkmuN4+fEf8LbG1sTm1EP25MviJwQtQGzHN9jPYbRKmygM6oHBmZAQAAbmlaCGs2bjlfOqZzY3XHh7YC1kxPWzTp8PVxpzpQe9NK4zsKLtzLhLE34eJPwjjoC1q3+KF7sPm2CRIKqpmBqVZj77wfP05nsQvGZtas/q6vC28c6KLwdsG72eYax5Xq1wdrJiZNOdFOdgV5eXk4vvfQStWnTRqTRj42Npddff90YOlhaWkrPPvssdevWjXx8fKhly5Y0depUOnv2rKObztgJZGrs1KmT5jM22oqVCecIkV9IeBQd7OPQtrB2csK6WQ8eEu4e3Ia+u68/hfp5CON8wpyNtLrKu9eUsG6NmX9u//B2hXYt/MT+cJ9euLWy5BprVz9OmIa3d3FceDvrZntC/Txtul5tsHZy4qIT3VRnoM+aNYvmzp1Lc+bMoUOHDom/3377bZo9e7b4vqCggHbv3i2MeLwvWbKEjhw5Qtdee62jm87YCSSCSE1N1XxCCFuxrCq83dHec8DayQnrVn/6RAfR6hlDqH9MEOWXlNP0b3fT66sOUmkTlmJj3eoH5rBuPdH0BrppybVFO05TUWk5a9fA5HADHRzezrrZnr5tgkTVjNr8o1iO77FeY2Dt5MSgE91UZ6Bv3ryZJkyYQGPHjqXo6Gi64YYb6Oqrr6bt27eL7xHW8Pvvv9NNN91EHTp0oP79+wtjfteuXXTq1ClHN5+xA3q5GG0BvHf7zuSIhFbj4hwX9qfA2skJ69YwQvw8aMHd/eiBYbHi7y82JtOUz7bS+dzGhWJaC+tWPw6czaG8ojLy83SlLi2bNpnmVZ1CqWWAJ13IL6FViedYu3qyel9llZKx3Zq+9rkprJvtwfPLK+M7i8/mRrryN743TdzZEFg7OTHoRDdXUhkDBw6kzz77jI4ePUrt27enhIQE2rhxI7333nu1/p+cnBwRZhgYaDnBS3FxsXgp5ObmiveysjLxAs7OzuIFwU1FV5Yj9N40Q29tyxFygbYo2zVdDrC+NctdXV3Fdk2XY7tY37yNtS3XSp+U9uBdK32yl07L91Z6z4e2C6YATxfRP0f3yXRbrJMcfVI+m+9T5j41lU5UYaCnRral+FZ+9PTi/bTz5EVRiu3DyfHUr8rjY68+Ke+m+rFOtfdp47EM8blvdDPxsN/UfbqlXxS989tRmr8pmcZ1CTbun3Wqu08Ibz90LldoNrxDsPGYOaJPwPwYs06N79NVHUPo41t60OurD1VLGBcW4Ekvje0kSmE2tk9Yx7yN9uyTFnVyRJ/Kq/5fbfqppU/m/ZDeQH/uueeEAd2xY0dx0NDZN998k2699VaL6xcVFYk56VOmTCF/f3+L67z11ls0c+bMGsv37Nkj5rGDkJAQMd89OTmZMjIqf7RBRESEeGHAAAMBCjExMRQaGkr79++nwsLKJC8A7cZAAbZtenLExcWRu7s77dy5s1obevfuTSUlJZSYmGhchn736dNH7O/w4cPG5ZiTHx8fT5mZmaIGoAKiCjAfA/PwMaqkoJU+nT59mrKzs8WUBrRPC32yh06IKFlWZaB39Ss09sGRfTp58qRRO9wIWSc5+hQeXhl9cfz4ccrLy9NEn5pap2ZE9K9h/vRJYqmYK3v7lztoSmdvGtfWk7y9ve3SJzwY4HrLysoSGrJOdffp1z2Vg/WR7pXba+o+jYyJpI9cnWn/2Vz6ce0OCna+JO6V2DbrVHufluxIFn93CXalpIOJdNaBffL19RXrKr9xrJPt+tQhJIQ2Pjuclm3aRynnL1KghzN1CnalqKBKg6mxferSpYt4N9WOdVJ/nyqqfudgOOP/q7VP+fn51BicKlRWuHXRokX09NNP03/+8x9x8ezdu5cee+wx4UGfNm1atXWRMO76668XB3X9+vW1GuiWPOiRkZHiIUb5Pzyqpd4+Yb8w9Fq3bi22oYU+2UOnvam5dMOnW0SN3a3PXUle7i4O7xOOL25w0E5ZpnedZOgTwDUXFRVV7cFF5j45SqdSgxP939J9xtKHV3cOpbev70aBPp427xO+g25IsopjyTrV3qfC4lLq9eY6Kiwtp9UPD6QuEc0c0qenf9pHi3en0rXx4fRIbz9xr3Rzc2Od6ujTNR9uoIPncunNiV1ocu8Ih/YJfyclJRl/41gnefqEZXg+we+cop3sfdKiTi5mbVd+52AUK9tRY59gazZv3lwY8rXZp1IZ6DCc4UWfPn26cdkbb7xBCxYsqDYaAuMc89AxErJu3TpxEKwFBw2jJg09aAyjRl5cto8WbD1F1/VoRe9N7u7o5jAMUwV+ZhduO0WvrTxIJeUGahPsQ3Nv60kdw/j3x1HsSLlAN366hZr7uNOOF64i50bOZ20oianZdO2cTeTu4kybnhsu8hgwtZOSmU9XvLNehLdDtyAfrn/OMIz6aKytqbokccjSbjqSBZTRDXPj/NixY/THH3/Uyzhn5APaY4Ta3MPH/ENJmcFY1mliD8dnb1dg7eSEdbMtGKW/rX9r+uGBASIxWHJmPk38eBMt3fNPSJ0tYN2sZ/Pxyuzt/WObO8w4B3ERgdQ9MlAM3Mz9dS9rZ2Xtc2TdV4NxztecvLB2cmLQiW6qM9DHjx8v5pyvXr2aUlJSaOnSpSK8fdKkSUbjHJndMRdh4cKFIpwgLS1NvDC/gtEeuAgxB0TrF2Nj+PtoBl0sKBXel6YuF1QXrJ2csG72AYbYqhlDaEi7YCoqNdDj3yeIyJfisuoheg2FdbOezUmZ4l0N98tpA1uL92X7L1BJaeMSC+mlvNo13RxfpQTwNScvrJ2cGHSim+oMdNQ7hwH+0EMPiYn7Tz31FN1///30+uuvi+/PnDlDK1asEPPOu3fvLhLhKC+UaGMYPbK0Kjnc+LiW5OqiusuaYZgq4PWbf2dfmjGinfgb01Ju+u9WOpP9T7Icxr4UlpTTnlPZ4vPA2GBHN0cYmzgvLhQZ6PdD6Y5ujmo5mZVPB85WZm8f1cWx5dUYhmHsieqe5P38/OiDDz4QCQCQCQ9hDJiDjgx+ALXRTdPrm76uuOIKRzefYZqcvKJS+uPgefF5korC2xmGsQwMjCdGtqd5d/ShAC83SjidTeM+2kAbqsp+MfZl18mLIqQ8PMCTopt7O7o55OHqQjf3jhCfv9l6ytHNUX14+4AYdYS3MwzD6MZAZxhzkJMAZQ3McxMwlazZn0bFZQaKDfGhrq3UlXSKtZMT1q1puLJjKK16ZLC4bjFFZeqX22n22mNkMDQsdyvrVr/w9gGxzatVKXAkt/aPIhcnou0pF+lwWmX5N0bd4e2Arzl5Ye3kRC+6abt3jCbQy8XYUJbvPSveJ3ZvpZqHTQXWTk5Yt6YjMsibfnpgIE3pG0moqfLu70fpnq93Uk5Bab23xbpZx+akLNWEtyu0auZDo7pWhm1/veWko5ujOk5lFdD+M0p4ewtSC3zNyQtrJyfOOtFN271jNAESAR46dKhGrUOG6HxuEW2q8gZN6K6+8HbWTk5Yt6bF082F3roujt6+IY48XJ1p3eF0Gjt7A+0/k1Ov7bBulye3qFSUNlM86GoBmg1rWTnAunT3GcoprP8AjR7C2/vHBFFzX/WUouNrTl5YOzkp14lubKAzqgf5BVBHEO9MdVbsPSu8br1aN6MoFcylNIe1kxPWzTHc1DuSFj84kKKCvCn1YiFdN3czfb/D+jnJrNvl2ZF8gTCDAHPPWwV6kVqAZlGexdS+hS8VlpbTT7tsW4JPdtQY3g74mpMX1k5OKnSiGxvoDCMxy6qyt6up9jnDMA2na6sAWvnwYBrRMZRKygz07OJ99MxPCVRUqm1vQVOHtw9QUXi7AqYo3d4vSnz+ZktKg3MRaDG8fd+ZHEK5es7ezjCMHmADnWEk5ej5PFFyxtXZicapzKvAMEzDCfB2o8+n9qanR3UQRskPO1Pp+rmbhaHC2Gr+uXrC2025Nj6c/DxdKSWrgP7irP6Cn/cr4e3NKVhF4e0MwzD2gg10RvUgEURMTIzmE0LUl2V7Kr3nV3QIoWYqLTnD2skJ6+Z4nJ2daPqVbenru/qJklIYjBs3ewOtPXS+jv/DutXFhfwSOnQu12jsqQlFOz8vd7qxV6RY9vXmFEc3SxWsTlRneDvga05eWDs5cdaJbtruHaMJcBGGhoZq/mKsDwh9NGZvV3F4O2snJ6ybehjcLliUYuseGUi5RWV091c76d3fjlC5hfBn1q1utp2o9J53aOFHIX7q8sSaanf7gNZi2fqjGZSSmU96xjS8fXRVlns1wdecvLB2cuKsE9203TtGEyBTY0JCguYzNtaHnScv0pnsQvL1cKWrOqmn5Iw5rJ2csG7qomWgF/1w/wCaVmW4zV53nKZ9uZ2yLhVXW491s3b+ubq85+batQn2EZFRyIG0YKu+S64p4e392qgzvJ2vOXlh7eSkXCe6sYHOqB5kaiwsLNR8xsb6sLQqvB0eBZRoUiusnZywburD3dWZZk7oSh9M7k5ebi608XgmjZ+9kfacuii+h0d9S1IW/XEsW7xb8rDrnc1VJSnVOP/c/JqbNiBavP+w8zQVlJSR3rO3j41TX3g74HulvLB2clKhE91cHd0AhmHqR3FZufGhZZKKw9sZhrE9mNLSKdyfHlywi05k5tNN/91C1/eMEOHQaTlFYp3ZO3dQeIAnvTK+M43uqk7Dpqk5n1tESRn5IlS6n8rmn1tiWPsQUW7v1IUCMZ1pSt/K7O564vSFAkpMVW94O8MwjL1gDzrDSMb6IxmUU1hKoX4eqkt0xDCM/ekQ5kfLHx5Eo7uEUWl5BS3acdponCvg7wcX7KY1VSHCegdRBUoZuwAvN5IhSeDUqikNX21O0by3yBLKQLRaw9sZhmHsBRvojOpxcXGhjh07ineGaHlV7fMJ3VuSC1wLKoa1kxPWTf34ebrRnFt6iJJcllDMuZkrD3K4u0l4+wCVDmpauuaQzd3TzZkOp+XR9uQLpFcD/RqVhrcDvlfKC2snJy460Y0NdEb1ODk5UWBgoHjXK8r80kXbT9FvB86rPnu7AmsnJ6ybHOxIuUh5RbXPT4ZZfi6nSJfGnUwJ4mq75gK83YzTmL7eclJ34e0JSnh7F/WGt/O9Ul5YOzlx0olubKAzqqesrIx27Ngh3vUIQlQHz1pHUz7fSs8t2UdlhgpydXYS5WfUjt61kxXWTQ7S84psup6Wjb3Ui4XivtknOohkuuamViWLW3MgrcY0Bi3zS9XUjL5tglRXEs8UvlfKC2snJ2U60Y0NdEYKtF5OoS7jHPNI4QUzBUb6QwvlmF+qV+1kh3VTP6F+njZdT+vh7agl7+PhKtU1h4SAMFIRRfXtNv140VfvSxPvY7upN7xdge+V8sLayUm5DnRjA51hVAoeyDB/tK7Zozy/lGH0Cww3ZGuvLdAPy/E91tMzSni7GsurWYNScu3b7adEFQ+tk3qxgBJOZxMiWEdx9naGYXQIG+gMo1Iwb9Tcc24Kzy9lGH2DJJEopQZqM9LxvdqTSdoTZD//Z/55MMnI1V1aUAt/D8q8VEJr9ld6lrWca+WdX4+Iv/u0bqb76A+GYfQJG+iM6kGmxri4OM1nbNTi/FK9aic7rJs8oM753Nt6UlhATUPmxt4Ruq+DnpRxiTLyisnD1Zl6RAWSjNecm4sz3dqvsuTa/M0ppPVcK8v2nhXLkL1e7dO4+F4pL6ydnLjoRDc20BkpcHd3J72hlfmletROC7Bu8gAjfOOzw+m7e/vR+zfG0Z0Do41Z3g06nwKjeM97RzcjTzcXaa+5m/tGkpuLE+05lU2Jqdmkh1wruUVlYrnajXS+V8oLaycn7jrQjQ10RopkEDt37tRFUgitzS/Vq3ayw7rJB8LY+7QOpPDSM/TYiFhRHz05M5/+OpZBembzcWX+ebDU1xwGYq+pSpimpZJrsuda4XulvLB2clKuE93YQGcYCeaXmqMY7XqfX8owTE2QqXxy70jxed4mbYZEWwOiB7acUHf98/qglFxbkXCWLuSXkBbgXCsMwzA1YQOdYVQeuvrC2E41lmO+Kead6n1+KcMwtRtzyIL999EMOp5+ifTIwXO5lFNYSr4erhTXKoBkp2dUIHVrFUAlZQb6fsdp0gJayLXCMAxja9hAZxiVo3hK+kQ3ow9v7k7f3dtfzDdl45xhmNqIau5NIzq2EJ+/3qJPLzoyggNMA3J1kf9xx8nJiaYOqEwWt2DrSdWGfdcHa/ug9lwrDMMwtkT+XyxG8yBTY+/evTWfsbG2EkErEysz2k4bGE0TurcSoZqyhLXrWTuZYd20odudgypDon/alUq5RaWkNzYnZUpT/9zaa258fEtq5u1GZ7ILae2h8yQrqOf+4R/H6NmfEutcT+25VvheKS+snZy46EQ3NtAZKSgp0cZ8u/qy93Q2nb5QSN7uLjS8YyjJiF61kx3WTU5MdYNh2i7UlwpKyunHnamkJ0rLDcZ5y7LMP7fmmkMm+sl9osTnrySNjNh2Iouu+XADvf/HUSo1VFDncH+x3EnSXCt8r5QX1k5OSnSgGxvojOpBpsbExETNZ2y0xMqEyvIyV3VqQd7uriQbetZOZlg3beiGkOg7qrzoX21O0URItLXsO5ND+SXlFOjtRp3CKg1ArVxzt/aLItirm45n0fH0PJKF7IIS4TGf/NlWSsrIp2BfD/poSg9aPWMwfXpbT5FbRbZcK3yvlBfWTk7KdaKbfE/8DKMT8DC9qiq8HWGNDMMw9WVSj1b09pojdOpCAf15OJ2u6lw5L10v888HxDQnZxV7XxtCZJA3jejUgn4/eF6UXHttQldS+1StZXvP0BurDlFWVU6VKX2j6LnRHSnA2038DSN8ZOcwEfWAhHCYc46wdjV7zhmGYewFe9AZRqXsSMGDSrGoZzy0vbpr+DIMo04QeXNzn8qSa/M3yxkSrfX55w1hWlXJtcW7UilPxfkFUjLz6fYvttPj3ycI4xxTLn56YAC9dV03o3GuAGMc0xFky7XCMAxja9hAZ6RA68kgLLEyodJ7PrpLGHm4ytt/PWqnBVg37eh2W//WIiR64/FMOnZenpDohlJUWk47Uy6KzwNigzV5zQ1q25xiQ3xEGP+S3WdIbaAU3Jx1x+jqD/4W5527qzM9PaoDrZ4xhHpHqzPhW0Phe6W8sHZy4qID3dhAZ1SPq6sr9enTR7zrKcHRL/vTpA9v16N2WoB105ZuCIkeWRXargcv+p5T2VRcZqBQPw9hxGrxmkN+AVT2UJLFIYxcTdFfYz/aQO/8dlQY6oPbBtNvjw2l6Ve2FYa6luB7pbywdnLiqhPdtHWnZDQJHjyys7NV9QBibzYnZYn650E+7lKHaOpROy3AumlPtzsGthHv8LbmFKg3JNoWbDEJb4chq9Vr7rqeEeTr4UonMvJFwjhHg/Pq+SX76MZPt9Cx9EvU3MedPpjcnb65uy9FB8sxUFJf+F4pL6ydnFToRDc20BnVg0yNhw8f1nzGRkvh7dd0CyNXF3kvUz1qpwVYN+3p1j8miDqG+VFhaTl9v/MUaX2AEwyUKLy9IdccjPPre7ZyeGQEHpRXJJylEe/9Rd9trzy3JveOpD+eGEYTe7SSZpCkIfC9Ul5YOzkp14lu8j75M4xGKS4rp1+rwtuvja98+GIYhmkMMJLuNJZcO6nZkmv5xWW093S2VPXPG8PtVcni1h4+T6cvFDT5/rHPafN20Izv9lDmpWIxpeD7+/rTrBviqJmPe5O3h2EYRguwgc4wKuOvIxmUV1xGYf6e1Lt1M0c3h2EYjYDs2KgLfia7kP44dJ60COY/lxkqKKKZl5h7r3XahvqKOd6I9lyw7WST5kmZuz6JRr7/F/19NIPcXZzpiZHt6edHh1C/GO0PjDAMw9gTNtAZKTw/Xl5emg6TM2Vl4jnxPi4uXPr6vXrTTiuwbtrUzdPNRdSfBvM3pWi6/rlsuTsac81NHdBavH+/47TIYG9vdp+6SONnb6RZaw5TUalB1Jpf89gQmjGindQVRxoC3yvlhbWTEyed6MYGOiNFOYX4+HhdlFUoKCmjPw6elz57ux610xKsm3Z1Q8k11JfeciKLDqflktaQcf55Y6+5EZ1aUKtAL8ouKBVzwe1FblEpvbhsH10/dzMdTsujZt5u9M6N8fTtvf0oJsSX9AjfK+WFtZMTF53oxgY6o3oMBgOlp6eLd62z9lC6SOIUFeRNcREBJDt60k5LsG7a1Q2G3KgulSXXvtJYyTVkEd9/NkfK+eeNueYw4HJ7lRcdmto6uzG2tzrxHI149y9asPWUCKe/oVcErX3yCvGudU9WXfC9Ul5YOzkx6EQ3NtAZ1YOL8MSJE5q/GE2zt4+PD9fEQ4+etNMSrJu2dTMtuXYxv4S0wtbkLGE8IlFZC39P0tM1h6zpHq7OdOBsLu0+VZkkz1ZJ4O7+aidN/3Y3ZeQVU5tgH+Exh+ccZUD1Dt8r5YW1kxODTnRjA51hVALCB9cfydBMeDvDMOqkT3Qz6tLSn4rLDLRox2nS3vxzucLbbQEypl9b9bthi8iIsnIDffZ3El39/t+07nA6ubk4iTnmvzw6RJfHl2EYpilhA51hVMJvB85TSbmB2oX6UocWfo5uDsMwGgXROXcMrCzP9c2WFGGMaYHNSZlSJoizFdOqNP153zlKzy1q8HZQpu7aOZvoXz8fFlOu+rYJol8eHSqytCPRIMMwDGNf2EBnpHiYDAgI0ETId10oyX3gPddKX/WindZg3bSvG+4zCFE+m1NEv1clppQZhF8fPX9JfO4vYZkvW1xzXVsFUM+oQFFm7rvt9Y+MyCsqpVdXHKBJn2yig+dyKcDLjd6+Po4W3dtflHNjasL3Snlh7eTESSe6sYHOqB5kauzUqZOmMzZmXSqmTcczjeXVtIIetNMirJv2dYMn9JaqkmvzNJAsDlnpQedwfxHurddrTvGiL9x2UtQqtzYJ3Jr9aTTyvb9pvkgyRzSpRyta++QwuqlPpPTlPu0J3yvlhbWTExed6MYGOqN6kAgiNTVV0wkhftmfRuWGCurayl9T5Wr0oJ0WYd30oZtScm178gU6UJX9XFa2SB7ebqtrbkzXcAr29aD0vGL69UDaZdc/m11I9369ix5YsIvScouodXNvWnB3P3p/cnexHaZu+F4pL6ydnBh0ohsb6Izq0cPFaMzeHqet5HB60E6LsG760C0swJPGdA0Tn+dvStFG/fO2+jbQ3V2d6ZZ+lZERX28+Wet6yDvwxcZkuuq9v+iPQ+fJ1dmJHr6yLf362FAa3I6TwFkL3yvlhbWTE4NOdGMDnWEcTFpOEW1PuSA+j9VQeDvDMOrnzkGVIdHLE86KqTYycia7kE5mFYhogD7RQaR3bu0XJQxu/K4s2n6Klu89IzLcI0oL7EvNoYmfbKLXVx2kgpJy6t26Gf386BB6alQHTgLHMAyjAlwd3QCG0Tur950Tc/56tW5GEc28Hd0chmF0RM+oZhQXEUCJqTmi5Nr0K9uSrOXV0A8/TzfSO6gBHxcZQLtPZtNzS/aZLPegLi0DaP2RdIKt7u/pSs9f00nUUOd55gzDMOqBPeiM6nF2dqaQkBDxru3wdu15z7WunVZh3fSjW/WSa9YnFlMTWiivZstrbs3+c8I4N+d8brGoaQ7jHDXT/3hyGE3pG8XGeSPge6W8sHZy4qwT3bTdO0YT4CKMjY3V5MV4+kKBqDmL56NrNGqga1U7LcO66Us3TK0J9nUXScKsSSymJpCBXPGgD4yVd+60ra45hLHPXHmwznVQXg9J4EL9PBu1L4bvlTLD2smJs050U13vysvL6aWXXqI2bdqQl5eXEOH1118XP8IK+Pzyyy9TeHi4WOeqq66iY8eOObTdjP1AIoikpCRNJoRYmVjpPR8Q21yTD0ta1k7LsG760s3D1YVu6ddaymRxKVkFdC6niNxdnMU0Ib1fc8jIj+NRFxfyS8R6TOPhe6W8sHZyYtCJbqoz0GfNmkVz586lOXPm0KFDh8Tfb7/9Ns2ePdu4Dv7+6KOP6NNPP6Vt27aRj48PjRo1ioqK6v5RYuQEF2FGRoYmL8aVCec0mb1dD9ppGdZNf7rdVpVYbOfJiyKJmGzh7T1bB0qd4MxW11x6XpFN12Pqhu+V8sLayYlBJ7qpzkDfvHkzTZgwgcaOHUvR0dF0ww030NVXX03bt283es8/+OADevHFF8V6cXFx9PXXX9PZs2dp2bJljm4+w1jN8fQ8OnQuVzwUj64qdcQwDOMIQv09jVUk5m1OJunKq0kc3m5LrI3E0mLEFsMwjFZQnYE+cOBAWrt2LR09elT8nZCQQBs3bqQxY8aIv5OTkyktLU2EtSsEBARQv379aMuWLQ5rN8M01Hs+tH0IBXq7O7o5DMPonDsHtRHvqxLOUUae+kuuGQwVtNVooMubIM6W9G0TROEBnlRb2jcsx/dYj2EYhlEnqiuz9txzz1Fubi517NiRXFxcxJz0N998k2699VbxPYxz0KJFi2r/D38r35lTXFwsXgrYPigrKxMvgGQDeCFkwjRsQlmOdpjOg69tOdqMrLjKdk2XA6xvzXJXV1exXdPl2C7WN29jbcu11KeWLVsaP2uhT1hfyd4+rlul91z2PllqO1C0Q7u00Cct6mS+HERERIjtm7ZT5j5pUSfztiv3SoX69qlruC/FRwRQQmoOLdyaQo9e1d7hfapr+ZG0PMrKLyFvdxfqHOZbrV9q1snSctPfOazTmHPvxWs60sPf7RXGeIWZcQ5eGd+ZnAjX9uX7qufryZo+Ybnpb5wW+qRFnSz1CctatWpVTTvZ+6RFnVzM2q7cK7GuedvV1CfzfkhvoP/www+0cOFC+vbbb6lLly60d+9eeuyxx4QY06ZNa9A233rrLZo5c2aN5Xv27BHz1wFS9iMhHTz0mNtg+pCKFzz6OTn/zMuLiYmh0NBQ2r9/PxUWFhqXY2AhMDBQbNv05EAovru7O+3cubNaG3r37k0lJSWUmJhoXIaTpU+fPmJ/hw8fNi5HQrz4+HjKzMykEydOVIsg6NSpkwjzT01NNS7XWp/wWSt92rg/hU5k5pObM1Fb78p2afHcO3nypOgTvtdKn7SoU219Qh4QrfVJizqZ98nT07PBfRrSopwSUom+2pRE9w1pQ2QoU61OPydVvveJDqID+xKk08lSn7DNxp57iCV4sr8/LTxUUi1hXJCXM93bqxmN7hpO6enpfD3ZqE/nz583/sZppU9a1MlSn5BsWmt90qJO7hb6BLsQ/1+tfcrPz6fG4FRhOgSgAiIjI4UXffr06cZlb7zxBi1YsEAcbBxYHDQI2L17d+M6w4YNE39/+OGHVnnQsZ+srCzy9/cXy3hUS719wn6Rpb9du3ZiG1ro079/OUyfbUimUV1a0Nxbe2qiT5baXlpaKm5k0E5ZJnuftKiT+XJs9/jx4zVKmcjcJ7140HGvbN++Pbm5uTWoTyVlBhr2zl+UcamEPpzcna7t3lK1Ot2/YDetPZxBz43pSPcMai2NTpaW46X8zkE7W5x7Ts4utD05i9KyCynEz4P6RDcjVxdnvp5s2Cf8fzybKr9xWuiTFnWy1CeA55O2bdtW+52TuU968aAfO3aMOnToIL5Ta59gazZv3lwY8oqtKbUHvaCgoNqFApSDB1B+LSwsTMxTVwx0HARkc3/wwQctbtPDw0O8zIGIeJmiHGRzlBPE2uXm223Icpw4lpbX1sb6LpepT3l5edXWkblPWH/1vsrpGBO6t9JEn+rqq6Kd6fZk7pMWdTJfjh9I/KiY6yZzny7Xdi30CbrhesP+GtonfHVb/2h6/4+jNG9zCk3o0UqVOpWVG2h78kXj/HOZdLK0HA91yr1S0c8WfRpQS/I8vp5s0ydT3czbJGuf6tt2WfuE+yXsh9p+52TsU0OWy9ansqrfubraroY+1dYPaZPEjR8/Xsw5X716NaWkpNDSpUvpvffeo0mTJhkPOkLe4VVfsWIF7du3j6ZOnSpCHSZOnOjo5jPMZdlzOpvOZBeSj7sLXdkh1NHNYRiGqcYt/aJEXfG9p7Npz6lKI1htHDibS3nFZeTn6UpdWgY4ujkMwzAMYzNU50FHvfOXXnqJHnroITFHCob3/fffTy+//LJxnWeeeUbE9t93332UnZ1NgwcPpjVr1oh5dwyjdlbsrZyrNrJzC/Jyl7duL8Mw2gTh0OPiw2nJ7jP01eYU6hHVjNRaXq1/THNyca4tZznDMAzDyIfq5qA3BQhpQWKAhs4LYJoWTG9AYofg4GCLoSYyUW6ooP5vrRUljL6Y1ptGdKpejUBraEk7PcG6yYktdduXmkPj52wkNxcn2vTscFEnXU3c/sU22nAsU2QkV8rDyQxfc3LCuskLaycnBkl0a6ytqd6eMUwVuACRHVHNF6K1bEvOEsa5v6crDWkXQlpHS9rpCdZNTmypW7eIAOrVuhmVllfQwm2nSE0gkd2OlAvi88Ba5ljLBl9zcsK6yQtrJyfOOtFN271jNAGyIiYkVC+hIysrE86J9zFdw8ndVfuXn5a00xOsm5zYWrc7BkaLdxjoxSY1sx0N5sYXlRqouY87tW/hS1qArzk5Yd3khbWTk3Kd6KZ9C4GRHszCQF1B2WdjlJYb6Jf9lQb6+PiWpAe0op3eYN3kxNa6je4aRi38PSjzUjGtTqy8d6mBzUmZ4n1AbHNjxnPZ4WtOTlg3eWHt5KRCJ7qxgc4wTcTG45mUXVBKwb4e4sGSYRhGzbi5ONPt/Svri8/blKKaByIlQZxWwtsZhmEYxhQ20BmmiViZUJm9fWy3MM46zDCMFEzpGyWm4+w7k0O7T2U7ujlUWFJOe6vagfrnDMMwDKM12EBnVI+Liwt17NhRvMtKUWk5/XbgvK7C27WinR5h3eTEHro19/WgCVX3rPmbU8jR7Dp5kUrKDdQywJNaN/cmrcDXnJywbvLC2smJi050YwOdUT2YYxgYGCj1XMP1RzLoUnGZeKjsqcKawvZCC9rpEdZNTuyl27SqZHG/7DtHaTlFpI7558GaOj/5mpMT1k1eWDs5cdKJbmygM6qnrKyMduzYId5lZWViZXj7uPiW5Kyj8HYtaKdHWDc5sZduXVsFUN/oICozoOTaSVLH/HNthbfzNScnrJu8sHZyUqYT3dhAZ6RA5nIK+cVltPZQVXh7nH7C27WgnZ5h3eTEXrrdMajSi/7ttlNiyo4jyC0qpcTUyvnnWky0ydecnLBu8sLayUm5DnRjA51h7Mwfh86Lmr3Rzb2payt/RzeHYRim3lzduYWYopOVX2JMeNnU7Ei+QIYKojbBPtQy0MshbWAYhmEYe8MGOsPYmZUJ/9Q+1/qcGYZhtIkrSq4NiDYmi3NEyTUlvF2L3nOGYRiGUWADnVE9yNQYFxcnZcbGnIJS+utouu6yt2tBOz3DusmJvXW7uU8kebg604GzubTz5EVqarQ6/xzwNScnrJu8sHZy4qIT3WxioL/yyit08qRjE8cw2sbd3Z1k5NeDaVRaXkEdWvhR+xZ+pEdk1U7vsG5yYk/dmvm406QercTn+ZuatuTahfwSOnQuV3zuH6M9Ax3wNScnrJu8sHZy4q4D3WxioC9fvpxiY2NpxIgR9O2331JxcbEtNsswxmQQO3fulDIphDJXc3x8OOkRmbXTM6ybnDSFbkrJtTUH0uhsdiE1FVtPVHrPO4b5UbCvB2kNvubkhHWTF9ZOTsp1optNDPS9e/eKlPddunShRx99lMLCwujBBx8UyxhGr2ReKjaGZI7TYfZ2hmG0R6dwf+ofE0Tlhgr6ZutJB9Q/16b3nGEYhmFsPge9R48e9NFHH9HZs2fpiy++oNTUVBo0aJCYJ/Dhhx9STk6OrXbFMFLwy75z4iE2LiKAooN9HN0chmEYm3DHwDbi/bvtTVdy7Z/558FNsj+GYRiG0UySOGR2LS0tpZKSEvG5WbNmNGfOHIqMjKTvv//e1rtjGPVnb2fvOcMwGmJk5xbUKtCLsgtKafneM3bfX1pOEZ3IyCdnJ6K+bYLsvj+GYRiG0YSBvmvXLnr44YcpPDycHn/8ceFRP3ToEP3111907NgxevPNN2nGjBm22h2jI5CpsXfv3lJlbDyXU0jbUy6Iz2Pj9Dn/XFbtGNZNVppKNxdnJ5o2sLX4PG+T/UuubTlRGd7etVUABXi5kRbha05OWDd5Ye3kxEUnutnEQO/WrRv179+fkpOTRXj76dOn6d///je1bdvWuM6UKVMoIyPDFrtjdAgiMmRidWKl97xvdBC1DPQiPSObdkwlrJucNJVuk3tHkZebCx1Oy6NtyZWDkfZi83F91D/na05OWDd5Ye3kpEQHutnEQL/pppsoJSWFVq9eTRMnTrQ4qhEcHEwGg8EWu2N0BjI1JiYmSpWxUe/Z22XWjmHdZKUpdQvwdqNJPe1fcg3eeT3MP+drTk5YN3lh7eSkXCe62cRAf+mll6hVq8ofaobROyez8ikhNUfMlxzTTd8GOsMw2uWOqpJrvx1Mo9MXCuyyj9MXCulMdiG5OjtRn+hmdtkHwzAMw2jOQL/++utp1qxZNZa//fbbdOONN9piFwwjDauqwtsHtQ3WZL1ehmEY0L6FHw1q25wMFUQL7FRyTSmv1iMqkLzdXe2yD4ZhGIbRnIH+999/0zXXXFNj+ZgxY8R3DNNYZEoGYQxv5+zt0mnH/APrJidNrdudJiXXCkrKbL59Jbx9gIbD2xX4mpMT1k1eWDs5cdGBbjYx0C9dukTu7u41lru5uVFubq4tdsHoGFdXV+rTp494VztHz+eJpEluLk40qksY6R2ZtGP+gXWTE0fodmXHUIoK8qbcojJatqdycNKW88+3nFDmn2s7QRxfc3LCuskLaycnrjrRzWZZ3C3VOF+0aBF17tzZFrtgdAwe0rKzs+1eyscWrKryng9rHyKSKOkdmbRj/oF1kxNH6IaSa1MHVJZcm7852ab7Tsq4RBl5xeTh6ixC3LUMX3NywrrJC2snJxU60c1mSeJef/11mjZtGn311VfiNXXqVFH7HN8xTGNApsbDhw+rPmMjbhYrq+afj4/n8HaZtGOqw7rJiaN0u7F3JHm7u9DR85doS1VIui3D2/tEB5GHq7ZDGvmakxPWTV5YOzkp14luNjHQx48fT8uWLaPjx4/TQw89RE8++SSlpqbSH3/8IcquMdqn3FAhHsyW7z0j3vG33jhwNpeSM/PJ082ZrurUwtHNYRiGaRICvNzo+p4R4vOXNiy5ppf65wzDMAxjis0C+MeOHStejP5Ys/8czVx5kM7lFBmXhQd40ivjO9PorvopM6YkhxvRsQX5eGh7bgzDMIwp0wZG0zdbT9Law+fpVFYBRTX3btT2DAb9zD9nGIZhGJt70Bl9G+cPLthdzTgHaTlFYjm+byxOTk7k5eUl3tUKHiaV8mrj4/UzKKEF7ZiasG5y4kjd2ob60tD2IYRpgV9vabwX/eC5XMopLCVfD1fq1iqAtA5fc3LCuskLaycnTjrRzSYGOuYBvPPOO9S3b18KCwujoKCgai9GmyCMHZ5zS8HsyjJ839hwd5RTiI+PV3VZhT2nL9KZ7ELxMHlFh1BHN0c1yKAdUxPWTU4crdudA6PF+/c7T1N+ceNKrilz2fu1CSJXF+37EhytHdMwWDd5Ye3kxEUnutnkV2/mzJn03nvv0eTJkyknJ4eeeOIJuu6668jZ2ZleffVVW+yCUSHbky/U8JybArMc32O9xmAwGCg9PV28q5UVeyvD26/u3II83bR909CadkxNWDc5cbRuqF4R3dyb8orKaMmeM43a1uakTF3NP3e0dkzDYN3khbWTE4NOdLOJgb5w4UL6/PPPRXI41KWbMmUK/e9//6OXX36Ztm7daotdMCokPa/IpuvVBi7CEydOqPZiLCs30Op9nL1dRu0Yy7BucuJo3ZydncRcdDB/U8NLrpWWG4wDuwNjg0kPOFo7pmGwbvLC2smJQSe62cRAT0tLE7XQga+vr/Cig3HjxtHq1attsQtGhYT6edp0PVnZlnyBMi+VUKC3Gw1up4+HSYZhGEvc0CuCfNxdKCkjnzYcq/SC15fE1BzKLymnZt5u1DHMz+ZtZBiGYRjNG+gRERF07lylBzE2NpZ+++038XnHjh3k4eFhi10wKqRvmyCRrb2uNA34HuvpIXv7mK7h5KaDuZIMwzC14efpJuqig/mbG5YsbotJeDu88gzDMAyjJ2xiTUyaNInWrl0rPj/yyCP00ksvUbt27Wjq1Kl011132WIXjApxcXYSpdTq4smR7cV6jQGZGgMCAlSZsbGkzEC/7E8Tnzl7u1zaMbXDusmJWnSbOqC1eF93OJ2SM/Pr/f83VyWIG6CT8HY1acfUD9ZNXlg7OXHSiW5OFQ2dJFYHmHe+efNmYaSPHz+e1EZubq4QF6H4/v7+jm6O9KCU2uPfJ1BhablxGYxyZG8f1LY5fXVnX81m4V13+DzdNX8nhfh50NbnRzR6MIJhGEYL3DlvO/15JIPuHBRNr4zvYvX/Kyotp7iZv4nBz7VPDqPYEF+7tpNhGIZh1GZrNtpqKi0tFV7y5ORk47L+/fuLTO5qNM4Z2zO6azi1C/URn+8aFE3f3dufVj48mLzdXWjT8Sz69y+HG7V9JIJITU1VZUKIlQmVUzvGdgtn41wy7ZjaYd3kRE263TGojXj/cWcqXapHybXdpy4K47yFvwfFBFf+rugBNWnHWA/rJi+snZwYdKJbow10Nzc3Wrx4sW1aw0iJwVBBx9Irwxhv7d9azBvs3NKf3r0xXiz738ZkWtaIkjtqvRjh6fntgBLeztnbZdKOqRvWTU7UpNuQtsEUE+IjjPPFu1LrXf8c2du1HsKoVu0Y62Hd5IW1kxODTnSzSdzxxIkTadmyZbbYFCMhqRcLRXi7u6sztQ7yNi4f0y2cHr6yrfj87OJE2n+mMru/VvjzcLrINNwq0It6RgU6ujkMwzCqAcnd7lBKrm1OEQO59Zp/HqOP+ucMwzAMY44r2QDMNX/ttddo06ZN1KtXL/LxqR6WNmPGDFvshlEpR87nife2Ib415po/PrI9HTyXK5IF3ff1TlrxyGAK9tVGZv+ViZXZ28fFh+vK08MwDGMN1/WMoP+sOSISxf11LIOu7BBa5/rwtieczhafEYnFMAzDMHrEJgb6F198QYGBgbRr1y7xMgWGCxvo2uZolYHewUK9WszLfn9yd5r48SbxkDZ94W5acE+/epUjc3Z2ppCQEPGuFvAgufZQuvg8Po7D22XSjrk8rJucqE03Xw9XUXLty03JNH9TymUN9B0pF6jMUEGRQV4UaRKNpQfUph1jHaybvLB2cuKsE91sYqCbJohj9MeRtEoDvX2LmgY6CPByo8+n9qKJH2+mbckX6M3Vh+jVa63P6ouLMDY2ltTEHwfPU3GZQSQx6tKSKwHIpB1zeVg3OVGjbtMGtqZ5m5Ppr6MZlJRxqc6s7FuV+ecx+imvpmbtmMvDuskLaycnzjrRTdvDD0yTGugdwmp/8Gob6kfv3RRvnI/4487TVm8fiSCSkpJUlRBiZYIS3t6Sw9sl0465PKybnKhRt9bNfWhEx0rP+debU6yafz6wrf7C29WoHXN5WDd5Ye3kxKAT3WziQUeZtbr48ssvbbEbRoWgHA68IqBDWN2e5Ku7hNGjI9rRh2uP0QvL9guPe3zk5ZOr4SLMyMig1q1bqyKkJbughP4+liE+j48Ld3RzVI3atGOsg3WTE7XqdsfANvTHoXT6aVcqPTmqA/l7utVYJ6eglPafzdFtgji1asfUDesmL6ydnBh0optNenbx4sVqr/T0dFq3bh0tWbKEsrMrE74w2iQlK1/MGcRcw5YBnpddHwb6VZ1aCMP+/m92UUZeMcnGrwfSqLS8gjqG+VG7WsL6GYZhmEoGtW1ObUN9RdUL1EW3xNbkLKqoQLSVL4X6X/63hGEYhmG0ik086EuXLrU4wvHggw/qYp6Anvln/rmvVaHeKL3z/uR4kTQuKSOfHlq4ixbe01+UaJOFlQnnxDvXPmcYhrk8+G1AybUXl+2nrzaniM9IIGq5/rn+vOcMwzAMY4rdrCKEHTzxxBP0/vvv22sXjMozuNeGn6cbfTa1N/l5uNKOlIv02qoDlz2XIiIiVBHKAo//5qRM8Zmzt18eNWnHWA/rJidq1u26nq3I39OVTl0ooPVHKitgmKLcV/VqoKtZO6Z2WDd5Ye3kxFknutm1d5jEX1ZWZs9dMCrP4F4byOT74ZTuBKf7gq2naNH2U1JcjD/vO0eGCqLukYEU1VxfZYAagpq0Y6yHdZMTNevm7e5KN/eNMiYKNR/4PHr+kvg96NeGDXRGHlg3eWHt5MRZJ7rZJMQdnnJTKioq6Ny5c7R69WqaNm2aLXbBqN2D3oC52MM7tqAnR7and347Si8vPyDmc/dq3azGeuXl5XT06FFq3749ubi4kBqyt3N4u3WoSTvGelg3OVG7brf3b03/23CCNhzLpGPn84w5PLacqAxv7xzuT8183EmPqF07xjKsm7ywdnJSrhPdbDL8sGfPnmqvxMREsfzdd9+lDz74wBa7YFRIYUk5nbxQID63r0eIuynTr2xLY7qGUUm5gR5csIvO5xbVWAcDPjk5OeLdkZzJLqSdJy8KL8/Ybpy93RrUoh1TP1g3OVG7bpFB3iJJKPhqyz9e9C06D2+XQTvGMqybvLB2clKhE91sYqD/+eef1V5r166lRYsW0X333UeurvVz0kdHR4uEMuav6dOni+/T0tLo9ttvp7CwMPLx8aGePXvS4sWLbdENpp4cT78ksu4293GnYF+PBm0D2r5zY7xIMpeeVyyM9OKyclIjqxMrved9o4MozIqM9QzDMEx17hgULd4X7zojSqtVq38eG+zQtjEMwzCMZgz05ORkOnbsWI3lWJaSUn2u2eXYsWOHCI9XXr///rtYfuONN4r3qVOn0pEjR2jFihW0b98+uu666+imm24SnnumaTlyvmHzz83x8XClz27vLRII7T6VTa8sP6DKkTHO3s4wDNM4UOMcU6IKS8vph52nKfViAZ3MKhBZ3fu0CXJ08xiGYRhGGwb6HXfcQZs3b66xfNu2beK7+hASEiK848pr1apVolTbsGHDxPfYzyOPPEJ9+/almJgYevHFFykwMJB27dpli64w9eBIWm69M7jXRnSwD82+pSeh8s6iHadp4bZ/ksYhEQS0dmRCiOTMfNp3Jkc8RCIkn7EONWjH1B/WTU5k0E2UXKvyos/fnExfV4W6xwR7k5ebducTakE7piasm7ywdnLirBPdbJIkDt7rQYMG1Vjev39/evjhhxu83ZKSElqwYIFIQqfU2B44cCB9//33NHbsWGGY//DDD1RUVERXXHFFrdspLi4WL4Xc3ErDEhnmlSzzEBov1G/HS0FZjqQEpl7d2pYjYQHaap69XklkgPWtWY6pAdiu6XJsF+ubt7G25fbuk5LBvW2Id7XvGtqnQTHN6MmR7eg/vx2jV1ccEIZ/r6hA8V1QUJCxD47QSUkONzA2iAI8XYz/TwadHHnuAUU7vLTQJy3qZGl5aGio2LZpO2XvkxZ1Mm87rjcFtfZpXNcW9Pqqg3Qmu4g++ztZLDuWnk+D/r2WXh7Xma6Ja6l5nSwtV+6VytQ+LfTJtI1a7BOWm/7GaaFPWtSptj7BKYj1Tbcve58stV1rfQoKChLrmrddTX1qbBUzmxjo6GBeXqWxZgom8ZsfuPqwbNkyys7OruaFh0E+efJkat68uRDB29ubli5dSm3btq11O2+99RbNnDnT4sAC5rEDXKTw1CNcPyMjw7gOUvnjhYyB6I8CRm/wALt//34qLCw0Lu/YsaMYOMC2TfseFxdH7u7utHPnzmpt6N27txiIUBLrAZwsffr0Efs7fPiwcbmXlxfFx8dTZmYmnThxwrg8ICCAOnXqRGfPnqXU1FTjcnv36UjaJfFuuJhKO3eet0mfenpVUP9W7rT1TAk9uGA3fXZDDBVfPC/OLz8/P9E+R+i0MqFygKeLb5HxO1l0cuS5h3Xxgna4T2ihT1rUybxPLVu2pIsXL5Kbm5txQFP2PmlRJ/M+4cEA90q0ERFoau3T9rPFVFBS89kgLbeYHvp2D33q7EStXbI1q5OlPhUUFBh/57BtLfRJizqZ9wl6IfeSr6+v0ZEke5+0qJOlPnXt2lVMxYWTT9FO9j5pUac4sz4pv3NwzMIIVmuf8vPzqTE4Vdhgsu/48eNF57/77rtqIx0wpNHAX375pUHbHTVqlBBl5cqVxmUIb9++fTv961//ouDgYGHEv//++7Rhwwbq1q2b1R70yMhIysrKIn9/f7GMR7Xq16ecwlLq9eY68XnPiyPIz9PVZn0qKCmjmz7bTofT8iguIoAW3NGTDuxLEAkBYTA0tU4oJXfN7M3k7uJMW5+7gvy93KTRydHnHn4QMP0E2ineBtn7pEWdzJfj8+7du6lHjx7VypjI3Cct6mTedrxDt169eonfTjX2qdxQQcPe+UsY45bAYzKScP711DAx5am2vqqpT7Y499B+aId7JbTTQp+0qJN5n7AMuZOU3zgt9EmLOlnqE9aB0Weqnex90qJOLmZtV37nMOiA9qu1T7A14UyGIa/Ymk3uQZ81axYNHTqUOnToQEOGDBHLYDCjcevWVRpx9eXkyZP0xx9/0JIlS4zLkpKSaM6cOWKEokuXLmIZRkSwr48//pg+/fRTi9vy8PAQL3MgonmWeeUgm2N68VqzvLbs9fVZjhPH0vLa2ljf5Y3p04msSq9aq0AvaubradM++bu60udTe9P4ORspMTWHZq4+QjdE/RNOZq8+1bb85/3p4n1YhxAK8vNqUJ8as1z2c0+5AZpuT/Y+aVEn0+XKD6S5bjL36XJt10qfsC9lHTX2aUdSVq3GOcCjzbmcItp1KocGWCi7psY+2eLcw0Odcq9UvHmy96mxbZelT5Z+42pruyx90qJO5m3B71xt2llaX4Y+NWS5jH1yMqnypdY+1beKWY19kw3o3LmzCDFANvX09HQReoBs6wgvQAhJQ5g3b54IF8BccwWEgIlGmx0sZfSDaTqU+ecoj2averlzplQmjVu85yz9mlyzPnpTgIemlVXl1Th7O8MwTONIzyuy6XoMwzAMozVs4kFX5iwi7NwWwNiGgT5t2rRqIxCYn4C55vfffz+98847InQAIe4oxYZs70zTgbBv0N4GGdxrY3C7YPq/azrRG6sP0Tf7CmhUv2wa0MR1cpG5HSWAkF34qk6hTbpvLYDBM1y3tY02MuqEdZMTGXQL9fO06XpaQQbtmJqwbvLC2smJi050s4kHHcb0jz/+WGM5ln311Vf13h5C20+dOkV33XVXteWYf/zzzz+LyfuY947EAV9//bXYxzXXXNOoPjAN86Cjnq09uXtwG5rYvSWVVxBN/3YPncn+J6FEU6Bkbx/RKZS83W02nqUbEGaEpB+mCVgY9cO6yYkMuvVtE0ThAZ5irrklsBzfYz09IYN2TE1YN3lh7eTESSe62cRAR5Z0JGwzByHqDfGqX3311SK0uH379jW+a9euHS1evJjOnz8vEtAlJCTQ7bff3uC2M/UH2hg96HY20HEBvn5tZ2oT6EoX8kvo/m92UlFpwysD1AeDoYJWJZ4Tnzm8vWFgjhcS6DS23ATTtLBuciKDbi7OTvTK+M7is/njlfI3vsd6ekIG7ZiasG7ywtrJSZlOdLOJgQ5vd5s2bWosb926tfiO0RYZl4rpYkGpmB/eNtQ+c9BN8XJ3oSf6+lIzbzfafyaXnl+yr1r2RHux69RFkazIz8OVhrUPsfv+tEpjSi0yjoN1kxMZdBvdNZzm3tZTZGs3BX9jOb7XIzJox9SEdZMX1k5OynWgm01iduEpR5K46Ojoasvh3cY8cUab4e3RzX3I061p5oCEeLvQ7Ju707T5O2npnjPUpaU/3TMkpknC20d1DWuyfjIMw+gBGOEjO4fR9uQLIiEc5pwjrF1vnnOGYRiGsYsHfcqUKTRjxgz6888/xagGXiiv9uijj9LNN99si10wqszgbt/wdnP6xwTRi2M7ic9v/XKYNh3PtNu+ysoN9PM+Dm9nGIaxFzDGUUptQvdW4p2Nc4ZhGIaxkYH++uuvU79+/WjEiBHk5eUlXphHPnz4cHrzzTdtsQtGRSjzzzvYMYO7KcjUiISAeL9jYDRd3zOCyg0V9PC3u+n0hcrSe7Zmy4ksyrxUQkE+7jTQQi1epv7aMfLAuskJ6yYvrJ2csG7ywtrJiYtOdLOJge7u7k7ff/89HTlyhBYuXEhLliyhpKQk+vLLL8nDw8MWu2BUxJHzl5rUQFfOMSVp3JuTulJcRICYB3/fN7uooKTMbuHtY7qGkZuLTS4T3aJox8gF6yYnrJu8sHZywrrJC2snJ+460M2mlgcyrN944400btw4atasGc2dO5d69+5ty10wDgaZzY81UQZ3BUyZ2LlzpzEpBOaDf3pbLwr2dadD53LpmZ8SbZo0rrisnNbsTxOfObzdttoxcsC6yQnrJi+snZywbvLC2slJuU50s7lrEPPQUfYsPDzcGPrOaAfUIS8oKSd3F2eKbu7tsHa0DPSiT27tRa7OTqIU2md/n7DZtjcczaTcojJq4e9BfaL1VYuXYRiGYRiGYRjJs7ifOXOG5s+fT/PmzaPs7Gy6ePEiffvtt3TTTTdpvpC8XhPExYb6kquDQ7+R8feVa7vQS8v206w1h6ljuL9NyqGtTKwMbx/brSUnLWIYhmEYhmEYpslolIW1ePFiuuaaa6hDhw60d+9eevfdd+ns2bPk7OxM3bp1Y+NcgxxREsS1sH/9c2u4rV8UTe4dSYYKoke+3U0ns/Ibtb3CknL6/eB58Xl8vD5r8TIMwzAMwzAMI6GBPnnyZOrRowedO3eOfvzxR5owYYIuJu7rGSWDe/smTBCHTI3IZWApYyMGgV6b2IV6RAWKsPT7vt5F+cUNTxq37nC6COGPaOZF3SMDG9lypi7tGPXCuskJ6yYvrJ2csG7ywtrJiYtOdGuUgX733XfTxx9/TKNHj6ZPP/1UhLYz+ghx79DENdBLSkpq/c7DtTJpXIifh/DwP/VjQoOTxinZ25EcjiNA7K8do15YNzlh3eSFtZMT1k1eWDs5KdGBbo0y0P/73/8K7/l9991H3333nUgMBy86jCODwWC7VjKqoLTcQEkZl5o0gztApsbExMQ6Mza28PekT2/rSW4uTvTL/jT6ZH1SvfeTV1RK646ki8/j4zh7e1Npx6gP1k1OWDd5Ye3khHWTF9ZOTsp1olujs3x5eXnRtGnT6K+//qJ9+/ZRly5dqEWLFjRo0CC65ZZbRE10RhukZOZTaXkF+bi7UKtAL1IbvVoH0WsTuorP7/x2hP48XGlsWwvmnpeUGSg2xIc6hTdthADDMAzDMAzDMIzN66D/61//otOnT9OCBQuooKCApkyZYstdMCpIEIf5584qzW4+pW8U3dovihDhPmPRHjpR5fG3Bg5vZxiGYRiGYRjGkdilThayuI8fP56WLVsmjHVGGxx10PxzUJ9kEK+M70K9WzejPCSN+2aXCF2/HBfzS2jDsUzxeRyHt9sUrSfy0Cqsm5ywbvLC2skJ6yYvrJ2cuOhAN7sXsg4NDbX3Lpim9qA3sYHu6upKffr0Ee/W4O7qTJ/c1pNa+HvQ8fRL9MQPCWRAHbY6WHMgjcoMFdQ53J/ahqqjhJwWqK92jDpg3eSEdZMX1k5OWDd5Ye3kxFUnutndQGe0w9HzleHiHZqwxBpA0sHs7Ox6ZWYP9fOk/97em9xdnMXc8tnrjlsV3n5td/aeO1o7xvGwbnLCuskLaycnrJu8sHZyUqET3dhAZ6yiqLScUrLyHeJBR6bGw4cP1ztjI+qYvzGpMmnc+38cFYa6JdJzi2jLiSzxeWy3cBu0mGmsdoxjYd3khHWTF9ZOTlg3eWHt5KRcJ7qxgc5YBULFMVgV5ONOwb7uJAs39Y6kaQNai8+Pf79X9MOc1fvOib71jAqkyCBvB7SSYRiGYRiGYRjGRgZ6TEwMZWVVeiBNQQgCvmPk50hVgrj2LXyly3D+4rjO1LdNEF0qLqP7vt5JuWZJ40yztzMMwzAMwzAMw0htoKekpFgMNSguLqYzZ87YYheMgzl63nEZ3DEg4OXl1eCBATcXZ/rk1p7UMsCTTmTm02OL9lJpmYG2JGXRvI3JtPtUtliPw9vVpx3jGFg3OWHd5IW1kxPWTV5YOzlx0oluThWNmGW/YsUK8T5x4kT66quvKCAgwPgdDPa1a9fS77//TkeOHCE1kZubK9qak5ND/v7+jm6OFEz7cjv9dTSD3pzUlW7tVxkyLhv7UnPohk83U3GZgXw9XOhS8T+DSkgm99GU7jS6KxvpDMMwDMMwDMM4xtZsVI56GOYAoxjTpk2r9p2bmxtFR0fTu+++25hdMCrBkR50g8FAmZmZFBwcTM7ODQ/66BYRQFP6RtL8zSerGeegpNxADy7YTXNv68lGugq1Y5oW1k1OWDd5Ye3khHWTF9ZOTgw60c25sQcJr6ioKEpPTzf+jRfC2+E5HzdunO1ayziEnMJSOpdTJD63b+ISawDn04kTJ8R7Yyg3VNCvByxncleYufKgWI9Rl3ZM08K6yQnrJi+snZywbvLC2smJQSe62WToITk5WYxkmCeIY7TBsSrvOeZw+3u6kaxsT75gHGiwBMxyfI/1GIZhGIZhGIZhpDTQZ82aRd9//73x7xtvvJGCgoKoVatWlJCQYItdMA7kSJWB7gjvuS1Jzyuy6XoMwzAMwzAMwzCqM9A//fRTioyMFJ+RFO6PP/6gNWvW0JgxY+jpp5+2xS4YB3I0zXHzz5UcB0i00NiMjaF+njZdj2k67ZimhXWTE9ZNXlg7OWHd5IW1kxMnnejWqCRxCmlpaUYDfdWqVXTTTTfR1VdfLZLE9evXzxa7YNTgQXeQge7i4kKdOnVq9HZQCz08wJPScopEOLs5uNTDAjzFeoy6tGOaFtZNTlg3eWHt5IR1kxfWTk5cdKKbTTzozZo1o9OnT4vP8JxfddVV4jMquFmqj87IAzQ8onjQHRTijkQQqampjU4I4eLsRK+M7yw+m4+7KX/je6zHqEs7pmlh3eSEdZMX1k5OWDd5Ye3kxKAT3WxioF933XV0yy230MiRIykrK0uEtoM9e/ZQ27ZtbbELxkFkXiqhiwWlhEiStqG+0l+MKKGGUmrwlJuCv7nEmu3Ry41Ua7BucsK6yQtrJyesm7ywdnJi0IluNglxf//990U4O7zob7/9Nvn6Vhpy586do4ceesgWu2AcXP88urkPebq5kBaAET6yc5jI1o6EcJhzjrB29pwzDMMwDMMwDCO9ge7m5kZPPfVUjeWPP/64LTbPOJDDVeHt7Vs4xntuL2CMD4ht7uhmMAzDMAzDMAzD2DbEHXzzzTc0ePBgatmyJZ08eVIs++CDD2j58uW22gWjwwzuwNnZmUJCQsQ7IxesnZywbnLCuskLaycnrJu8sHZy4qwT3WzSu7lz59ITTzwh5p5nZ2cbE8MFBgYKI52RP4N7hzB/h7UBF2FsbKzmL0YtwtrJCesmJ6ybvLB2csK6yQtrJyfOOtHNJr2bPXs2ff755/TCCy+I9PcKvXv3pn379tliF4wDMBgq6JjRQHdciDsSQSQlJWk+IYQWYe3khHWTE9ZNXlg7OWHd5IW1kxODTnSziYGenJxMPXr0qLHcw8OD8vPzbbELxgGcyS6k/JJycndxptbNfRzWDlyEGRkZmr8YtQhrJyesm5ywbvLC2skJ6yYvrJ2cGHSim00M9DZt2tDevXtrLEdNdD0Uk9d6BveYEB9yc9F2KAnDMAzDMAzDMIzUWdxfe+01kb0d88+nT59ORUVFVFFRQdu3b6fvvvuO3nrrLfrf//5nu9YyDpp/7rgEcQzDMAzDMAzDMHqhUQb6zJkz6YEHHqB77rmHvLy86MUXX6SCggK65ZZbRDb3Dz/8kG6++WbbtZZxSAb39g7M4A6QCCIiIkLzCSG0CGsnJ6ybnLBu8sLayQnrJi+snZw460Q3pwq4vBsIDk5aWhqFhoYal8FAv3TpUrVlaiM3N5cCAgIoJyeH/P0dl51c7Yz5cAMdOpdL/5vam67q3MLRzWEYhmEYhmEYhlE1jbU1Gz384OTkVO1vb29vVRvnjHWUlRsoKf2SKkLcUbbv0KFDxvJ9jDywdnLCuskJ6yYvrJ2csG7ywtrJSblOdGtUiDto3759DSPdnAsXLjR2N0wTk5KVTyXlBvJ2d6FWgV4ObQuCPDAC1YhgD8ZBsHZywrrJCesmL6ydnLBu8sLayUmFTnRrtIGOeehw4TPa4khapfe8XQs/cnauewCGYRiGYRiGYRiGUYGBjiRwHNKu4QzuLXwd3RSGYRiGYRiGYRhd0Kg56JcLbWfkz+DeIczxSfSQjDAmJkbzGRu1CGsnJ6ybnLBu8sLayQnrJi+snZw460S3RnnQtR7/r2eOGj3ojq+BjouQozTkhLWTE9ZNTlg3eWHt5IR1kxfWTk6cdaJbo4YfDAaDLg6S3igqLRdJ4kD7MMeHuCNTY0JCguYzNmoR1k5OWDc5Yd3khbWTE9ZNXlg7OSnXiW7ajg9gGsTx9EtkqCBq5u1GIb4ejm6OiNQoLCzkiA0JYe3khHWTE9ZNXlg7OWHd5IW1k5MKnejGBjpTa3h7+xZ+nGeAYRiGYRiGYRimiWADnak9g3uY4+efMwzDMAzDMAzD6AXVGejR0dHCa2v+mj59unGdLVu20PDhw8nHx4f8/f1p6NChItyBsW0Gd3jQ1YCLiwt17NhRvDNywdrJCesmJ6ybvLB2csK6yQtrJycuOtGt0XXQbc2OHTuqTfzfv38/jRw5km688UajcT569Gh6/vnnafbs2eTq6iqSBWg93X5TcsRYYk0dBjoGaAIDAx3dDKYBsHZywrrJCesmL6ydnLBu8sLayYledFOdVRsSEkJhYWHG16pVqyg2NpaGDRsmvn/88cdpxowZ9Nxzz1GXLl2oQ4cOdNNNN5GHh+OTmWmB3KJSOptTJD63D1WHgV5WViYGbvDOyAVrJyesm5ywbvLC2skJ6yYvrJ2clOlEN9V50E0pKSmhBQsW0BNPPCFGTNLT02nbtm1066230sCBAykpKUmEObz55ps0ePDgWrdTXFwsXgq5ubniHeIqAsMDjxdKx+GloCyHV980Y2BtyxFygbaanzhKKIZ5WYDaliMyANs1XY7tYn3zNta2vCF9OlY1/7yFvwf5uFf2w9F9wvrYN95ZJ/n6pGinpT5pUSfT5cp1Z75PmfukRZ3M267cK5V1tNCnyy3XSp9Mf+e00ict6mTeJ2D6G6eFPmlRJ0t9wjrm2sneJy3q5GLWduVeif9r3nY19amxAwiqNtCXLVtG2dnZdMcdd4i/T5w4Id5fffVVeuedd6h79+709ddf04gRI0QofLt27Sxu56233qKZM2fWWL5nzx4xj13x3MNTn5ycTBkZGcZ1IiIixOvo0aOUk5NjXB4TEyNqwGO/pvPfMWCA0Ats2/TkiIuLI3d3d9q5c2e1NvTu3VsMRCQmJhqX4WTp06eP2N/hw4eNy728vCg+Pp4yMzONxwIEBARQp06d6OzZs5Sammpc3pA+HUmr9J6HeRqMbXV0n06fPi3Og927d4tjzjrJ06eTJ08atcONUAt90qJO5n0KDw8X78ePH6e8vDxN9EmLOpn3CQ8GuN6ysrKEhlrokxZ1stSngoIC470S29ZCn7Sok3mffH19xbrKb5wW+qRFnSz1CVG4wFQ72fukRZ3izPqk/M7BcMb/V2uf8vPzqTE4Vai4kNyoUaOEKCtXrhR/b968mQYNGiTmn//rX/+qJt7YsWOFIW6tBz0yMlI8xCDJHOBRrcrlr606RPM3p9A9g6PpudEdVNGn0tJScQPt2bMnubm5sU4S9Qk/CLt27RLaYT0t9EkvHnRccz169DDuX/Y+6cWDDt169eolfju10KfLLddKn9B+5XcO2mmhT1rUybxPWIZwW+U3Tgt90pMHHUafqXay90kvHvTdu3eLQQe0X619gq3ZvHlzYcgrtqYmDHR43jAisWTJEpowYYJYhpEMLPvmm2/otttuM647efJkIcjChQut2jYOGkZNGnrQtMyUz7bSlhNZ9M6N8XRDrwhSAzhFMSKFETCuyy4XrJ2csG5ywrrJC2snJ6ybvLB2clIhiW6NtTVVlyROYd68eSJcAJ5x0xJsLVu2pCNHjlRbF6EGrVu3dkArtcdRpQa6SkqsKcCjwMgJaycnrJucsG7ywtrJCesmL6ydnLjrQDdVGugIJ4CBPm3aNOEZV8BIydNPP00fffQR/fTTT2J+5EsvvSTmGdx9990ObbMWyLxUTFn5JYQBqbahvqQWEDKCMCTzMBZG/bB2csK6yQnrJi+snZywbvLC2slJuU50U2WSuD/++INOnTpFd911V43vHnvsMSoqKhLl1i5cuCAm/f/+++9iMj/TOI5W1T9vHeRNXu7/zMdhGIZhGIZhGIZhdGqgX3311dUm35uDGuh4MbblSFV4e3uVhbczDMMwDMMwDMPoAVWGuDOO4UiVB71DGBvoDMMwDMMwDMMwTY1qs7jbE87ibplJn2yiPaeyafaUHjQ+viWpBaVcglKCgZEH1k5OWDc5Yd3khbWTE9ZNXlg7OamQRDfNZnFnmv6EP6piDzrqaTNywtrJCesmJ6ybvLB2csK6yQtrJyclOtCNDXRGcCa7kPJLysnNxYna/H97dwImVXXmf/yt6qYXaOhm6aZBQBZlM4IiuP4VRIWoY0jimMRlAmrclxiNyWSeKDBZMMm4ZcYYnwzBTIwmMUOISzIuETQTNbIpUaGRRRbZGrBZmm6gu+r/vEduTVVRDU2j1H3P/X6epyj61u3qe+rXt6vee849t1sHCRM9UrZo0SLvZ2z0EdnZRG42kZtdZGcTudlFdjY1RyQ3CnRkXP98QGWZtCvg1wIAAAAAjjQqMTg1G3a6e2ZwBwAAAID8oEBHRg96GM8/VzoZBGwiO5vIzSZys4vsbCI3u8jOpoII5MYs7szi7lzw4F/k3fXb5WdfHinnDe2e780BAAAAAHOYxR2Hrak5IctqPxriPiiEQ9z1GFJdXZ27hy1kZxO52URudpGdTeRmF9nZlIxIbhTokFVbd8mepoSUtiuQXp1LJWx0psYlS5Z4P2Ojj8jOJnKzidzsIjubyM0usrOpOSK5UaBDavZd/3xg9zKJx2P53hwAAAAAiCQKdKQV6OEb3g4AAAAAUUGBjtDP4B6LxaS0tNTdwxays4ncbCI3u8jOJnKzi+xsikUkN2ZxZxZ3GXvvHFlRWy+/vPpkOfPYynxvDgAAAACYxCzuOCyNe5vl/c31oZ3BXSUSCdm0aZO7hy1kZxO52URudpGdTeRmF9nZlIhIbhToEbe8dqckkiIV7dtJZcdiCSPdCVesWOH9zugjsrOJ3GwiN7vIziZys4vsbEpEJDcK9IgLzj/XCeJ8P58DAAAAAMKMAj3iajbsDPXwdgAAAACICgr0iEv1oId0BnelPfs60QI9/PaQnU3kZhO52UV2NpGbXWRnUywiuTGLe8RncT/jnpfkg7oG+e11p8nJ/brke3MAAAAAwCxmcUeb7Wjc64pzNbB7mYSVTgSxdu1a7yeE8BHZ2URuNpGbXWRnE7nZRXY2JSKSGwV6hC3d+NH55907FUtF+yIJq6jsjD4iO5vIzSZys4vsbCI3u8jOpkREcqNAj7D0GdwBAAAAAPlFgR5hNRs+KtCZwR0AAAAA8o8CPcKCHvRBIZ7BXcXjcamsrHT3sIXsbCI3m8jNLrKzidzsIjub4hHJjVncIzyL+8jvviCbd+6Rp24+Q4b1qsj35gAAAACAaczijjbZvHO3K871MoLHVIV3BnelE0EsX77c+wkhfER2NpGbTeRmF9nZRG52kZ1NiYjkRoEe8eHtfbq0l/ZFhRJmuhPW1tZ6vzP6iOxsIjebyM0usrOJ3OwiO5sSEcmNAj2ilu6bII4Z3AEAAAAgHCjQI6pm3zXQmcEdAAAAAMKBAj2iajZsd/cDQz6Du9KZGnv16uX9jI0+IjubyM0mcrOL7GwiN7vIzqZ4RHIL98nH+EToxP1LDfWgBzsj7CE7m8jNJnKzi+xsIje7yM6meERy8/vwA3Jat61Rdu5uksJ4TPp16yBh19zcLIsXL3b3sIXsbCI3m8jNLrKzidzsIjubmiOSGwV6hCeI61/ZQYoK4yZ6/PU6gnoPW8jOJnKzidzsIjubyM0usrMpGZHcwl+d4WNXs+8Sa4OqO+V7UwAAAAAA+1CgR7gHfVD3snxvCgAAAABgHwr0CPegW7kGuk4I0b9/f+9nbPQR2dlEbjaRm11kZxO52UV2NsUjkhuzuEdMcyIp723aN4O7gUusKd0Jq6qq8r0ZaAOys4ncbCI3u8jOJnKzi+xsikckN78PP2A/q7bUy56mhJS0i0vvzu3FAp2p8a233vJ+xkYfkZ1N5GYTudlFdjaRm11kZ1NzRHKjQI+YpWnD2+PxmFigMzU2NDR4P2Ojj8jOJnKzidzsIjubyM0usrMpGZHcKNAjZskGW+efAwAAAEBUUKBHtAd9EAU6AAAAAIQKBXrE1AQ96EYmiFMFBQUyePBgdw9byM4mcrOJ3OwiO5vIzS6ys6kgIrkxi3uENO5tlve37DLXgx6LxaSioiLfm4E2IDubyM0mcrOL7GwiN7vIzqZYRHKjBz1CVtTWu8uslZe2k+6disWKpqYmmTt3rruHLWRnE7nZRG52kZ1N5GYX2dnUFJHcKNAjev65HoGyxPfLKfiM7GwiN5vIzS6ys4nc7CI7m5ojkBsFeoTUBJdYqy7L96YAAAAAALJQoEfI0n0TxFk6/xwAAAAAooICPYo96MYKdJ2pcdiwYd7P2OgjsrOJ3GwiN7vIziZys4vsbCqISG6hK9D79u3rzo/Ovt10000Z6yWTSTn//PPdY7Nmzcrb9lqxc3eTrP2wwWSBroqKivK9CWgjsrOJ3GwiN7vIziZys4vsbCqKQG6hK9B1Zr7169enbi+88IJbfskll2Ss98ADD5ib6CwME8RVdSyWzh2KzE0GMW/evEhMCuEbsrOJ3GwiN7vIziZys4vsbGqOSG6huw56ZWVlxtf33HOPDBgwQEaPHp1a9uabb8q9997rAurRo0cettLw+efV9nrPAQAAACAKQteDnm7Pnj3y2GOPyVVXXZXqLd+1a5dcdtll8tBDD0l1dXW+N9EMq+efAwAAAEBUhK4HPZ2eW15XVyeTJk1KLfva174mp59+ukyYMKHVz7N79253C2zfvt3d60Xugwvdx+Nxd0skEu4WCJbrUAo97/1gy3XSAj2YEDxv+nKVPSSjpeWFhYXuedOX6/Pq+tnb2NLy9DbVrP+ozcdUtndfW2pTsD1673tOPrYp/bl8aZOPOaUvD/6f/TMtt8nHnLK3PbhPz896mw623Jc2pWfoS5t8zCm7TSp7e6y3yceccrVJ18neRutt8jGngqxtD76vpfzC0qbsdnhVoE+fPt1NBNezZ0/39VNPPSUvvfSSLFy48JCeZ9q0aTJ16tT9luvzdOjQITW0XofSr1y5Umpra1Pr9OrVy92WLl0q27ZtSy3v37+/VFVVydtvvy0NDR9NvqYGDx4sFRUV7rnTfzl0xkGd1ECH5acbOXKkGymwaNGi1DL9ZRk1apT7eUuWLEktLy0tleHDh8vmzZtlxYoVqeXl5eUyZMgQWbdunaxduza1PL1N73zwoVvWvHWNrFtXaLJN+vN9z8m3Nq1ZsyaVnS9t8jGn7DYdddRR7ue+99573rTJx5xaatOHH34o3bt396pNPuaUq03aDt/a5GNOQZv0Z+h2pX8utd4mH3PK1abjjz9eRowYsV9NYblNPuY0rIU2Kf3+sLapvr5eDkcsmX4IIERWrVrlGjxz5sxUb/ltt90mP/7xj91RikDQq3rmmWfKnDlzWt2D3rt3b9myZYt06tTJ+6NatdsbZNT3X3LLFt19jpSVFJlqk67f2NgoJSUlbpmvOfnYJn0OPS1Fs9N1fWiTjznlWl//ZmbPlGq5TT7mlL3tetO/le3bt3fP40ObDrbclzbp+sH7nG6LD22KSg/6zp07U+9xPrTJx5xytUnX1WJK3+fSJ5223CYfcyrI2vbgfU47WHX9sLZJa82uXbu6Qj6oNb0o0KdMmSKPPPKI64HTF1tt2LDBHf1Ip0fAHnzwQbnoooukX79+rXpufdH0qElbXzRrXlu+RS792evSp0t7eeUbZ4s1urPqkTM9Ahj8LsAGsrOJ3GwiN7vIziZys4vsbGoyktvh1pqhbJkerZgxY4ZMnDgx48XXSeFyTQzXp0+fVhfnUb7EGhPEAQAAAEB4hXIW9xdffFFWr17tZm/HxzeD+6DqsnxvCgAAAADAUg/6uHHjMsb2H0hIR+iH8hrolnvQg3NQYA/Z2URuNpGbXWRnE7nZRXY2FUQgt9Ceg/5JitI56BrvsKnPy47GJvmf286UwdV+txcAAAAArNaaoRzijo/P+m2NrjgvjMekf7cyswcZ6urqGC1hENnZRG42kZtdZGcTudlFdjYlI5IbBXpEzj/v162DFBXajFsvW6DXM8y+lALCj+xsIjebyM0usrOJ3OwiO5uaI5KbzYoNh37+ebXd888BAAAAIAoo0KMyg7vhCeIAAAAAIAoo0CNyDfRBhnvQY7GYlJaWunvYQnY2kZtN5GYX2dlEbnaRnU2xiOTGLO4ez+LenEjK0Lv/R3Y3JWTO18dI324d8r1JAAAAAOCt7czijpas3rrLFecl7eLSu0t7sSqRSMimTZvcPWwhO5vIzSZys4vsbCI3u8jOpkREcqNA91jNvgnijq3qKAVxu0NBdCdcsWKF9zujj8jOJnKzidzsIjubyM0usrMpEZHcKNAjcP75QCaIAwAAAIDQo0CPQA/6oOqyfG8KAAAAAOAgKNAjcIk16z3oOlOjTrTg+4yNPiI7m8jNJnKzi+xsIje7yM6mWERyYxZ3T2dx393ULEPvfs7N5P7at8ZKj/LSfG8SAAAAAHhtO7O4I5cVtfWuOO9YUijVnUrEMp0IYu3atd5PCOEjsrOJ3GwiN7vIziZys4vsbEpEJDcKdM8niBvUvaP5YSBR2Rl9RHY2kZtN5GYX2dlEbnaRnU2JiORGge79BHG2zz8HAAAAgKigQPe9B50CHQAAAABMoED3lC8zuKt4PC6VlZXuHraQnU3kZhO52UV2NpGbXWRnUzwiuTGLu4ezuNfvbpLjJj/n/r/grvOkS4eifG8SAAAAAHhvO7O4I9t7m3a6+8qOxV4U5zoRxPLly72fEMJHZGcTudlEbnaRnU3kZhfZ2ZSISG4U6B6q2bA9NYO7D3QnrK2t9X5n9BHZ2URuNpGbXWRnE7nZRXY2JSKSGwW6h2o27PTm/HMAAAAAiAoKdK9ncC/L96YAAAAAAFqJAt1DPs3grnSmxl69enk/Y6OPyM4mcrOJ3OwiO5vIzS6ysykekdwK870B+Hhtrd8jtTt2u/8f61mBDnvIziZys4nc7CI7m8jNLrKzKR6R3Pw+/BDh4e29u5RKWbEfx1+am5tl8eLF7h62kJ1N5GYTudlFdjaRm11kZ1NzRHKjQPf1/HNPes9VMpl01xHUe9hCdjaRm03kZhfZ2URudpGdTcmI5EaB7pmaDX6dfw4AAAAAUUGB7u0M7hToAAAAAGAJBbpHdLiHjz3oOiFE//79vZ+x0UdkZxO52URudpGdTeRmF9nZFI9Ibn7MIgZnw/ZG2d7YJAXxmPSv7CC+0J2wqqoq35uBNiA7m8jNJnKzi+xsIje7yM6meERy8/vwQ8QEvef9unWQ4sIC8YXO1PjWW295P2Ojj8jOJnKzidzsIjubyM0usrOpOSK5UaB7xMcZ3IOh+w0NDd7P2OgjsrOJ3GwiN7vIziZys4vsbEpGJDcKdI/UbNjp3fnnAAAAABAVFOhezuBelu9NAQAAAAAcIgp0TzQnkvLeJv9mcFcFBQUyePBgdw9byM4mcrOJ3OwiO5vIzS6ys6kgIrkxi7sn1mzdJY17E1JcGJeju/ozg7uKxWJSUVGR781AG5CdTeRmE7nZRXY2kZtdZGdTLCK50YPuiZp9w9uP7V7mLrPmk6amJpk7d667hy1kZxO52URudpGdTeRmF9nZ1BSR3CjQPbF0g5/D2wO+X07BZ2RnE7nZRG52kZ1N5GYX2dnUHIHcKNA960H37RJrAAAAABAVFOieqAl60Ksp0AEAAADAoljS9yu957B9+3YpLy+Xbdu2SadOncS63U3Nctzdz0lTIimv/vNY6VlRKj7RX9GGhgYpLS11k0PADrKzidxsIje7yM4mcrOL7GxKGsntcGtNetA9sHJzvSvOOxYXSo/yEvFRUVFRvjcBbUR2NpGbTeRmF9nZRG52kZ1NRRHIjQLds+HtYT6adDiTQcybNy8Sk0L4huxsIjebyM0usrOJ3OwiO5uaI5IbBboHlm70ewZ3AAAAAIgCCnQP1GzY6e4HdS/L96YAAAAAANqIAt2jHvRB1fYnvAMAAACAqGIWd+OzuO/a0yRD737O/X/+t8+VrmXF4hv9FdVzTQoKCrw8x95nZGcTudlEbnaRnU3kZhfZ2ZQ0khuzuEfcexs/Gt7erazYy+I8sGfPnnxvAtqI7GwiN5vIzS6ys4nc7CI7m/ZEIDcKdONqUsPb/T3/XI+ULVq0yPsZG31EdjaRm03kZhfZ2URudpGdTc0RyS10BXrfvn3dkIXs20033SRbt26VW265RQYNGuQuUN+nTx+59dZb3fABifol1pjBHQAAAABMK5SQmTt3bsZRkbffflvOO+88ueSSS2TdunXu9m//9m8ydOhQWbVqlVx//fVu2e9+9zuJ9ARxFOgAAAAAYFroCvTKysqMr++55x4ZMGCAjB492vWk//d//3fqMV3+ve99T6644gppamqSwsLQNefI9aBX+12g62QQsInsbCI3m8jNLrKzidzsIjubCiKQW2HYJwF47LHH5Pbbb29xpr5gdrwoFucf1u+RTTt2u/8fW+XvOeia7ahRo/K9GWgDsrOJ3GwiN7vIziZys4vsbCqMSG6hrmpnzZoldXV1MmnSpJyPb968Wb7zne/Itddee8Dn2b17t7ulT32vtNddbyoej7tbIpFwt0CwXIfdp1+RrqXlwbT/wfOmL1fZkxq0tFx/AYNLCQT0eXX9YBsXr6tzy4+qKJGOJe1a3HZLbcq1XNfXzPRAjC7zoU0+5tTStus+rNnpuj60yceccq2/Y8cOKSvLPPBnuU0+5pS97XrTv5UVFRXueXxo08GW+9ImXT94n9Nt8aFNPuaU3Sal8yMF73E+tMnHnHK1SdfVTj59n0vvBLTcJh9zKsja9uB9rnPnzm79sLYpux1eFejTp0+X888/X3r27LnfYxrOhRde6M5FnzJlygGfZ9q0aTJ16tT9li9cuFA6dOiQGlqvQ+ZXrlwptbW1qXV69erlbkuXLs2YjK5///5SVVXlzpFvaGhILR88eLD7cKTPnf7LMWzYMCkqKpJ58+ZlbMPIkSPdSAGdkTCgvyx6dEh/3pIlS1LLdWK84cOHuwMTK1askBdXNLrlR5V9NNefnou/du3a1PoW2xTQawcOGTLEtWnNmjWuyNNt0O3zoU0+5pSrTbrusmXL3HbpH0If2uRjTtlt6tGjh6xfv146duzoCnUf2uRjTtlt0g8G+rfyhBNOcBn60CYfc8rVpl27dqXe5/S5fWiTjzllt0mLO507SX9WUORZb5OPOeVq03HHHZfavvQC3XKbfMxpWFabgve5sWPHpmZ0D2Ob6uvr5XDEkumHAEJEJ4DTBs+cOVMmTJiQ8Zh+YBw/fry0b99ennnmGSkpKTnkHvTevXvLli1bUhePt3hU6+6n3pXH31gj15/VT/75gqF5P6r1cbQp1/K9e/fKggULZMSIEdKuXTsv2uRjTrm2Xd8Q5s+f77ILRj9Yb5OPOWUv1//rPnfiiSemfr71NvmYU/a2673mdtJJJ7kPND606WDLfWmTbn/wPqfZ+dAmH3PKbpMu0wI9eI/zoU0+5pSrTbqOFn3p2Vlvk485FWRte/A+pwcddPvD2iatNbt27Zo6FdubHvQZM2a4oxHaS55OG6zFeXFxsTz11FMHLc6Vrqu3bBpi9rnrwYucLX3nbc3yls6JP5Tl+ouTa3mwjcs2fXR0ZnCP8gNuu6U25Voe7LRBgedDm3zMqaXlQXbpz2e9TT7mlL48eIPMzs1ymw627b60KTiVJHt5W7e9peXk9PG2ST/UBX8rg94862063G230qZc73EtbbuVNvmYU/a26PtcS9nlWt9Cm9qy3GKbYmmX4Q5rmw53brRQFuh6tEIL9IkTJ2Y0UIvzcePGuaFgOnmcfh2cT67DEVp6wXykb+Y1G6NxDXTd0XR4SvoQJNhAdjaRm03kZhfZ2URudpGdTbGI5BbKIe7PP/+86yWvqamRgQMHppbPmTNHzj777Jzfo+cJ9O3bt1XPr0W9nnfQ1mEHYbBxe6Oc8v0/S0E8Ju9MHS8l7aJzcAIAAAAAwuhwa839++1DQHvJ9bhBenGuxowZk5qpNvvW2uLcF0v2Xf+8b9f23hfnOqJi06ZNGeeBwAays4ncbCI3u8jOJnKzi+xsSkQkt1AW6Di4pfsK9EHVfg9vV7oT6qyLvu+MPiI7m8jNJnKzi+xsIje7yM6mRERyo0A3KirnnwMAAABAVFCgG7V0X4E+iAIdAAAAALxAgW5QIpFMFegDIzDEXWdq1IkWfJ+x0UdkZxO52URudpGdTeRmF9nZFItIbqGcxf2TZn0W91Vb6mX0j+ZIUWFc3p06XgoLOM4CAAAAAPnm5SzuOLCafRPEHVtVFoniXCeCWLt2rfcTQviI7GwiN5vIzS6ys4nc7CI7mxIRyc3/6s5DUTv/PCo7o4/IziZys4nc7CI7m8jNLrKzKRGR3CjQDarZuDMy558DAAAAQFRQoFu+BnpEetABAAAAIAoo0I3Z05SQ5bXR6kGPx+NSWVnp7mEL2dlEbjaRm11kZxO52UV2NsUjkhuzuBubxV0niBv/wCtSVlwof58yzvvLDAAAAACAFcziHjE1wfXPu5dFpjjXiSCWL1/u/YQQPiI7m8jNJnKzi+xsIje7yM6mRERyo0C3ev55RIa3K90Ja2trvd8ZfUR2NpGbTeRmF9nZRG52kZ1NiYjkRoFutgc9OgU6AAAAAEQBBboxUbsGOgAAAABEBQW6Ibv2NMnqrbsiNYO70pkae/Xq5f2MjT4iO5vIzSZys4vsbCI3u8jOpnhEcivM9wag9ZZt2ik65363siLpVlYsUdsZYQ/Z2URuNpGbXWRnE7nZRXY2xSOSm9+HHzyjl1iL4vnnzc3NsnjxYncPW8jOJnKzidzsIjubyM0usrOpOSK5UaAbPP88agV6Mpl01xHUe9hCdjaRm03kZhfZ2URudpGdTcmI5EaBbsiSCF5iDQAAAACiggLdkKj2oAMAAABAFFCgG1G3a49s3L7b/X9g9zKJ2oQQ/fv3937GRh+RnU3kZhO52UV2NpGbXWRnUzwiuTGLuxFLN+5090dVlErHknYSJboTVlVV5Xsz0AZkZxO52URudpGdTeRmF9nZFI9Ibn4ffvBITWp4e7R6z5XO1PjWW295P2Ojj8jOJnKzidzsIjubyM0usrOpOSK5UaAbsTS4xFoEJ4jTmRobGhq8n7HRR2RnE7nZRG52kZ1N5GYX2dmUjEhuFOjGetAHMUEcAAAAAHiJAt0APUoUzODOJdYAAAAAwE8U6AbU7tgtdbv2SjwmMqAyeuegFxQUyODBg909bCE7m8jNJnKzi+xsIje7yM6mgojkxizuhoa39+3WQUra+f0LmUssFpOKiop8bwbagOxsIjebyM0usrOJ3OwiO5tiEcmNHnQDajZE+/zzpqYmmTt3rruHLWRnE7nZRG52kZ1N5GYX2dnUFJHcKNANFegDI1qgK98vp+AzsrOJ3GwiN7vIziZys4vsbGqOQG4U6AYwQRwAAAAA+I8CPeQSCZ3BfadEvQcdAAAAAHxHgR5yaz9skIa9zVJUEJe+XdtLFOlMjcOGDfN+xkYfkZ1N5GYTudlFdjaRm11kZ1NBRHKjQDcyg/uAqjIpLIhuXEVFRfneBLQR2dlEbjaRm11kZxO52UV2NhVFILfoVnzWzj/vHr3rn6dPBjFv3rxITArhG7KzidxsIje7yM4mcrOL7GxqjkhuFOhWLrFW3SnfmwIAAAAA+ARRoJuZwT26PegAAAAAEAUU6CG2tzkhy2uZwR0AAAAAoiCWTCaTEjHbt2+X8vJy2bZtm3Tq1CnUvefj7n9FOhQVyNtTx0ssFpMo0l9RPddEZ2yM6mtgFdnZRG42kZtdZGcTudlFdjYljeR2uLUmPegh1ZxIyjNvrXP/71FRIonIHUbJtGfPnnxvAtqI7GwiN5vIzS6ys4nc7CI7m/ZEIDcK9BD6n7fXy//7wUvy45eWua+Xbap3X+vyKNIjZYsWLfJ+xkYfkZ1N5GYTudlFdjaRm11kZ1NUcqNADxktwm94bIGs39aYsXzDtka3PKpFOgAAAAD4jgI9ZMPapz79ruQazR4s08d1PQAAAACAXyjQQ+SNlVv36zlPp2W5Pq7rRY1OBgGbyM4mcrOJ3OwiO5vIzS6ys6kgArkxi3uIZnH/w5sfyFd//eZB13vwSyfIhBOOOiLbBAAAAABoHWZx90hVx5KPdT1f6DGkuro6dw9byM4mcrOJ3OwiO5vIzS6ysykZkdwo0EPk5H5dpEd5ibR0VT9dro/relGiMzUuWbLE+xkbfUR2NpGbTeRmF9nZRG52kZ1NzRHJjQI9RAriMZl80VD3/+wiPfhaH9f1AAAAAAB+oUAPmU9/qoc8fMUIqS7PHMauX+tyfRwAAAAA4J9CCZm+ffvKqlWr9lt+4403ykMPPSSNjY1yxx13yK9//WvZvXu3jB8/Xn7yk59I9+7dxRdahJ83tNrN1r5pR6M751yHtUe15zwWi0lpaam7hy1kZxO52URudpGdTeRmF9nZFItIbqGbxb22tjbjvIK3335bzjvvPJk9e7aMGTNGbrjhBnn22Wfl0UcfdbPj3XzzzRKPx+Wvf/2r+VncAQAAAAB2eTeLe2VlpVRXV6duzzzzjAwYMEBGjx7tGjl9+nS57777ZOzYsXLSSSfJjBkz5NVXX5XXX38935uOT0gikZBNmza5e9hCdjaRm03kZhfZ2URudpGdTYmI5Ba6Ie7p9uzZI4899pjcfvvtbijD/PnzZe/evXLuueem1hk8eLD06dNHXnvtNTn11FNzPo8Ohddb+lEN1dTU5G5Ke+H1poGnhx4s11799MEGLS0vKChw2xo8b/pylT3rYEvLCwsL3fOmL9fn1fWzt7Gl5b60STNfvny5OxLVrl07L9rkY065tl23JchO1/OhTT7mlL1c/79ixYpUbj60ycecsrdd73V/q6iokKKiIi/adLDlvrQp/W+lZudDm3zMKbtN+v3p73E+tMnHnHK1SdfJzs56m3zMqSBr24P3uc6dO7v1w9qm7HZ4VaDPmjXLXetu0qRJ7usNGza4Ny798JFOzz/Xx1oybdo0mTp16n7LFy5cKB06dEj13GtP/cqVK90w+0CvXr3cbenSpa4HP9C/f3+pqqpyQ/AbGhoyDhjo9ulzp/9yDBs2zG37vHnzMrZh5MiR7kDEokWLUsv0l2XUqFHu5+mlBAJ6zsXw4cNl8+bN7sNzQP+4DBkyRNatWydr165NLfelTWvWrHG/BwsWLHDb50ObfMwpV5t0PokgO/1D6EObfMwpu009enw0GeWyZctkx44dXrTJx5yy2xRcH3bLli0uQx/a5GNOudq0a9eu1N9KfW4f2uRjTtltKisrc+sG73E+tMnHnHK16bjjjnP36dlZb5OPOQ3LalPwPqeFs35/WNtUX18vXp2Dnk4ngNNQnn76aff1448/LldeeWVGb7g6+eST5eyzz5Yf/OAHre5B7927t/sQE5wXwFGtcPeg6x/QESNG0INurE36hqAjXzQ7etDttEn/r/vciSeeSA+6oTbpveamp3/Rg26rTbr9wfscPeh22qTL5s6dm3qP86FNUepB16IvPTvrbYpKD/qCBQvcQQfd/rC2SWvNrl27tvkc9ND2oGvP24svvigzZ85MLdNz0vUDvx45Se9F37hxo3usJcXFxe6WTUPUW7rgRc6WvvO2Znn287Zluf7i5Fre0jYe6nIrbdL1NW+9D9ax3iYfc2pp24Pscr0B5lr/cLe9peXk1Prl+iajR5azc7PcpoNtuw9t0p+j+1t2oWC5Ta1d7kObgr+VQW+eD206nG230KZgn8v1t9Jqmw512622Sd/nWsou1/oW2tSW5dbaFNu3z+nPamnbw9Cmltphvgd9ypQp8sgjj7jhzUEj9SiEDjt44okn5OKLL3bLampq3LCIA52Dno1Z3AEAAAAAHzfvZnFXOpxAZ2efOHFixhEIbejVV1/tJo3Ty67p0Fkd8n7aaae1ujiHPfr7oOeGpA8zgQ1kZxO52URudpGdTeRmF9nZlIhIbqEs0HVo++rVq+Wqq67a77H7779f/uEf/sH1oJ911lluaHv6MHj4Jyo7o4/IziZys4nc7CI7m8jNLrKzKRGR3EJ5Dvq4ceMyTr5PV1JSIg899JC7AQAAAADgi1D2oAMAAAAAEDUU6Ag9nUFRJwfMNZMiwo3sbCI3m8jNLrKzidzsIjub4hHJLbSzuH+SmMUdAAAAAPBx83IWdyCdTgSxfPly7yeE8BHZ2URuNpGbXWRnE7nZRXY2JSKSGwU6Qk93wtraWu93Rh+RnU3kZhO52UV2NpGbXWRnUyIiuVGgAwAAAAAQAqG8zNonLTjtXs8PQPg1NTVJfX29y6uwMJK/smaRnU3kZhO52UV2NpGbXWRnU5OR3IIas61TvYW3ZZ+gHTt2uPvevXvne1MAAAAAAB7WnOXl5Yf8fZGcxV3PW1i3bp107NhRYrFYvjcHrTgKpQdT1qxZw6z7xpCdTeRmE7nZRXY2kZtdZGfTdiO5aXmtxXnPnj3bdEm4SPag6wvVq1evfG8GDpHuiGHeGdEysrOJ3GwiN7vIziZys4vsbOpkILe29JwHmCQOAAAAAIAQoEAHAAAAACAEKNAResXFxTJ58mR3D1vIziZys4nc7CI7m8jNLrKzqTgiuUVykjgAAAAAAMKGHnQAAAAAAEKAAh0AAAAAgBCgQAcAAAAAIAQo0BEK06ZNk1GjRknHjh2lqqpKPvvZz0pNTU3GOmPGjJFYLJZxu/766/O2zfjIlClT9stl8ODBqccbGxvlpptukq5du0pZWZlcfPHFsnHjxrxuM0T69u27X25606wU+1t4vPLKK3LRRRdJz549XQ6zZs3KeFynkrn77rulR48eUlpaKueee6689957Gets3bpVLr/8cnfd2IqKCrn66qtl586dR7gl0XKg3Pbu3Svf/OY35fjjj5cOHTq4db785S/LunXrDrqf3nPPPXloTbQcbJ+bNGnSfrl8+tOfzliHfS58ueV6z9Pbj370o9Q67HPhrAEaW/FZcvXq1XLhhRdK+/bt3fPceeed0tTUJBZRoCMUXn75Zbfjvf766/LCCy+4Dy/jxo2T+vr6jPWuueYaWb9+fer2wx/+MG/bjP9z3HHHZeTyv//7v6nHvva1r8nTTz8tTz75pMtZP4B+/vOfz+v2QmTu3LkZmel+py655JLUOuxv4aB/B4cPHy4PPfRQzsc1lx//+Mfy05/+VP72t7+5gm/8+PHuA01AC4V33nnH5fzMM8+4D7LXXnvtEWxF9Bwot127dsmCBQvkrrvucvczZ850H0g/85nP7Lfuv/7rv2bsh7fccssRakF0HWyfU1qQp+fyxBNPZDzOPhe+3NLz0tvPf/5zV4BrsZeOfS58NcDXDvJZsrm52RXne/bskVdffVV+8YtfyKOPPuoOXpuks7gDYbNp0ya9ukDy5ZdfTi0bPXp08qtf/Wpetwv7mzx5cnL48OE5H6urq0u2a9cu+eSTT6aWLV682GX72muvHcGtxMHovjVgwIBkIpFwX7O/hZPuO7///e9TX2te1dXVyR/96EcZ+11xcXHyiSeecF+/++677vvmzp2bWudPf/pTMhaLJT/44IMj3IJoys4tlzfeeMOtt2rVqtSyo48+Onn//fcfgS3EoWQ3ceLE5IQJE1r8HvY5G/ucZjh27NiMZexz4asB6lrxWfKPf/xjMh6PJzds2JBa5+GHH0526tQpuXv37qQ19KAjlLZt2+buu3TpkrH8V7/6lXTr1k0+9alPybe+9S3XC4H80+G0OqSsf//+rtdAhxmp+fPnuyOhOuQ2oMPf+/TpI6+99loetxjp9IjzY489JldddZXrTQiwv4XfypUrZcOGDRn7WHl5uZxyyimpfUzvdYjtyJEjU+vo+vF43PW4Izzve7r/aVbpdHitDus88cQT3VBcq0M2fTNnzhw3jHbQoEFyww03yJYtW1KPsc+Fnw6PfvbZZ92pB9nY58JVA8xvxWdJvddThrp3755aR0eSbd++3Y1ksaYw3xsAZEskEnLbbbfJGWec4QqDwGWXXSZHH320KwQXLVrkzt/TIYE6NBD5o4WADiPSDyk6FGzq1Kly5plnyttvv+0Kh6Kiov0+cOofUH0M4aDn6dXV1bnzKgPsbzYE+1H6h5Lg6+AxvddCIl1hYaH78MN+GA56OoLuY5deeqk7Zzlw6623yogRI1xWOmxTD5Tp39n77rsvr9sbdTq8XYfX9uvXT5YvXy7/8i//Iueff74rEgoKCtjnDNAh0HrOc/Ypd+xz4asBNrTis6Te53ofDB6zhgIdoaPnoWhxl34es0o/d0uPkumESOecc457cxwwYEAethRKP5QEhg0b5gp2Lex++9vfugmrEH7Tp093OWoxHmB/A44M7Rn6whe+4Cb7e/jhhzMeu/322zP+vuqH1Ouuu85NqlRcXJyHrYX60pe+lPH3UbPRv4vaq65/JxF+ev65jvgrKSnJWM4+F84aIGoY4o5Qufnmm91kKrNnz5ZevXodcF0tBNWyZcuO0NahNfQI58CBA10u1dXVbvi09s5mDy3Tx5B/q1atkhdffFG+8pWvHHA99rdwCvaj7Nls0/cxvd+0aVPG4zpkU2eZZj8MR3Gu+6FOjpTee97SfqjZvf/++0dsG3FwenqXng4U/H1knwu3v/zlL25E2MHe9xT7XP5rgOpWfJbU+1zvg8Fj1lCgIxS050B3zN///vfy0ksvuWFjB/Pmm2+6e+3ZQ3joZWS0l1VzOemkk6Rdu3by5z//OfW4vinqOeqnnXZaXrcTH5kxY4Ybiqmznx4I+1s46d9K/fCRvo/pOXd6nmuwj+m9frDR8/gC+ndWhxIGB16Qv+Jc5/DQg2R6zuvB6H6o5zFnD59Gfq1du9adgx78fWSfC/+oMf18ojO+Hwz7XP5rgJNa8VlS7//+979nHBgLDnoOHTpUrGGIO0IzpOXxxx+XP/zhD+6coOB8EZ3sSIdJa8Gnj19wwQXuQ4yeE6uXXDjrrLPcECTkz9e//nV33VEd1q6XvZg8ebI7B0/PpdT8dAIWHTKm53PpH0q9XIn+IT311FPzvemRpx8WtUCfOHGiOz8ywP4WvoNe6SMXdGI4/dCo+5ROkqPn6333u9+VY4891n2w0Ut36ekKei1ZNWTIEHfOrF42Ty/FpoWhfhjSYbrppzXgyOWmhdw//uM/ukusaY+RXiIoeN/Tx3VYrZ7PrAdazj77bPe+qF/rfnjFFVdI586d89iyaGenN51rRS/NpQfH9O/lN77xDTnmmGPcpFSKfS6cfyuDA5h6qa577713v+9nnwtnDVDeis+Selk2LcT/6Z/+yV16VJ/j29/+tntuk6cm5HsaeUDpr2Ku24wZM9zjq1evTp511lnJLl26uMsHHXPMMck777wzuW3btnxveuR98YtfTPbo0SNZVFSUPOqoo9zXy5YtSz3e0NCQvPHGG5OdO3dOtm/fPvm5z30uuX79+rxuMz7y3HPPuf2spqYmYzn7W7jMnj07599HvdRTcKm1u+66K9m9e3eX1znnnLNfplu2bEleeumlybKyMnfZmSuvvDK5Y8eOPLUoGg6U28qVK1t839PvU/Pnz0+ecsopyfLy8mRJSUlyyJAhye9///vJxsbGfDct0tnt2rUrOW7cuGRlZaW79JNeluuaa67JuLyTYp8L399K9cgjjyRLS0vdpbuysc+FswZo7WfJ999/P3n++ee7fLt165a84447knv37k1aFNN/8n2QAAAAAACAqOMcdAAAAAAAQoACHQAAAACAEKBABwAAAAAgBCjQAQAAAAAIAQp0AAAAAABCgAIdAAAAAIAQoEAHAAAAACAEKNABAAAAAAgBCnQAAD4Bc+bMkVgsJnV1dR/bun379pUHHnjgY9xKtMaYMWPktttuy/dmAAAigAIdAOCl1157TQoKCuTCCy/My88//fTTZf369VJeXn7I6z766KNSUVGx33pz586Va6+9Vj5pP/vZz2T48OFSVlbmtuPEE0+UadOmpR6fNGmSfPazn5UjITh4cdxxx0lzc3PGY7pt+loBAOALCnQAgJemT58ut9xyi7zyyiuybt26I/7zi4qKpLq62hWXH9e6lZWV0r59e/kk/fznP3e9xbfeequ8+eab8te//lW+8Y1vyM6dOyWfVqxYIf/1X/8lvtCDDYlEIt+bAQAIGQp0AIB3tJj8zW9+IzfccIPrQc/Vy/r000/LqFGjpKSkRLp16yaf+9znUo9t2rRJLrroIiktLZV+/frJr371q4zh5e+//74rprWADejwdF2mPb65hq2vWrXKPWfnzp2lQ4cOrkf4j3/8437r6v+vvPJK2bZtm1umtylTpuQc4r569WqZMGGC6+nu1KmTfOELX5CNGzemHtfvO+GEE+SXv/yl+17tof/Sl74kO3bsaPG1e+qpp9zzXH311XLMMce47bz00kvle9/7Xuo5f/GLX8gf/vCH1PYFbV6zZo37Xu3Z7tKli9s2fa2ye96nTp3qDjboNl9//fWyZ8+eg2aqB1smT54su3fvzvn4oWTy3HPPuVEBmu/YsWNd3n/6059kyJAhbpsuu+wy2bVrV8bzNzU1yc033+xeQ/19ueuuuySZTKYe1+36+te/LkcddZTL95RTTkn93PRREfr6Dh06VIqLi11+AACko0AHAHjnt7/9rQwePFgGDRokV1xxhesVTi+mnn32WVeQX3DBBbJw4UL585//LCeffHJGIanF5uzZs+V3v/ud/OQnP3FF3OG46aabXBGnPfp///vf5Qc/+IErrHMNd9ciXAtFHfauNy38smnvqxbAW7dulZdfflleeOEF18v8xS9+MWO95cuXy6xZs+SZZ55xN133nnvuaXE7tSf/9ddfdwcUctFt0SL805/+dGr7dJv37t0r48ePl44dO8pf/vIX1/Ou7dP10gtwfa0XL17sitcnnnhCZs6c6Qr2g9FefS2S//3f/10Olx5k+I//+A959dVXUwcV9DV//PHH3e/G888/v9/P0YMShYWF8sYbb8iDDz4o9913n/znf/5n6nEt3vW0il//+teyaNEiueSSS1zb33vvvdQ6WvRr7vp977zzjlRVVR12WwAAnkkCAOCZ008/PfnAAw+4/+/duzfZrVu35OzZs1OPn3baacnLL7885/fW1NRoJZ984403UssWL17slt1///3u65UrV7qvFy5cmFrnww8/dMuCn6P3+rUuV8cff3xyypQpOX9m9rozZsxIlpeX77fe0UcfndqG559/PllQUJBcvXp16vF33nknY9snT56cbN++fXL79u2pde68887kKaec0uJrt27duuSpp57qnmfgwIHJiRMnJn/zm98km5ubU+vosgkTJmR83y9/+cvkoEGDkolEIrVs9+7dydLS0uRzzz2X+r4uXbok6+vrU+s8/PDDybKysoznb+m1+elPf+q+v66uzj2mr5G+VoeayYsvvphaZ9q0aW7Z8uXLU8uuu+665Pjx41Nfjx49OjlkyJCMtn3zm990y9SqVatcFh988EHGtp9zzjnJb33rW+7/up36c958880WX3sAAOhBBwB4paamxvVy6rBspb2e2qus56QHdBj0Oeeck/P7tXdXv+ekk05KLdPe+FyTth0KPaf7u9/9rpxxxhluqLb2sh4O3c7evXu7W0CHTut26mMBHdquvdqBHj16HHA0gD6uPcHay//Vr37V9VpPnDjR9QYf6Jzpt956S5YtW+Z+lvac602HuTc2Nrpe/IBOPpd+Hv1pp53mTknQnuyD0WH3Xbt2db3Qh2PYsGGp/3fv3t1tT//+/TOWZb9Gp556asYcAbrd2juu55Lra6X3AwcOTLVdbzpaIb3tOtdA+s8GACBb4X5LAAAwTAtxLSp79uyZWqbD2/WcXx3WrOcQ67nHhyMe/+j4dvqweR3ifSBf+cpX3BDwYAi1zop+7733unOrP0nt2rXL+FqLzNZMTvapT33K3W688UZ3nviZZ57pCs6zzz475/paZOtBDT1fP5ueb/5x0AMnei68noKgQ8rbmkn6a6KvR1tfo/S26xUD5s+f7+7TpZ/GoL93rZk0EAAQXfSgAwC8oYW5zvStha/2kgc37d3Vgl3PeVbai6nnQueiveX6PFpspffKp1+jPCg49fzrQPrkZC3R3m4tdvW86zvuuMNdziwX7WnNvqRYNp3QTHud03ue3333Xbed2pP+cQqer76+vsXtGzFihOtR1vOqdXK59Fv6peY0i4aGhtTXer67FrHpIwEORM/t1onrss9bb2smrfW3v/0t42vd7mOPPdYV5DrhnL4e2uue3XY9px8AgNaiQAcAeEMnQfvwww/dUOigBzi4XXzxxalh7jrEXIt1vdfh4MGkbUonltPh3Nddd50ryrRQ197v9F53/b8OedbJ1vT7tWf529/+9kEnOdPZw1euXCkLFixwE9BpkZ2LDkvXXlk9iLB58+b9ZhRX5557rhx//PFy+eWXu+fTYf1f/vKXZfTo0TJy5Mg2v4Y68/13vvMdN8mbThSnhag+rxbAOqw72D4doq8HLnT7tKdat0NnN9eJ63SSOG2nTgSnQ/vXrl2ben6dME7z0YMJOou9ZqC94UEPeGvo664T/wUHDNqayaHQGddvv/1212b93dFJ5PQUAKVD27X9+jrpwRdtu+ahoyR0xAQAAK1FgQ4A8IYW4Fq4pvfYBrRAnzdvnissx4wZI08++aS75JVehkwvtaUFVWDGjBmux12L3c9//vNy7bXX7jfjthaI2tOuw7q1+Nbzyw9Ee1h1JnctyvUAgBZ1Ojt8Ljoruva067nzWhj/8Ic/3G8dHSqtlzrTy7adddZZrt16HrVeXu5w6PNoUa491bqN+rrppej0YIGe/62uueYadyBDDwTo9mkxr+dx6wz1ffr0ca+ZtlMLcT0HXWekD+i5/9rzrNus7fvMZz6Tuoxca2leetPX/3AyORRafGvPv872rzlqca6/F+m/M7qOjozQ10YvJzd37lz3egAA0FoxnSmu1WsDABBR2musRZ/e0DZ67rgOwdfLvgEAgP3Rgw4AAAAAQAhQoAMAAAAAEAIMcQcAAAAAIAToQQcAAAAAIAQo0AEAAAAACAEKdAAAAAAAQoACHQAAAACAEKBABwAAAAAgBCjQAQAAAAAIAQp0AAAAAABCgAIdAAAAAIAQoEAHAAAAACAEKNABAAAAAAgBCnQAAAAAAEKAAh0AAAAAgBCgQAcAAAAAIAQo0AEAAAAAkPz7/zZZssHG1XZrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "acquisition_fns = {\"entropy\":calc_entropy, \"MI\": calc_MI}\n",
    "plot_acquisition_curves(list(acquisition_fns.keys()), database = database)\n",
    "Image(filename='acquisition_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46a737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_w_acquisition(T, model, train_dataset, train_indices, pool_indices, acquisition_fn, n_acq = 100, n_epochs=1, acq_batch_size = 128):\n",
    "    train_indices_copy = train_indices.copy()\n",
    "    pool_indices_copy = pool_indices.copy()\n",
    "\n",
    "    for i in range(n_acq):\n",
    "        considered_indices = pool_indices.copy()\n",
    "        condition = False\n",
    "        final = False\n",
    "        while True: \n",
    "            pool_data = DataLoader(Subset(train_dataset, considered_indices.copy()), batch_size = acq_batch_size, shuffle = False)    # gets data from pool from which we will acquire new xs\n",
    "            \n",
    "            considered_indices = []\n",
    "\n",
    "            for batch_idx, (x_batch,_) in enumerate(pool_data):\n",
    "                acquired_x, acquired_indices = acquire_x(x_batch, 10, get_TNC_preds(x_batch, model ,T), acquisition_fn)\n",
    "                print(f\"Acquired indices: {acquired_indices}\")\n",
    "\n",
    "                considered_indices.append(acquired_indices)\n",
    "\n",
    "            # Ensures we get final actual acquired indices when length of considered_indices is less than batch_size\n",
    "            if (len(considered_indices)>128):\n",
    "                condition = True\n",
    "            if condition: \n",
    "                if final:\n",
    "                    pool_indices_copy = np.setdiff1d(pool_indices_copy, considered_indices)\n",
    "                    train_indices_copy = np.concatenate((train_indices_copy, considered_indices))\n",
    "                    model = train_model(train_indices=train_indices_copy, lr = opt_lr, n_epochs = n_epochs)\n",
    "                    break\n",
    "                else:\n",
    "                    final = True\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b592ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class analytic_inf_CNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            # Convolution 1\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Convolution 2\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Max pooling\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # Dropoout 1\n",
    "            nn.Dropout(p=0.25),\n",
    "\n",
    "            # Flatten and fully connected\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = 32*11*11, out_features = hidden_dim),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Droput 2\n",
    "            nn.Dropout(p=0.5),\n",
    "        )\n",
    "        self.final_layer = nn.Linear(in_features = hidden_dim, out_features = output_dim)\n",
    "    def forward(self, x):\n",
    "        phi = self.layers(x)\n",
    "        pred = self.final_layer(phi)\n",
    "        return pred, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AI_model(model, train_indices, lr = 3e-4, weight_decay = 1e-6, n_epochs = 100, s = 1, sigma = 1):\n",
    "    train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size=64, shuffle=True)\n",
    "    n_batches = len(train_loader)\n",
    "\n",
    "    # Initialize model, optimizer and loss function \n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        pbar = tqdm.tqdm(enumerate(train_loader), total=n_batches, \n",
    "                               desc=f'Epoch {epoch + 1}/{n_epochs}')\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Change predictions to one-hot encodings\n",
    "            target = F.one_hot(target, num_classes = 10)\n",
    "            pred, phi = model(data)\n",
    "            \n",
    "            Sigma_dash = torch.linalg.inv((sigma**(-2)*phi@phi.T) + s**(-2))\n",
    "\n",
    "            #mu_dash = sigma**(-2)*Sigma_dash@phi.T@target\n",
    "    \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            pbar.set_postfix(loss = loss.item())\n",
    "            #pbar.set_description(f'Epoch {epoch + 1}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27c442",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c47603",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_model() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m all_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m T \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mopt_lr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     output \u001b[38;5;241m=\u001b[39m test_model(model)\n\u001b[1;32m      8\u001b[0m     all_outputs\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "\u001b[0;31mTypeError\u001b[0m: train_model() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "N=1\n",
    "\n",
    "for i in range(N):\n",
    "    all_outputs = []\n",
    "    for T in range(5):\n",
    "        model = train_model(train_indices = train_indices, lr = opt_lr)\n",
    "        output = test_model(model)\n",
    "        all_outputs.append(output)\n",
    "    all_outputs = torch.stack(all_outputs, dim =0)\n",
    "    print(all_outputs.shape)\n",
    "\n",
    "    acquired_indices = np.random.choice(pool_indices, size=10, replace= False)\n",
    "    pool_indices = np.setdiff1d(pool_indices, acquired_indices)\n",
    "    train_indices = np.concatenate((train_indices, acquired_indices))\n",
    "\n",
    "    train_loader = DataLoader(Subset(train_dataset, train_indices), batch_size = 64, shuffle = True)\n",
    "\n",
    "    print(len(train_loader.dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d4e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1000, 0.6000, 0.3000],\n",
      "         [0.0000, 0.8000, 0.2000],\n",
      "         [0.1000, 0.7000, 0.2000]],\n",
      "\n",
      "        [[0.1000, 0.2000, 0.7000],\n",
      "         [0.0000, 0.9000, 0.1000],\n",
      "         [0.8000, 0.1000, 0.1000]]])\n",
      "max indices shape: torch.Size([2, 3, 1])\n",
      "zeros: torch.Size([2, 3, 3])\n",
      "one_hot scatter: torch.Size([2, 3, 3])\n",
      "sum over T: torch.Size([3, 3])\n",
      "c_argmax: torch.Size([3])\n",
      "tensor([0.5000, 0.0000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t1n1=[0.1,0.6,0.3]\n",
    "t1n2=[0.0,0.8,0.2]\n",
    "t1n3=[0.1,0.7,0.2]\n",
    "t2n1=[0.1,0.2,0.7]\n",
    "t2n2=[0.0,0.9,0.1]\n",
    "t2n3=[0.8,0.1,0.1]\n",
    "\n",
    "\n",
    "t1_predictions = torch.tensor([t1n1, t1n2, t1n3])\n",
    "\n",
    "# T=2 Predictions: Shape (3, 3) -> N x C\n",
    "t2_predictions = torch.tensor([t2n1, t2n2, t2n3])\n",
    "\n",
    "# --- Step 2: Stack the T tensors along a new dimension (dim=0) ---\n",
    "# Resulting shape: (T, N, C) -> (2, 3, 3)\n",
    "tensor = torch.stack([t1_predictions, t2_predictions], dim=0)\n",
    "\n",
    "print(tensor)\n",
    "\n",
    "print(calc_var_rat(tensor))\n",
    "\n",
    "# print(torch_tensor)\n",
    "# print(torch_tensor.shape)\n",
    "# print(calc_entropy(torch_tensor))\n",
    "\n",
    "# print(f\"Entropy shape: {calc_entropy(torch_tensor).shape}\")\n",
    "\n",
    "# print(calc_MI(torch_tensor))\n",
    "# print(calc_MI(torch_tensor).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b5dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    for batch_idx, (data,target) in (pbar:= tqdm.tqdm(enumerate(test_loader))):\n",
    "        print()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UDL Active Learning (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
